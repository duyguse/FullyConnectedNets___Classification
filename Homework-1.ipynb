{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I - Fully Connected Neural Networks\n",
    "\n",
    "We covered artificial neural networks with multiple hidden layers in class. In this assignment, you will implement Fully Connected Neural Network (FCN) components in order to perform a supervised classification task.\n",
    "\n",
    "The dataset you are going to work with are : (i) for development of your code, you will use Wine dataset for classification; (ii) for actual training and testing of your implementation in this assignment, the actual dataset will be Book Genre Classification data. You will be performing a genre classification of books into 32 categories.\n",
    "\n",
    "Usage of any built-in functions for code parts that you are asked to write are not allowed. We provide a skeleton code on which to build on your own architecture. In the Layer class, there are two important methods, named as forward and backward. Almost everything you will use in this assignment is derived from this class. We will follow PyTorch-like architecture in the skeleton code.\n",
    "\n",
    "**Please do not modify the following cells, except the book genre classification cell. We will use them for the evaluation of your homeworks. **\n",
    "\n",
    "**You should modify and fill in the code under blg561/layers.py, which includes functions such as layer.NNLayer.* ...**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from blg561e.layer import layer\n",
    "from blg561e.checks import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To auto-reload your modules from the *.py files, re run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "In the `Layer` class, there are two important methods, named as `forward` and `backward`. Almost everything you will use in this assignment is derived from this class. You will be programming in Python language.\n",
    "\n",
    "**Don't forget to test your implementation by using the cells below!**\n",
    "\n",
    "\n",
    "\n",
    "### a. Affine Layer\n",
    "\n",
    "In this layer, we basically implement the hidden layers of neural nets. Each neuron (building block of neural networks) is a just logistic regression classifier itself, but stacking these neurons make them powerful to implement any function.\n",
    "We are going to implement our affine layer \n",
    "\n",
    "Go under blg561e/layer.py and find Affine class. Implement the forward pass for Affine layer which is formulated as follows:\n",
    "\n",
    "$ z = W x + b $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing forward method of affine layer:\n",
      "difference:  8.825372662436368e-08\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 10\n",
    "input_shape = (4, 7, 2) \n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "affineLayer = layer.AffineLayer(input_size, weight_size)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "affineLayer.W = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "affineLayer.b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "out = affineLayer.forward(x)\n",
    "correct_out = np.array([[-0.34448963, -0.15630714,  0.03187535],\n",
    "       [-0.18626697,  0.0119934 ,  0.21025377],\n",
    "       [-0.0280443 ,  0.18029394,  0.38863218],\n",
    "       [ 0.13017836,  0.34859447,  0.56701059],\n",
    "       [ 0.28840102,  0.51689501,  0.74538901],\n",
    "       [ 0.44662368,  0.68519555,  0.92376742],\n",
    "       [ 0.60484634,  0.85349608,  1.10214583],\n",
    "       [ 0.763069  ,  1.02179662,  1.28052425],\n",
    "       [ 0.92129166,  1.19009716,  1.45890266],\n",
    "       [ 1.07951432,  1.35839769,  1.63728107]])\n",
    "\n",
    "relError = rel_error(out, correct_out)\n",
    "\n",
    "print('Testing forward method of affine layer:')\n",
    "print('difference: ', relError)\n",
    "assert 1e-6 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward pass : \n",
    "Go under blg561e/layer.py and find AffineLayer class. Implement the backward pass for Affine layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing backward method of affine layer:\n",
      "dx error:  8.322946841758815e-10\n",
      "dw error:  2.9043699773260153e-09\n",
      "db error:  3.216964989387283e-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1773)\n",
    "num_inputs = 7\n",
    "input_shape = (4, 10, 3)\n",
    "output_dim = 8\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "affineLayer = layer.AffineLayer(input_size, weight_size)\n",
    "\n",
    "\n",
    "x = np.random.randn(10, 2, 3)\n",
    "affineLayer.W = np.random.randn(6, 5)\n",
    "affineLayer.b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = grad_check(affineLayer.forward, x, dout)\n",
    "dw_num = grad_check(lambda _ : affineLayer.forward(x), affineLayer.W, dout)\n",
    "db_num = grad_check(lambda _ : affineLayer.forward(x), affineLayer.b, dout)\n",
    "\n",
    "affineLayer.forward(x)\n",
    "dx, dw, db = affineLayer.backward(dout)\n",
    "\n",
    "# Errors should be around 1e-6 at least\n",
    "print('Testing backward method of affine layer:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))\n",
    "\n",
    "assert 1e-6 > rel_error(dx_num, dx) \n",
    "assert 1e-6 > rel_error(dw_num, dw) \n",
    "assert 1e-6 > rel_error(db_num, db) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### b. ReLU Layer\n",
    "\n",
    "Go under `blg561e/layer.py` and find `ReLU` class. Implement the forward pass for ReLU which is basicly zeroing the negative inputs:\n",
    "\n",
    "$ ReLU(x) = max(x, 0) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing forward method of ReLU layer:\n",
      "Error:  0.0\n"
     ]
    }
   ],
   "source": [
    "relu = layer.ReLU()\n",
    "x = np.array([0,1,3,4,-1,2,4,1773,-1773, 1.3, .4, -.1]).reshape(3, -1)\n",
    "out = relu.forward(x)\n",
    "correct_out = np.array([[0.000, 1.000, 3.000, 4.000],\n",
    "                       [0.000, 2.000, 4.000, 1773],\n",
    "                       [0.000, 1.300, 0.4, 0]])\n",
    "\n",
    "# Compare your output with ours. \n",
    "relError = rel_error(out, correct_out)\n",
    "print('Testing forward method of ReLU layer:')\n",
    "print('Error: ', rel_error(out, correct_out))\n",
    "assert 1e-6 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing backward method of ReLU layer:\n",
      "dx error:  3.2756263483625388e-12\n"
     ]
    }
   ],
   "source": [
    "relu = layer.ReLU()\n",
    "np.random.seed(1773)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = grad_check(relu.forward, x, dout)\n",
    "\n",
    "relu.forward(x)\n",
    "dx = relu.backward(dout)\n",
    "# The error should be around 3e-12\n",
    "print('Testing backward method of ReLU layer:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Softmax classifier \n",
    "\n",
    "In multi-class classification task, as we've seen in the class, the softmax loss function is utilized. \n",
    "Practically, at the final layer of the network, instead of the standard activation, we utilize softmax function to turn the likelihood of each class into class probabilities. Then, we utilize the cross-entropy loss as the data loss. Below, you implement and return only the data loss component in your overall loss. \n",
    "*** Implement your loss computation in the function \"loss\" of the layer.py ***\n",
    "\n",
    "The L2 regularizer will be added by you in the Optimization phase later.\n",
    "You will write forward pass and backward pass for the softmax unit. Below, we evaluate your method by a numerical gradient method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.302478991941983\n",
      "dx error:  8.698659869674144e-09\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1773)\n",
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "softmax = layer.Softmax()\n",
    "\n",
    "def softmax_loss (x,y):\n",
    "    probs = softmax.forward(x)\n",
    "    dx = softmax.backward(y)\n",
    "    \n",
    "    loss = layer.loss(probs, y) \n",
    "    return loss,dx\n",
    "\n",
    "loss, dx = softmax_loss(x,y)\n",
    "\n",
    "dx_num = grad_check(lambda x: softmax_loss(x, y)[0], x)\n",
    "\n",
    "# The loss should be about 2.3\n",
    "print('\\nTesting softmax_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Implement your activation (Bonus)\n",
    "Implement a novel or a recently published activation function and test its correctness below. If you used an activation from a paper, please don't forget to give a reference to it. Make sure that you have the correct implementation of the forward pass so that we can test your backward pass using a numerical gradient.\n",
    "\n",
    "Also, under this cell, write your activation mathematically and its derivative. Do not forget to use your activation in training part with the Wine data to show that it works and makes sense. You can also plot your activation for litte extra credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your activation:\n",
      "dx error:  0.8944288726913566\n"
     ]
    }
   ],
   "source": [
    "act = layer.YourActivation()\n",
    "np.random.seed(1773)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = grad_check(act.forward, x, dout)\n",
    "\n",
    "act.forward(x)\n",
    "dx = act.backward(dout)\n",
    "\n",
    "relError = rel_error(dx_num, dx)\n",
    "print('Testing your activation:')\n",
    "print('dx error: ', relError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Optimizers\n",
    "\n",
    "Implement SGD and SGDWithMomentum Strategies in `VanillaSGDOptimizer` and `SGDWithMomentum` classes. Test their correctness using cell below. \n",
    "**Do not forget to add L2 regularization to both optimizers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1773)\n",
    "toyModel = layer.Model()\n",
    "layers = [layer.AffineLayer(10,2, seed=1773), layer.AffineLayer(2,3, seed=1773), layer.Softmax()]\n",
    "toyModel(layers)\n",
    "optimizer = layer.VanillaSDGOptimizer(model=toyModel, lr=1, regularization_str=1e-1)\n",
    "\n",
    "x = np.random.randn(3,10)\n",
    "y = np.array([0,1,2]).reshape(1,-1)\n",
    "toyModel.forward(x)\n",
    "toyModel.backward(y)\n",
    "optimizer.optimize()\n",
    "expected = [ np.array([[ 0.97873084,  0.81250429],\n",
    " [-3.7373582,  -4.06007668],\n",
    " [ 0.29461562, -0.37317717],\n",
    " [ 0.23786611 , 0.27586238],\n",
    " [-1.45262147, -2.34007449],\n",
    " [ 0.03742712, -0.24127232],\n",
    " [ 0.2617457 ,  0.51694319],\n",
    " [ 0.35243035,  0.96434886],\n",
    " [ 0.17950643,  0.76174137],\n",
    " [ 1.62739663,  1.42935729]]),\n",
    "np.array([-0.23634795, -0.22072128]),\n",
    "np.array([[-0.53813187, -0.23883808, -0.09825078],\n",
    " [-1.90591288, -1.13402054, -0.4392717 ]]),\n",
    "np.array([-0.34588157, -0.00713497,  0.35301654])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Weights of 0th layer\n",
      "Testing biases of 1th layer\n",
      "Testing Weights of 0th layer\n",
      "Testing biases of 1th layer\n"
     ]
    }
   ],
   "source": [
    "student_out = []\n",
    "for i in range(2):\n",
    "    student_out.append( toyModel[i].W)\n",
    "    student_out.append(toyModel[i].b)\n",
    "for i in range(4):\n",
    "    relError = rel_error(student_out[i], expected[i])\n",
    "    if i % 2 == 0:\n",
    "        print('Testing Weights of {}th layer'.format(i%2))\n",
    "    else:\n",
    "        print('Testing biases of {}th layer'.format(i%2))\n",
    "    assert 1e-6 > relError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1773)\n",
    "toyModel = layer.Model()\n",
    "layers = [layer.AffineLayer(10,2, seed=1773), layer.AffineLayer(2,3, seed=1773), layer.Softmax()]\n",
    "toyModel(layers)\n",
    "optimizer = layer.SGDWithMomentum(model=toyModel, lr=1, regularization_str=1e-1, mu=.5)\n",
    "\n",
    "x = np.random.randn(3,10)\n",
    "y = np.array([0,1,2]).reshape(1,-1)\n",
    "toyModel.forward(x)\n",
    "toyModel.backward(y)\n",
    "optimizer.optimize()\n",
    "expected = [np.array([[ 0.97873084,  0.81250429],\n",
    "        [-3.7373582 , -4.06007668],\n",
    "        [ 0.29461562, -0.37317717],\n",
    "        [ 0.23786611,  0.27586238],\n",
    "        [-1.45262147, -2.34007449],\n",
    "        [ 0.03742712, -0.24127232],\n",
    "        [ 0.2617457 ,  0.51694319],\n",
    "        [ 0.35243035,  0.96434886],\n",
    "        [ 0.17950643,  0.76174137],\n",
    "        [ 1.62739663,  1.42935729]]),\n",
    " np.array([-0.23634795, -0.22072128]),\n",
    " np.array([[-0.53813187, -0.23883808, -0.09825078],\n",
    "        [-1.90591288, -1.13402054, -0.4392717 ]]),\n",
    " np.array([-0.34588157, -0.00713497,  0.35301654])]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Weights of 0th layer\n",
      "Testing biases of 1th layer\n",
      "Testing Weights of 0th layer\n",
      "Testing biases of 1th layer\n"
     ]
    }
   ],
   "source": [
    "student_out = []\n",
    "for i in range(2):\n",
    "    student_out.append( toyModel[i].W)\n",
    "    student_out.append(toyModel[i].b)\n",
    "for i in range(4):\n",
    "    relError = rel_error(student_out[i], expected[i])\n",
    "    if i % 2 == 0:\n",
    "        print('Testing Weights of {}th layer'.format(i%2))\n",
    "    else:\n",
    "        print('Testing biases of {}th layer'.format(i%2))\n",
    "    assert 1e-6 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Build your own model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example which is implemented using previously defined API. In this example, you will use the widely known Wine dataset (https://archive.ics.uci.edu/ml/datasets/wine). Each instance has 13 features as the chemical analysis of wines and you will classify the data where the class number is 3 and each class represents different origin of wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_wine  # Load dataset\n",
    "data = load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names) # Before training, understand your data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 8.625958443570875, Accuracy: 0.09859154929577464\n",
      "Epoch: 0, Test Loss: 5.470136464676513, Test Accuracy: 0.1111111111111111\n",
      "Epoch: 50, Loss: 1.12649196533196, Accuracy: 0.5774647887323944\n",
      "Epoch: 100, Loss: 0.8980940201513027, Accuracy: 0.6690140845070423\n",
      "Epoch: 150, Loss: 0.7544516791371254, Accuracy: 0.7112676056338029\n",
      "Epoch: 200, Loss: 0.6686707778504835, Accuracy: 0.7887323943661971\n",
      "Epoch: 200, Test Loss: 0.8524557519314278, Test Accuracy: 0.6388888888888888\n",
      "Epoch: 250, Loss: 0.6167203350979423, Accuracy: 0.8169014084507042\n",
      "Epoch: 300, Loss: 0.581932071981168, Accuracy: 0.8450704225352113\n",
      "Epoch: 350, Loss: 0.5560392533699753, Accuracy: 0.8732394366197183\n",
      "Epoch: 400, Loss: 0.5352504114885857, Accuracy: 0.8732394366197183\n",
      "Epoch: 400, Test Loss: 0.6925443213045124, Test Accuracy: 0.7777777777777778\n",
      "Epoch: 450, Loss: 0.5177443164137281, Accuracy: 0.8802816901408451\n",
      "Epoch: 500, Loss: 0.5025592902128605, Accuracy: 0.8873239436619719\n",
      "Epoch: 550, Loss: 0.4890606227303331, Accuracy: 0.8873239436619719\n",
      "Epoch: 600, Loss: 0.476789295128826, Accuracy: 0.8873239436619719\n",
      "Epoch: 600, Test Loss: 0.6255447763835764, Test Accuracy: 0.8333333333333334\n",
      "Epoch: 650, Loss: 0.4656258930405093, Accuracy: 0.8943661971830986\n",
      "Epoch: 700, Loss: 0.45535219673465643, Accuracy: 0.9014084507042254\n",
      "Epoch: 750, Loss: 0.4458244056674582, Accuracy: 0.9014084507042254\n",
      "Epoch: 800, Loss: 0.4369429200990285, Accuracy: 0.9014084507042254\n",
      "Epoch: 800, Test Loss: 0.5836067903140666, Test Accuracy: 0.8333333333333334\n",
      "Epoch: 850, Loss: 0.4285325246651959, Accuracy: 0.9014084507042254\n",
      "Epoch: 900, Loss: 0.42059626704497866, Accuracy: 0.9014084507042254\n",
      "Epoch: 950, Loss: 0.41306388183700626, Accuracy: 0.9014084507042254\n"
     ]
    }
   ],
   "source": [
    "X, y = data.data, data.target # Get the features and the corresponding classes\n",
    "model = layer.Model() # Create a model instance\n",
    " \n",
    "# Wine dataset has 13 features, so the input size of first layer is 13. We have 3 classes, so size of last hidden is 3. \n",
    "# Each neuron corresponds the likelihood of a class, named P(y=neuron_index|x), where y is class label \n",
    "# and x is features given.\n",
    "layers = [layer.AffineLayer(13,16), layer.ReLU(), layer.AffineLayer(16,32), layer.ReLU(), layer.AffineLayer(32,3), layer.Softmax()]\n",
    "\n",
    "model(layers) # Load layers to model object\n",
    "predictions  = np.ones(178) # Number of instances in the Wine data is 178\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Shuffle dataset\n",
    "def create_permutation(x, y):\n",
    "    perm = np.random.permutation(len(x))\n",
    "    return x[perm], y[perm]\n",
    "\n",
    "def train_test_split(X, y, ratio=.2):\n",
    "    X, y = create_permutation(X, y)\n",
    "    split_index =  int(len(X) * (1-ratio))\n",
    "    X_train, y_train = X[:split_index], y[:split_index]\n",
    "    X_test, y_test = X[split_index:], y[split_index:]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "\n",
    "# Options\n",
    "preprocessing_on = True\n",
    "shuffle_on_each_epoch = True\n",
    "regularization_strength = 1e-7\n",
    "n_epochs = 1000\n",
    "train_test_split_ratio = .2\n",
    "print_every = 50\n",
    "test_every = 200\n",
    "if preprocessing_on:\n",
    "    X = preprocessing.scale(X)\n",
    "    \n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "\n",
    "optimizer = layer.SGDWithMomentum(model,lr=1e-3, regularization_str=regularization_strength)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    if shuffle_on_each_epoch:\n",
    "        X_train, y_train = create_permutation(X_train, y_train)\n",
    "    softmax_out = model.forward(X_train)\n",
    "\n",
    "    predictions = np.argmax(softmax_out, axis=1)\n",
    "    train_acc = np.mean(predictions == y_train)\n",
    "    loss = layer.loss(softmax_out, y_train)\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(loss)\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss, train_acc))\n",
    "    \n",
    "    model.backward(y_train)\n",
    "    optimizer.optimize()\n",
    "\n",
    "    \n",
    "    if epoch % test_every == 0:\n",
    "            \n",
    "        softmax_out = model.forward(X_test)\n",
    "        predictions = np.argmax(softmax_out, axis=1)\n",
    "        loss = layer.loss(softmax_out, y_test)\n",
    "        test_acc = np.mean(predictions == y_test)\n",
    "        \n",
    "        for i in range(test_every):\n",
    "            test_losses.append(loss)\n",
    "            test_accs.append(test_acc)\n",
    "        #test_accs.append(test_acc)\n",
    "        print(\"Epoch: {}, Test Loss: {}, Test Accuracy: {}\".format(epoch, loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Plot the training and test loss curves for diagnostics below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accs)\n",
    "plt.plot(test_accs)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. Train and plot the training and test loss curves for my activation function:\n",
    "\n",
    "#### Instead of ReLU, I used my activation function for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 9.801890144818271, Accuracy: 0.14084507042253522\n",
      "Epoch: 0, Test Loss: 6.545681783198762, Test Accuracy: 0.3888888888888889\n",
      "Epoch: 50, Loss: 0.5866244994709019, Accuracy: 0.7323943661971831\n",
      "Epoch: 100, Loss: 0.5801067993752862, Accuracy: 0.7323943661971831\n",
      "Epoch: 150, Loss: 0.5755958798005253, Accuracy: 0.7394366197183099\n",
      "Epoch: 200, Loss: 0.5709057987174938, Accuracy: 0.7394366197183099\n",
      "Epoch: 200, Test Loss: 1.3591773651942232, Test Accuracy: 0.6388888888888888\n",
      "Epoch: 250, Loss: 0.5505589790149062, Accuracy: 0.7394366197183099\n",
      "Epoch: 300, Loss: 0.5336565380927297, Accuracy: 0.7464788732394366\n",
      "Epoch: 350, Loss: 0.3756222492395582, Accuracy: 0.7464788732394366\n",
      "Epoch: 400, Loss: 0.36969017634839685, Accuracy: 0.9295774647887324\n",
      "Epoch: 400, Test Loss: 1.0777062628025653, Test Accuracy: 0.8888888888888888\n",
      "Epoch: 450, Loss: 0.3659646805285599, Accuracy: 0.9295774647887324\n",
      "Epoch: 500, Loss: 0.36272226009811465, Accuracy: 0.9295774647887324\n",
      "Epoch: 550, Loss: 0.3598270168331879, Accuracy: 0.9295774647887324\n",
      "Epoch: 600, Loss: 0.3570966104482561, Accuracy: 0.9295774647887324\n",
      "Epoch: 600, Test Loss: 1.062029110648989, Test Accuracy: 0.8888888888888888\n",
      "Epoch: 650, Loss: 0.35464609467518127, Accuracy: 0.9295774647887324\n",
      "Epoch: 700, Loss: 0.35224700089537275, Accuracy: 0.9295774647887324\n",
      "Epoch: 750, Loss: 0.3501475478169447, Accuracy: 0.9295774647887324\n",
      "Epoch: 800, Loss: 0.3479827969382654, Accuracy: 0.9295774647887324\n",
      "Epoch: 800, Test Loss: 1.04729172047595, Test Accuracy: 0.8888888888888888\n",
      "Epoch: 850, Loss: 0.34613229061644757, Accuracy: 0.9295774647887324\n",
      "Epoch: 900, Loss: 0.3441951743994025, Accuracy: 0.9295774647887324\n",
      "Epoch: 950, Loss: 0.34243121570408647, Accuracy: 0.9295774647887324\n"
     ]
    }
   ],
   "source": [
    "X, y = data.data, data.target # Get the features and the corresponding classes\n",
    "model = layer.Model() # Create a model instance\n",
    " \n",
    "layers = [layer.AffineLayer(13,16), layer.YourActivation(), layer.AffineLayer(16,32), layer.YourActivation(), layer.AffineLayer(32,3), layer.Softmax()]\n",
    "\n",
    "model(layers) # Load layers to model object\n",
    "predictions  = np.ones(178) # Number of instances in the Wine data is 178\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Shuffle dataset\n",
    "def create_permutation(x, y):\n",
    "    perm = np.random.permutation(len(x))\n",
    "    return x[perm], y[perm]\n",
    "\n",
    "def train_test_split(X, y, ratio=.2):\n",
    "    X, y = create_permutation(X, y)\n",
    "    split_index =  int(len(X) * (1-ratio))\n",
    "    X_train, y_train = X[:split_index], y[:split_index]\n",
    "    X_test, y_test = X[split_index:], y[split_index:]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "\n",
    "# Options\n",
    "preprocessing_on = True\n",
    "shuffle_on_each_epoch = True\n",
    "regularization_strength = 1e-7\n",
    "n_epochs = 1000\n",
    "train_test_split_ratio = .2\n",
    "print_every = 50\n",
    "test_every = 200\n",
    "if preprocessing_on:\n",
    "    X = preprocessing.scale(X)\n",
    "    \n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "\n",
    "optimizer = layer.SGDWithMomentum(model,lr=1e-3, regularization_str=regularization_strength)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    if shuffle_on_each_epoch:\n",
    "        X_train, y_train = create_permutation(X_train, y_train)\n",
    "    softmax_out = model.forward(X_train)\n",
    "\n",
    "    predictions = np.argmax(softmax_out, axis=1)\n",
    "    train_acc = np.mean(predictions == y_train)\n",
    "    loss = layer.loss(softmax_out, y_train)\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(loss)\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss, train_acc))\n",
    "    \n",
    "    model.backward(y_train)\n",
    "    optimizer.optimize()\n",
    "\n",
    "    \n",
    "    if epoch % test_every == 0:\n",
    "            \n",
    "        softmax_out = model.forward(X_test)\n",
    "        predictions = np.argmax(softmax_out, axis=1)\n",
    "        loss = layer.loss(softmax_out, y_test)\n",
    "        test_acc = np.mean(predictions == y_test)\n",
    "        \n",
    "        for i in range(test_every):\n",
    "            test_losses.append(loss)\n",
    "            test_accs.append(test_acc)\n",
    "        #test_accs.append(test_acc)\n",
    "        print(\"Epoch: {}, Test Loss: {}, Test Accuracy: {}\".format(epoch, loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accs)\n",
    "plt.plot(test_accs)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV5bX/8c9iHgIiECBMAooKOABGnL1VxFqrgq04tLVUrdS21qG9t7W9v1a9vW2183DbKrUojoBWKq1aReoEKhIGUURlCmOAMI8h0/r9sXf0iCfJybDPPsn5vl+v8zpnzys7sM6TZ++9HnN3REQke7SIOwAREUkvJX4RkSyjxC8ikmWU+EVEsowSv4hIllHiFxHJMkr8Ig1kZl80s+cj2vc9ZvbDKPYt2UuJXzKemRWaWamZdT9k/mIzczMb0IB93xHuY1SK6w8I129VNc/dH3H38+sbQ8K+v2JmcxLnufsN7v7jhu5bJJESvzQVq4GrqibM7HigfUN2aGYGXA1sByY0KDqRJkSJX5qKh4AvJ0xPAB6smjCzk81sc2JL3Mw+b2aLa9jnWUBv4GbgSjNrk7BtezP7lZmtMbNdZjbHzNoDr4Sr7DSzvWZ2WmJLPeya+WXiQczsKTP7dvj5NjNbaWZ7zOxdM7s0nD8EuAc4LdzvznD+A2b2vwn7ut7MVpjZdjObaWa9E5a5md1gZsvNbIeZ/TH8chP5GCV+aSreADqb2RAzawlcATxctdDd5wPbgDEJ23yJ4AujOhOAfwDTwumLEpb9EjgJOB3oCnwXqATODpd3cfccd3/9kH0+ClxRlXDN7HDgfGBquHwlwRfOYcCdwMNmlufuy4AbgNfD/XY5NFgzOxf4GXA5kAesSdhvlYuAk4ETw/U+XcPPL1lKiV+akqpW/xjgPWDDIcunECR7zKwrQdJ7NNmOzKwDMB541N3LgCcIu3vMrAVwLXCzu29w9wp3f83dD6YQ46uAEyR3gMsIkvlGAHd/3N03unulu08DlgMpXV8AvghMdveFYSzfJ/gLYUDCOne5+053Xwu8CAxPcd+SRVrVvopIxniIoKtlIAndPAkeBpaZWQ5Ba/dVdy+qZl+XAuXAM+H0I8ALZpYLGNCOoHVeJ+7uZjaV4HrEK8AXSPjLxMy+DHwbGBDOygG6k5rewMKEY+01s21AH6AwnL0pYf394f5FPkYtfmky3H0NwUXeC4EnkyzfALxOkNSvpvZunhxgrZltAh4HWhMk7K1ACXBksjBSCPUx4DIzOwI4BfgbQDj9F+BGoFvYnfMOwRdNKvveCBxRNWFmHYFufPIvH5EaKfFLU3MdcK6776tm+YME/fHHAzOSrWBmfYDRBP3hw8PXicDdwAR3rwQmA782s95m1jK8iNsWKCbo6x9UXYDuvihc7z7gOXffGS7qSJDci8M4rgGOS9h0M9A38SLzIR4FrjGz4WEsPwXmuXthdbGIJKPEL02Ku69094IaVplB0CqeUcOXw9XAYnd/3t03Vb2A3wMnmNlxwH8CbwPzCW73vBto4e77gZ8Ac81sp5mdWs0xHgPOI+Eag7u/C/yK4K+SzQRfTnMTtvk3sBTYZGZbk/zss4EfEvwFUUTwF8mVNZwLkaRMA7FIc2NmK4GvufsLcccikonU4pdmxcw+T9Cd8u+4YxHJVLqrR5oNM3sJGApcHfbTi0gS6uoREcky6uoREckyTaKrp3v37j5gwIC4wxARaVIWLFiw1d1zD53fJBL/gAEDKCio6Q4+ERE5lJmtSTZfXT0iIllGiV9EJMso8YuIZBklfhGRLKPELyKSZZT4RUSyjBK/iEiWUeIXEclA+0vLufMfS1mzrbrq4vUXaeI3s1vNbKmZvWNmj5lZOzPramazzGx5+H54lDGIiDRFTy8p4v65hWzZk8pQz3UTWeIPRzm6Cch39+OAlgSDRtwGzHb3wcDscFpERBJML1jHoNyO5B/R+G3jqLt6WgHtzawV0IFgzNCxwJRw+RRgXMQxiIg0KSuL9zK/cAeX5/fDzGrfoI4iS/zhwNe/BNYSDBO3y92fB3q6e1G4ThHQI9n2ZjbRzArMrKC4uDiqMEVEMs70gnW0bGF8bmSfSPYfZVfP4QSt+4FAb6CjmX0p1e3dfZK757t7fm7uJ4rLiYg0S2UVlfxtwQbOOaYHPTq1i+QYUXb1nAesdvdidy8DngROBzabWR5A+L4lwhhERJqUl94vZuveg1xxcr/IjhFl4l8LnGpmHSzopBoNLANmAhPCdSYAT0UYg4hIkzJt/jpyO7XlnGOi6+mIrB6/u88zsyeAhUA5sAiYBOQA083sOoIvh/FRxSAi0pRs2V3Ci+9v4fqzBtGqZXTt8kgHYnH324HbD5l9kKD1LyIiCf62cAMVlc7l+X0jPY6e3BURyQDuzuMF6xg1oCuDcnMiPZYSv4hIBihYs4NVW/cxPuLWPijxi4hkhGnz15HTthWfPSEv8mMp8YuIxGxPSRlPLyni4hPz6NAm0kuvgBK/iEjs/rmkiANlFVyeH929+4mU+EVEYjZt/jqO7pnD8H5d0nI8JX4RkRh9sHkPi9ftjKwgWzJK/CIiMZo+fx2tWxqXjoimIFsySvwiIjEpLa/kyUUbOG9IT7rltE3bcZX4RURiMnvZZrbvK+XyCAuyJaPELyISk2kF68g7rB1nD05v6XklfhGRGBTtOsArHxRz2Ul9adkiPRd1qyjxi4jE4ImC9VQ6jD8pvd08oMQvIpJ2lZXO4wvWc9qgbvTv1iHtx1fiFxFJszdWb2Pt9v2RjrJVkyjH3D3GzBYnvHab2S1m1tXMZpnZ8vD98KhiEBHJRNPnr6NTu1ZccFyvWI4fWeJ39/fdfbi7DwdOAvYDM4DbgNnuPhiYHU6LiGSFXQfKePadTYwb3od2rVvGEkO6unpGAyvdfQ0wFpgSzp8CjEtTDCIisZu5eAMHyytj6+aB9CX+K4HHws893b0IIHzvkWwDM5toZgVmVlBcXJymMEVEojWtYB1D8jozrHfn2GKIPPGbWRvgEuDxumzn7pPcPd/d83Nz0/twg4hIFJZu3MU7G3ZzRX7ftBVkSyYdLf7PAAvdfXM4vdnM8gDC9y1piEFEJHaPF6ynTasWjEtjQbZk0pH4r+Kjbh6AmcCE8PME4Kk0xCAiEquSsgpmLNrAp4f1okuHNrHGEmniN7MOwBjgyYTZdwFjzGx5uOyuKGMQEckEz7+7mV0HyrgiTaNs1STSwR3dfT/Q7ZB52wju8hERyRrT56+jT5f2nH5kt9pXjpie3BURidi67fuZs2Ir4/P70iLNBdmSUeIXEYnYEwvWYwbjM6CbB5T4RUQiVVHpPLFgPWce1Z0+XdrHHQ6gxC8iEqm5K7ayYeeBWJ/UPZQSv4hIhKYVrOPwDq0ZM7Rn3KF8SIlfRCQiO/aVMmvpZsaN6EPbVvEUZEtGiV9EJCIzFm2gtKKSyzPkom4VJX4RkQi4O9ML1nFC38MYkhdfQbZklPhFRCLw1vpdvLdpT8a19kGJX0QkEvfPXU1O21aMHd477lA+QYlfRKSRbdpVwtNLirji5H50atc67nA+QYlfRKSRPfRGIZXufOX0AXGHkpQSv4hIIzpQWsGj89YyZmhP+nXtEHc4SSnxi4g0or8v3sCO/WVce8bAuEOplhK/iEgjcXcmz1nNsN6dGTWwa9zhVCvqgVi6mNkTZvaemS0zs9PMrKuZzTKz5eH74VHGICKSLnNWbGX5lr1ce8bAWMfUrU3ULf7fAf9y92OBE4FlwG3AbHcfDMwOp0VEmrzJc1bTPactF52YF3coNYos8ZtZZ+Bs4K8A7l7q7juBscCUcLUpwLioYhARSZeVxXt58f1irj71iIyqy5NMlC3+QUAxcL+ZLTKz+8ysI9DT3YsAwvceyTY2s4lmVmBmBcXFxRGGKSLScA/MLaRNyxZ88dT+cYdSqygTfytgJPBndx8B7KMO3TruPsnd8909Pzc3N6oYRUQabNf+Mp5YsJ6xw3vTPadt3OHUKsrEvx5Y7+7zwuknCL4INptZHkD4viXCGEREIjd1/loOlFVwTQbfwpkossTv7puAdWZ2TDhrNPAuMBOYEM6bADwVVQwiIlErr6hkymuFnDaoG0N7Z1YVzuq0inj/3wIeMbM2wCrgGoIvm+lmdh2wFhgfcQwiIpF5bulmNu4q4c6xx8UdSsoiTfzuvhjIT7JodJTHFRFJl8lzV3NEtw6ce2zS+1Qykp7cFRGpp8XrdrJgzQ6+cvoAWrbI3Ae2DqXELyJST/fPXU2ntq0Yn4GDrdREiV9EpB6qau5ffnI/ctpGfbm0cdWa+M3sZjPrbIG/mtlCMzs/HcGJiGSqTK+5X5NUWvzXuvtu4Hwgl+DOnLsijUpEJIM1hZr7NUkl8VddsbgQuN/d30qYJyKSdZpCzf2apJL4F5jZ8wSJ/zkz6wRURhuWiEhmaio192uSyhWJ64DhwCp3329m3Qi6e0REsk5Vzf1fjT8xo2vu1ySVFr8DQ4GbwumOQLvIIhIRyWCT56wmt1Pm19yvSSqJ/0/AacBV4fQe4I+RRSQikqGaUs39mqTS1XOKu480s0UA7r4jrL0jIpJVHphbSJtWLfjCKZlfc78mqbT4y8ysJUGXD2aWiy7uikiWqaq5P66J1NyvSSqJ//fADKCHmf0EmAP8NNKoREQyzGNNrOZ+TWrt6nH3R8xsAUFFTQPGufuyyCMTEckQZWHN/dOP7MaQvKZRc78mqZRs6A/sB/5BMIjKvnCeiEhWeG7pJop2lTTZB7YOlcrF3acJ+veN4DbOgcD7wLAI4xIRyRiT5zS9mvs1SaWr5/jEaTMbCXwtlZ2bWSHB7Z8VQLm755tZV2AaMAAoBC539x11ilpEJE0Wrd3BwrU7uePiobRoQjX3a1LnsszuvhA4uQ6bnOPuw929aiSu24DZ7j4YmB1Oi4hkpPvnFtKpbSsua2I192tSa4vfzL6dMNkCGAkUN+CYY4FPhZ+nAC8B32vA/kREIlG06wDPvF3EV04f0ORq7tcklRZ/p4RXW4I+/7Ep7t+B581sgZlNDOf1dPcigPA9aaeZmU00swIzKygubsj3jIhI/Tz0+hoq3ZnQBGvu1ySVPv47G7D/M9x9o5n1AGaZ2Xupbujuk4BJAPn5+d6AGERE6uxAaQWPvrmW84f2apI192tSbeI3s38QPq2bjLtfUtvO3X1j+L7FzGYAo4DNZpbn7kVmlgdsqXvYIiLRmjp/LTv3l3Htmc3jFs5ENbX4f9mQHZtZR6CFu+8JP58P/A/BswATCEbxmgA81ZDjiIg0tpKyCv700kpOHdS1ydbcr0m1id/dX27gvnsCM8J61a2AR939X2Y2H5huZtcBa4HxDTyOiEijeviNNRTvOcj/XTUi7lAikcpdPYOBnxHU5P+wDr+7D6ppO3dfBZyYZP42gvIPIiIZZ39pOfe8vJIzjurGKYO6xR1OJFK5q+d+4M9AOXAO8CDwUJRBiYjE5eE31rB1bym3nnd03KFEJpXE397dZwPm7mvc/Q7g3GjDEhFJv/2l5dz78irOGtyd/AHNr2+/SipPJJSYWQtguZndCGygmnvvRUSasgdfX8O2faXc0oxb+1BDi9/MeoYfbwE6EIy5exLwJYK7cUREmo29B8u59+WV/MfRuZx0xOFxhxOpmlr8b5nZ28BjwAfuvh64Jj1hiYik15TXCtmxv4xbxzTv1j7U3Mffh+Be/rOAD8zs72Z2hZm1T09oIiLpsaekjL+8uopzjslleL8ucYcTuWoTv7tXuPtz7n4N0I/g7p5xwGozeyRdAYqIRG3Ka4XszJLWPqRYltndS4F3gWXAboJ7+kVEmrzdJWVMemUV5w3pwQl9m39rH2pJ/GbW38z+y8wWAv8EWgJj3b15Ps4mIlnn/jmF7C4pb/Z38iSqqUjbawT9/I8DE929IG1RiYikwa4DZdw3ZxVjhvbkuD6HxR1O2tR0V8/3gVfcXSWRRaRZmjxnNXtKyrnlvMFxh5JWURZpExHJWLv2lzF5zmouGNaLYb2zp7UP9RhzV0SkObhvzir2HCzn5ixr7YMSv4hkoZ37S7l/biEXHt+LIXmd4w4n7Wq6uPvt6pYBuPuvGz8cEZHo/eXVVewrLefm0dlzJ0+imlr8VQOs5wNfJ7jDpw9wA3W4j9/MWprZIjP7Zzjd1cxmmdny8L15F8UQkYyyfV8pD8wt5LPH53FMr05xhxOLmp7cvTMcaL07MNLdv+Pu3yEo1Na3Dse4meDBryq3AbPdfTAwO5wWEUmLSa+sYn9ZBTePzr6+/Sqp9PH3B0oTpkuBAans3Mz6Ap8F7kuYPRaYEn6eQlAGQkQkclv3HuTB1wu5+ITeDO6Zna19SK0e/0PAm2Y2A3DgUoJRuFLxW+C7BF1GVXq6exGAuxeZWdLa/mY2EZgI0L9//xQPJyJSvUmvrKKkrIKbsri1Dym0+N39JwTlmHcAO4Fr3P2ntW1nZhcBW9x9QX0Cc/dJ7p7v7vm5ubn12YWIyIeK9wSt/bHD+3BUj5y4w4lVKi1+CAZi2e3u95tZrpkNdPfVtWxzBnCJmV1IMEh7ZzN7GNhsZnlhaz8P2FL/8EVEUnPvyyspLa/kW+ceFXcosau1xW9mtwPfIyjhANAaeLi27dz9++7e190HAFcC/3b3LwEz+WgErwnAU/WIW0QkZVt2l/DQG2sYN6IPg3Kzu7UPqV3cvRS4BNgH4O4b+XiffV3dBYwxs+XAmHBaRCQyf355JeWVzk3nZnfffpVUunpK3d3NzAHMrGNdD+LuLwEvhZ+3AaPrug8RkfrYvLuER+at5XMj+jCge53TV7OUSot/upndC3Qxs+uBF/j47ZkiIhnrzy+tpLLS+ZZa+x+qtcXv7r80szEEI28dA/zI3WdFHpmISAMV7TrAo/PW8vmRfenfrUPc4WSMWhO/md3t7t8DZiWZJyKSsf704koq3blRd/J8TCpdPWOSzPtMYwciItKYNuw8wLT56xif349+XdXaT1RTdc6vA98ABpnZkoRFnYC5UQcmItIQP316GWaotZ9ETV09jwLPAj/j44XU9rj79kijEhFpgDnLt/L020V8e8zR9OnSPu5wMk5NQy/uAnYBVwGENXXaATlmluPua9MToohI6krLK7l95jv079qBiWcPijucjJTKk7sXhw9brQZeBgoJ/hIQEck4989dzcrifdx+8VDatW4ZdzgZKZWLu/8LnAp84O4DCR6+Uh+/iGScTbtK+P3s5Yw+tgejh/SMO5yMlUriLwuftm1hZi3c/UVgeMRxiYjU2U+fWUZZpXP7xcPiDiWjpVKyYaeZ5QCvAI+Y2RagPNqwRETq5vWV25j51kZuGj1YD2vVIpUW/1hgP3Ar8C9gJXBxlEGJiNRFWUVwQbfv4e35xqeOjDucjJdKi38i8Li7r+ejIRNFRDLGg6+v4YPNe7n36pN0QTcFqbT4OwPPmdmrZvZNM9MVExHJGFv2lPDbWR/wH0fncv5QpadUpDL04p3uPgz4JtAbeNnMXog8MhGRFNz1zHscLK/kjkuGYWZxh9MkpNLir7IF2ARsA5IOkC4ikk7zC7fz5KINXH/2QAaq1n7KUnmA6+tm9hIwG+gOXO/uJ6SwXTsze9PM3jKzpWZ2Zzi/q5nNMrPl4fvhDf0hRCT7lFdU8sO/v0Pvw9rxzXNUj6cuUrm4ewRwi7svruO+DwLnuvteM2sNzDGzZ4HPAbPd/S4zu42gDpBKPItInTwyby3vbdrDn744kg5tUkllUqXaFr+ZdQ4//hxYG7bUP3zVtmMP7A0nW4cvJ7g9tOruoCnAuHpHLyJZaeveg/zy+fc586jufOa4XnGH0+TUVp3zImABQcJOvGriQK3Vj8ysZbj9UcAf3X2emfV09yIAdy8Ki78l23Yiwa2k9O/fP4UfRUSyxd3PvkdJWYUu6NZTTdU5LwrfB9Z35+5eAQw3sy7ADDM7rg7bTgImAeTn53t9YxCR5mXh2h08vmA9X/uPQRzVIyfucJqkVC7uzk5lXk3cfSfwEnABsNnM8sL95BHcLSQiUquKSudHT71Dz85tNXh6A9TUx98u7MvvbmaHJ/TvDyC4n79GZpYbtvQxs/bAecB7wExgQrjaBOCphv0IIpItHntzLe9s2M1/f3YoOW11Qbe+ajpzXwNuIUjyC/ioj3838McU9p0HTAn7+VsA0939n2b2OjDdzK4D1gLj6xu8iGSP7ftK+cVz73PaoG5cfEJe3OE0aTX18f8O+J2Zfcvd/1DXHbv7EmBEkvnbCGr6i4ik7BfPvc++g+XcOVYXdBsqlSd3K6u6bADCbp9vRBiTiMjHLFm/k6nz1/KV0wdwdM9OcYfT5KWS+K8PL84C4O47gOujC0lE5COVlc4Pn1pK95y23HyeLug2hlQSfwtL+Lsq7LNvE11IIiIfmV6wjrfW7eQHFx5Lp3at4w6nWUjlsvhzBBdj7yF4cOsGggFZREQitXN/KXf/6z1GDejKuOF94g6n2Ugl8X+P4AnarxPc2fM88JcogxIRAfjV8x+wu0QXdBtbKvX4K939Hne/zN0/DywF6nyXj4hIXby1biePzFvD1acewZC8zrVvIClL6QkIMxsOXAVcAawGnowyKBHJbntKyrhp6iJ6dW7HrWOOjjucZqfaxG9mRwNXEiT8bcA0wNz9nDTFJiJZyN354d/fYd32/UydeBqHtdcF3cZWU4v/PeBV4GJ3XwFgZremJSoRyVpPLtzA3xdv5NbzjmbUwForwEs91NTH/3mCoRZfNLO/mNloPl6aWUSkUa0q3ssPn3qHUQO7cuO5GlUrKtUmfnef4e5XAMcSVNa8FehpZn82s/PTFJ+IZImD5RV867FFtGnVgt9dOZyWLdTOjEoqd/Xsc/dHwvr8fYHFBMMliog0mruffZ+lG3fz88+fQN5h7eMOp1lL5cndD7n7dne/193PjSogEck+/35vM5PnrmbCaUdw/jANpRi1OiV+EZHGtnl3Cf/5+BKO7dWJ7184JO5wsoISv4jEpqLSuXXaYg6UVvB/XxhBu9Yt4w4pK0SW+M2sn5m9aGbLzGypmd0czu9qZrPMbHn4fnhUMYhIZrvn5ZW8tnIbd1wylKN6qNxyukTZ4i8HvuPuQ4BTgW+a2VCCC8Oz3X0wMBtdKBbJSgvW7ODXsz7gohPyuDy/X9zhZJXIEr+7F7n7wvDzHmAZ0AcYC0wJV5sCjIsqBhHJTLsOlHHTY4vIO6wdP/3c8SrAlmZp6eMPB2gfAcwDerp7EQRfDkCParaZaGYFZlZQXFycjjBFJA3cnR88+Tabdpfw+6tG0Fk19tMu8sRvZjnA34Bb3H13qtu5+yR3z3f3/Nzc3OgCFJG0mjZ/HU+/XcR3zj+akf11iS8OkSZ+M2tNkPQfcfeqip6bzSwvXJ4HbIkyBhHJHMs37+GOfyzljKO6ccPZR8YdTtaK8q4eA/4KLHP3XycsmglMCD9PAJ6KKgYRyRwlZUFJho5tWvGby4fTQiUZYpNSPf56OgO4GnjbzBaH834A3EUwlON1wFpgfIQxiEiG+MnTy3hv0x7uv+ZkenRuF3c4WS2yxO/uc6i+mufoqI4rIpnnuaWbeOiNNXz1zIGcc0zS+zkkjfTkrohEauPOA3z3iSUc16cz/3XBMXGHIyjxi0iEyisquWXqYsorKvnDVSNp20olGTJBlH38IpLl/vDvFbxZuJ1fX34iA7t3jDscCanFLyKReOn9Lfzh38u5dEQfPjeyb9zhSAIlfhFpdPMLt3PDwws4pldnfjzuuLjDkUMo8YtIo3pnwy6uvX8+vQ9rz0PXjSKnrXqUM40Sv4g0mpXFe5kw+U06tWvFQ189he45beMOSZJQ4heRRrFh5wGuvm8eAA9/9RT6dNG4uZlKf4OJSIMV7znIl+6bx56D5UydeCqDcnPiDklqoBa/iDTIrv1lfHnym2zaVcL9XzmZYb0PizskqYUSv4jU2/7Scq554E1WbNnDvVefRP6ArnGHJClQ4heRejlYXsHXHlrA4nU7+f2VIzj7aI2b0VSoj19E6qy8opKbH1vMq8u38vPLTuAzx+fFHZLUgVr8IlInlZXObU++zb+WbuJHFw3VQOlNkBK/iKTM3fmff77LEwvWc8t5g7n2zIFxhyT1EOUIXJPNbIuZvZMwr6uZzTKz5eG7BtwUaUJ++8JyHnitkGvPGMjNowfHHY7UU5Qt/geACw6Zdxsw290HA7PDaRFpAu57dRW/m72cy/P78sOLhhCMripNUWSJ391fAbYfMnssMCX8PAUYF9XxRaTxTJ+/jv99ehkXHt+Ln33uBCX9Ji7dffw93b0IIHzXGGwiGe6Zt4u47cklnH10Lr+5YjgtNUh6k5exF3fNbKKZFZhZQXFxcdzhiGSllz8o5uapixjZ/3Du+ZJG0Gou0p34N5tZHkD4vqW6Fd19krvnu3t+bq4eDBFJtxfe3czXHipgcI9O/PUrJ9OhjR77aS7SnfhnAhPCzxOAp9J8fBGpRXlFJT97dhlffbCAI3NzePC6URzWvnXcYUkjiuwr3MweAz4FdDez9cDtwF3AdDO7DlgLjI/q+CJSd5t3l/CtRxfxZuF2vnBKf3500VDatVb3TnMTWeJ396uqWTQ6qmOKSP29tmIrN01dxL6DFfz2iuGMG9En7pAkIuq0E8lylZXOH19cwW9e+IBBuTk8dv1IBvfsFHdYEiElfpEstn1fKbdOW8zLHxQzbnhvfnLp8XTUGLnNnn7DIllqwZod3PjoQrbtLeUnlx7HF0b114NZWUKJXyTLuDuT5xbys2eW0btLe578xukc10ejZmUTJX6RLLK7pIzvPr6Efy3dxPlDe/KL8SfqVs0spMQvkiWWbtzFNx5ZyIYdB/h/nx3CdWcOVNdOllLiF2nm3J2p89dx+8yldO3QhqkTT9XYuFlOiV+kGdtfWs7/m/EOTy7awFmDu/PbK4bTLadt3GFJzJT4RZohd+e1ldu48x9LWb5lL7eedzQ3nnuUKmsKoMQv0qyUV1Ty9NtFTHplFUs37qZHp7Y8eO0ozhqsQofyESV+kWZg38Fyps1fx1/nrGbDzgMcmduRuz9/PGF2zdsAAAjBSURBVGOH91GtHfkEJX6RJmzLnhIemFvIw2+sYXdJOaMGdOXOS4Zx7rE9aKFuHamGEr9IE7Riy17ue3UVTy7cQFllJRcM68XEswcxov/hcYcmTYASv0gT4e4UrNnBvS+v4oVlm2nbqgWXn9yXr545iAHdO8YdnjQhSvwiGa6i0pn17ibufWUVi9bu5PAOrbl59GC+fNoRujVT6kWJXyQDlVVUsnb7fl5buY2/vrqKwm376d+1Az8eO4zLTupH+za6YCv1F0viN7MLgN8BLYH73P2uOOIQiZO7s21fKauK97GqeC+rtobvxftYu30/5ZUOwIn9uvCnC47l08N66T58aRRpT/xm1hL4IzAGWA/MN7OZ7v5uumMRSYeSsgrWbNv/YXJfGSb3VcV72V1S/uF6bVq1YGC3jhzTqxMXHNeLQbk5HNurE8N6d1ZNHWlUcbT4RwEr3H0VgJlNBcYCjZ74/zB7OTPf2tjYuxVJ2YGyCjbuPEDYeAegV+d2DMrtyCXDezOoew6DcjtyZG4Ovbu0V4te0iKOxN8HWJcwvR445dCVzGwiMBGgf//+9TpQbqe2DO6ZU69tRRpDm5YtOGJk3w+T+8DuHTXClcQujn+ByZo0/okZ7pOASQD5+fmfWJ6KK0f158pR9fvSEBFprlrEcMz1QL+E6b6A+mNERNIkjsQ/HxhsZgPNrA1wJTAzhjhERLJS2rt63L3czG4EniO4nXOyuy9NdxwiItkqlqtM7v4M8EwcxxYRyXZxdPWIiEiMlPhFRLKMEr+ISJZR4hcRyTLmXq9no9LKzIqBNfXcvDuwtRHDaWyKr2EUX8MovobL5BiPcPdPDLjcJBJ/Q5hZgbvnxx1HdRRfwyi+hlF8DdcUYjyUunpERLKMEr+ISJbJhsQ/Ke4AaqH4GkbxNYzia7imEOPHNPs+fhER+bhsaPGLiEgCJX4RkSzTLBK/mY03s6VmVmlm+Ycs+76ZrTCz983s09Vs39XMZpnZ8vD98AhjnWZmi8NXoZktrma9QjN7O1yvIKp4khz3DjPbkBDjhdWsd0F4TleY2W1pjO8XZvaemS0xsxlm1qWa9dJ6/mo7Hxb4fbh8iZmNjDqmhGP3M7MXzWxZ+P/k5iTrfMrMdiX83n+UrvjC49f4+4r5/B2TcF4Wm9luM7vlkHViPX915u5N/gUMAY4BXgLyE+YPBd4C2gIDgZVAyyTb/xy4Lfx8G3B3muL+FfCjapYVAt1jOJd3AP9Zyzotw3M5CGgTnuOhaYrvfKBV+Pnu6n5X6Tx/qZwP4ELgWYIR6E4F5qXxd5oHjAw/dwI+SBLfp4B/pvvfW6q/rzjPX5Lf9SaCB6My5vzV9dUsWvzuvszd30+yaCww1d0PuvtqYAXBYO/J1psSfp4CjIsm0o+YmQGXA49FfawIjAJWuPsqdy8FphKcw8i5+/PuXh5OvkEwglvcUjkfY4EHPfAG0MXM8tIRnLsXufvC8PMeYBnB2NdNSWzn7xCjgZXuXt9KAhmhWST+GiQb2D3ZP/ie7l4EwX8SoEcaYjsL2Ozuy6tZ7sDzZrYgHHg+nW4M/5yeXE23V6rnNWrXErQCk0nn+UvlfGTEOTOzAcAIYF6SxaeZ2Vtm9qyZDUtrYLX/vjLi/BGMGFhdYy3O81cnsQzEUh9m9gLQK8mi/3b3p6rbLMm8yO9fTTHWq6i5tX+Gu280sx7ALDN7z91fiTo+4M/AjwnO048JuqOuPXQXSbZttPOayvkzs/8GyoFHqtlNZOcviVTORyz/Fj8WgFkO8DfgFnfffcjihQTdF3vD6zp/BwanMbzafl+ZcP7aAJcA30+yOO7zVydNJvG7+3n12CzVgd03m1meuxeFfz5uqU+MVWqL1cxaAZ8DTqphHxvD9y1mNoOgO6FREleq59LM/gL8M8miVM9rvaRw/iYAFwGjPexgTbKPyM5fEqmcj0jPWW3MrDVB0n/E3Z88dHniF4G7P2NmfzKz7u6eluJjKfy+Yj1/oc8AC91986EL4j5/ddXcu3pmAleaWVszG0jwDfxmNetNCD9PAKr7C6KxnAe85+7rky00s45m1qnqM8EFzXcijqnq2In9ppdWc9z5wGAzGxi2gq4kOIfpiO8C4HvAJe6+v5p10n3+UjkfM4Evh3ennArsqupejFp4PemvwDJ3/3U16/QK18PMRhHkhm1pii+V31ds5y9BtX+lx3n+6iXuq8uN8SJIUOuBg8Bm4LmEZf9NcMfF+8BnEubfR3gHENANmA0sD9+7RhzvA8ANh8zrDTwTfh5EcGfIW8BSgi6OdJ3Lh4C3gSUE/9nyDo0vnL6Q4O6QlWmObwVBX+/i8HVPJpy/ZOcDuKHq90zQVfHHcPnbJNx9lobYziToFlmScN4uPCS+G8Nz9RbBRfPT0xhf0t9Xppy/8PgdCBL5YQnzMuL81eelkg0iIlmmuXf1iIjIIZT4RUSyjBK/iEiWUeIXEckySvwiIllGiV8EMLPXItjnADP7QmPvV6ShlPhFAHc/PYLdDgCU+CXjKPGLAGa2N3z/lJm9ZGZPWFD3/5GEJzILzexuM3szfB0Vzn/AzC47dF/AXcBZYX32W81sWLjd4rAIXsbWcpHmTYlf5JNGALcQjOcwCDgjYdludx8F/B/w21r2cxvwqrsPd/ffEDzp+Tt3Hw7kEzxtLpJ2Svwin/Smu69390qC8gYDEpY9lvB+Wh33+zrwAzP7HkElxwMNjlSkHpT4RT7pYMLnCj5exdaTfC4n/L8Udgu1SbZTd3+UoKzvAeA5Mzu3sQIWqQslfpG6uSLh/fXwcyEfldgeC7QOP+8hGOoQADMbBKxy998TFMA7IepgRZJpMvX4RTJEWzObR9Bouiqc9xfgKTN7k6C6675w/hKg3MzeIqjI2g74kpmVEYzb+j/pDFykiqpziqTIzAoJygFn5OAaIqlSV4+ISJZRi19EJMuoxS8ikmWU+EVEsowSv4hIllHiFxHJMkr8IiJZ5v8DuHFOAYdT1MAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myData = [i for i in range(-10,10)]\n",
    "\n",
    "myAct = layer.YourActivation()\n",
    "out = myAct.forward(myData)\n",
    "plt.plot(myData, out)\n",
    "plt.title('My Activation')\n",
    "plt.ylabel('Activated Values')\n",
    "plt.xlabel('inputs')\n",
    "plt.show()\n",
    "# My Activation Funtion is plotted. Negatives are zero, positives are squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II - Book Genre Classification\n",
    "\n",
    "Now, in this part, you will work with text data (https://arxiv.org/pdf/1610.09204.pdf) for book genre analysis. Originally, the dataset is used for book genre classification by the book cover image. In this part, you will classify the books into their genres by their titles. The total number of genres for the books to be classified into is 32.\n",
    "\n",
    "Below, we already implemented the preprocessing codes fro the data. Run the below cells and load the text data \"book32-listing.csv\" into an appropriate form. You will need to use batch-wise optimizer since it is almost impossible to fit all the data at once.\n",
    "\n",
    "**IMPORTANT: You are NOT allowed to use sklearn or any other implementations for the learning part\n",
    ". You are ALLOWED ONLY TO USE your own implementation from the above steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Image_link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Class</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761183272</th>\n",
       "      <td>0761183272.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61Y5cOdH...</td>\n",
       "      <td>Mom's Family Wall Calendar 2016</td>\n",
       "      <td>Sandra Boynton</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623439671</th>\n",
       "      <td>1623439671.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61t-hrSw...</td>\n",
       "      <td>Doug the Pug 2016 Wall Calendar</td>\n",
       "      <td>Doug the Pug</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00O80WC6I</th>\n",
       "      <td>B00O80WC6I.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41X-KQqs...</td>\n",
       "      <td>Moleskine 2016 Weekly Notebook, 12M, Large, Bl...</td>\n",
       "      <td>Moleskine</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761182187</th>\n",
       "      <td>0761182187.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61j-4gxJ...</td>\n",
       "      <td>365 Cats Color Page-A-Day Calendar 2016</td>\n",
       "      <td>Workman Publishing</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578052084</th>\n",
       "      <td>1578052084.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51Ry4Tsq...</td>\n",
       "      <td>Sierra Club Engagement Calendar 2016</td>\n",
       "      <td>Sierra Club</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Image                                         Image_link  \\\n",
       "Id                                                                              \n",
       "761183272   0761183272.jpg  http://ecx.images-amazon.com/images/I/61Y5cOdH...   \n",
       "1623439671  1623439671.jpg  http://ecx.images-amazon.com/images/I/61t-hrSw...   \n",
       "B00O80WC6I  B00O80WC6I.jpg  http://ecx.images-amazon.com/images/I/41X-KQqs...   \n",
       "761182187   0761182187.jpg  http://ecx.images-amazon.com/images/I/61j-4gxJ...   \n",
       "1578052084  1578052084.jpg  http://ecx.images-amazon.com/images/I/51Ry4Tsq...   \n",
       "\n",
       "                                                        Title  \\\n",
       "Id                                                              \n",
       "761183272                     Mom's Family Wall Calendar 2016   \n",
       "1623439671                    Doug the Pug 2016 Wall Calendar   \n",
       "B00O80WC6I  Moleskine 2016 Weekly Notebook, 12M, Large, Bl...   \n",
       "761182187             365 Cats Color Page-A-Day Calendar 2016   \n",
       "1578052084               Sierra Club Engagement Calendar 2016   \n",
       "\n",
       "                        Author  Class      Genre  \n",
       "Id                                                \n",
       "761183272       Sandra Boynton      3  Calendars  \n",
       "1623439671        Doug the Pug      3  Calendars  \n",
       "B00O80WC6I           Moleskine      3  Calendars  \n",
       "761182187   Workman Publishing      3  Calendars  \n",
       "1578052084         Sierra Club      3  Calendars  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv into a data frame\n",
    "csv = 'book32-listing.csv'\n",
    "all_data = pd.read_csv(csv, encoding = 'ISO-8859-1', index_col=0)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-299-971b6204215f>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Text'] = data['Title'].astype(str) + ' ' + data['Author'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471839655</th>\n",
       "      <td>Fundamentals of Photonics (Wiley Series in Pur...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604691956</th>\n",
       "      <td>50 Beautiful Deer-Resistant Plants: The Pretti...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62237330</th>\n",
       "      <td>Eric: A Novel of Discworld Terry Pratchett</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472051849</th>\n",
       "      <td>The North Country Trail: The Best Walks, Hikes...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806983590</th>\n",
       "      <td>The Rug Hook Book: Techniques, Projects And Pa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text  Class\n",
       "Id                                                                  \n",
       "471839655   Fundamentals of Photonics (Wiley Series in Pur...     23\n",
       "1604691956  50 Beautiful Deer-Resistant Plants: The Pretti...      8\n",
       "62237330           Eric: A Novel of Discworld Terry Pratchett     24\n",
       "472051849   The North Country Trail: The Best Walks, Hikes...     29\n",
       "806983590   The Rug Hook Book: Techniques, Projects And Pa...      8"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we only care about the Title, Author and Class columns, we will extract them and shuffle the data\n",
    "# We can enrich the feature representation by including the Author information\n",
    "from sklearn.utils import shuffle\n",
    "data = all_data[['Title', 'Author', 'Class']]\n",
    "data['Text'] = data['Title'].astype(str) + ' ' + data['Author'].astype(str)\n",
    "data = data[['Text', 'Class']]\n",
    "data = shuffle(data, random_state=42)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\duygu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471839655</th>\n",
       "      <td>fundamentals photonics wiley series pure appli...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604691956</th>\n",
       "      <td>beautiful deer resistant plants prettiest annu...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62237330</th>\n",
       "      <td>eric novel discworld terry pratchett</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472051849</th>\n",
       "      <td>north country trail best walks hikes backpacki...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806983590</th>\n",
       "      <td>rug hook book techniques projects patterns eas...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text  Class\n",
       "Id                                                                  \n",
       "471839655   fundamentals photonics wiley series pure appli...     23\n",
       "1604691956  beautiful deer resistant plants prettiest annu...      8\n",
       "62237330                 eric novel discworld terry pratchett     24\n",
       "472051849   north country trail best walks hikes backpacki...     29\n",
       "806983590   rug hook book techniques projects patterns eas...      8"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we will use some very basic text cleaning steps \n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords') # After you download the data, you can comment this line \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # Stopwords carry far less meaning than other keywords in the text\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # Remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # Remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # Convert text to lowercase \n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: clean_text(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will extract features from the text and split the data into training, validation and test sets\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2500) \n",
    "# You can change the max_features if you encounter a memory error, but do not make it too small\n",
    "\n",
    "x_train_series, y_train = data['Text'][:150000], data['Class'][:150000] # 150K train\n",
    "x_val_series, y_val = data['Text'][150000:180000], data['Class'][150000:180000] # 30K val\n",
    "x_test_series, y_test = data['Text'][180000:], data['Class'][180000:] # ~30K test\n",
    "\n",
    "x_train = np.array(vectorizer.fit_transform(x_train_series).todense())\n",
    "x_val = np.array(vectorizer.transform(x_val_series).todense())\n",
    "x_test = np.array(vectorizer.transform(x_test_series).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. You will use your implementations (layers.py) below to carry out the book genre classification. Construct your model with all its layers in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 13.185586835738388, Accuracy: 0.0146484375\n",
      "Epoch: 100, Loss: 6.404966458948828, Accuracy: 0.0859375\n",
      "Epoch: 200, Loss: 4.093178815131452, Accuracy: 0.123046875\n",
      "Epoch: 300, Loss: 3.7152495203385936, Accuracy: 0.18359375\n",
      "Epoch: 400, Loss: 3.3147398137212036, Accuracy: 0.2666015625\n",
      "Epoch: 500, Loss: 2.8854544429918594, Accuracy: 0.2861328125\n",
      "Epoch: 600, Loss: 2.7901036067756673, Accuracy: 0.2998046875\n",
      "Epoch: 700, Loss: 2.683370587978197, Accuracy: 0.337890625\n",
      "Epoch: 800, Loss: 2.747620890970005, Accuracy: 0.3037109375\n",
      "Epoch: 900, Loss: 2.533660562477211, Accuracy: 0.3525390625\n",
      "Epoch: 1000, Loss: 2.4685649294154155, Accuracy: 0.3759765625\n",
      "Epoch: 1100, Loss: 2.4582199684286152, Accuracy: 0.376953125\n",
      "Epoch: 1200, Loss: 2.46267872529822, Accuracy: 0.3798828125\n",
      "Epoch: 1300, Loss: 2.4239736363763233, Accuracy: 0.3798828125\n",
      "Epoch: 1400, Loss: 2.274122725889458, Accuracy: 0.4287109375\n",
      "Epoch: 1500, Loss: 2.3600912001720857, Accuracy: 0.3779296875\n",
      "Epoch: 1600, Loss: 2.2619831535237322, Accuracy: 0.4150390625\n",
      "Epoch: 1700, Loss: 2.1639636931088155, Accuracy: 0.44140625\n",
      "Epoch: 1800, Loss: 2.2339979123653335, Accuracy: 0.4091796875\n",
      "Epoch: 1900, Loss: 2.124473270921942, Accuracy: 0.4443359375\n",
      "Epoch: 2000, Loss: 2.1202959250304425, Accuracy: 0.46875\n",
      "Epoch: 2100, Loss: 2.146277120707411, Accuracy: 0.455078125\n",
      "Epoch: 2200, Loss: 2.1613531295068884, Accuracy: 0.4326171875\n",
      "Epoch: 2300, Loss: 2.1311371376372445, Accuracy: 0.4423828125\n",
      "Epoch: 2400, Loss: 2.129034940568607, Accuracy: 0.455078125\n",
      "Epoch: 2500, Loss: 2.11106968933907, Accuracy: 0.4384765625\n",
      "Epoch: 2600, Loss: 2.062009679468985, Accuracy: 0.451171875\n",
      "Epoch: 2700, Loss: 2.0308244243656457, Accuracy: 0.462890625\n",
      "Epoch: 2800, Loss: 2.082594288977869, Accuracy: 0.470703125\n",
      "Epoch: 2900, Loss: 2.0519941091908005, Accuracy: 0.4677734375\n",
      "Epoch: 3000, Loss: 1.9016765965021196, Accuracy: 0.4951171875\n",
      "Epoch: 3100, Loss: 1.9890595432723441, Accuracy: 0.4814453125\n",
      "Epoch: 3200, Loss: 1.9841040631666442, Accuracy: 0.474609375\n",
      "Epoch: 3300, Loss: 2.0225758912319396, Accuracy: 0.46484375\n",
      "Epoch: 3400, Loss: 1.9191696956458884, Accuracy: 0.48828125\n",
      "Epoch: 3500, Loss: 1.8896532965989383, Accuracy: 0.505859375\n",
      "Epoch: 3600, Loss: 1.9275620906428708, Accuracy: 0.4970703125\n",
      "Epoch: 3700, Loss: 1.929290259778832, Accuracy: 0.494140625\n",
      "Epoch: 3800, Loss: 1.8910975820697133, Accuracy: 0.4970703125\n",
      "Epoch: 3900, Loss: 1.898394322129242, Accuracy: 0.482421875\n",
      "Epoch: 4000, Loss: 1.9299291859227177, Accuracy: 0.4736328125\n",
      "Epoch: 4100, Loss: 1.9187757625309587, Accuracy: 0.490234375\n",
      "Epoch: 4200, Loss: 1.862301318748109, Accuracy: 0.4892578125\n",
      "Epoch: 4300, Loss: 1.839741774176841, Accuracy: 0.4970703125\n",
      "Epoch: 4400, Loss: 1.7978769847039633, Accuracy: 0.513671875\n",
      "Epoch: 4500, Loss: 1.883682137439242, Accuracy: 0.4931640625\n",
      "Epoch: 4600, Loss: 1.8758971457929534, Accuracy: 0.4921875\n",
      "Epoch: 4700, Loss: 1.927482974447182, Accuracy: 0.4794921875\n",
      "Epoch: 4800, Loss: 1.83139465868388, Accuracy: 0.51953125\n",
      "Epoch: 4900, Loss: 1.9527932888990247, Accuracy: 0.5068359375\n",
      "Epoch: 5000, Loss: 1.8609868967032126, Accuracy: 0.5048828125\n",
      "Epoch: 5100, Loss: 1.8060920158004246, Accuracy: 0.525390625\n",
      "Epoch: 5200, Loss: 1.7969437571466025, Accuracy: 0.5107421875\n",
      "Epoch: 5300, Loss: 1.8940193918010548, Accuracy: 0.4853515625\n",
      "Epoch: 5400, Loss: 1.846473417023812, Accuracy: 0.4814453125\n",
      "Epoch: 5500, Loss: 1.8541292715726863, Accuracy: 0.486328125\n",
      "Epoch: 5600, Loss: 1.806523008950281, Accuracy: 0.5087890625\n",
      "Epoch: 5700, Loss: 1.8023977971164593, Accuracy: 0.494140625\n",
      "Epoch: 5800, Loss: 1.812647786541417, Accuracy: 0.5068359375\n",
      "Epoch: 5900, Loss: 1.7326719594855167, Accuracy: 0.5322265625\n",
      "Epoch: 6000, Loss: 1.7134172752272707, Accuracy: 0.53515625\n",
      "Epoch: 6100, Loss: 1.7283388632282857, Accuracy: 0.5341796875\n",
      "Epoch: 6200, Loss: 1.833492985766912, Accuracy: 0.509765625\n",
      "Epoch: 6300, Loss: 1.7753208954215371, Accuracy: 0.52734375\n",
      "Epoch: 6400, Loss: 1.7826451989116596, Accuracy: 0.529296875\n",
      "Epoch: 6500, Loss: 1.848609408802445, Accuracy: 0.490234375\n",
      "Epoch: 6600, Loss: 1.7526826140759642, Accuracy: 0.5185546875\n",
      "Epoch: 6700, Loss: 1.7316604525396744, Accuracy: 0.52734375\n",
      "Epoch: 6800, Loss: 1.807460377315395, Accuracy: 0.5029296875\n",
      "Epoch: 6900, Loss: 1.74760572888079, Accuracy: 0.533203125\n",
      "Epoch: 7000, Loss: 1.7604871550552508, Accuracy: 0.5283203125\n",
      "Epoch: 7100, Loss: 1.754811385645415, Accuracy: 0.5244140625\n",
      "Epoch: 7200, Loss: 1.668214354012295, Accuracy: 0.5341796875\n",
      "Epoch: 7300, Loss: 1.6713140269194877, Accuracy: 0.544921875\n",
      "Epoch: 7400, Loss: 1.781219379426438, Accuracy: 0.5126953125\n",
      "Epoch: 7500, Loss: 1.7471126447306728, Accuracy: 0.5283203125\n",
      "Epoch: 7600, Loss: 1.7192810470235163, Accuracy: 0.5302734375\n",
      "Epoch: 7700, Loss: 1.7404554226054172, Accuracy: 0.517578125\n",
      "Epoch: 7800, Loss: 1.6539436824532023, Accuracy: 0.546875\n",
      "Epoch: 7900, Loss: 1.7508597418942111, Accuracy: 0.5244140625\n",
      "Epoch: 8000, Loss: 1.704772295745026, Accuracy: 0.5458984375\n",
      "Epoch: 8100, Loss: 1.6895952425870018, Accuracy: 0.521484375\n",
      "Epoch: 8200, Loss: 1.7186828701983727, Accuracy: 0.53515625\n",
      "Epoch: 8300, Loss: 1.7124907585101057, Accuracy: 0.515625\n",
      "Epoch: 8400, Loss: 1.7531404902824383, Accuracy: 0.515625\n",
      "Epoch: 8500, Loss: 1.6658801782441364, Accuracy: 0.53515625\n",
      "Epoch: 8600, Loss: 1.654132728345252, Accuracy: 0.548828125\n",
      "Epoch: 8700, Loss: 1.7597574092717705, Accuracy: 0.5205078125\n",
      "Epoch: 8800, Loss: 1.6937483657886367, Accuracy: 0.5234375\n",
      "Epoch: 8900, Loss: 1.7335333025399238, Accuracy: 0.5185546875\n",
      "Epoch: 9000, Loss: 1.6826555127106266, Accuracy: 0.546875\n",
      "Epoch: 9100, Loss: 1.6679441467777072, Accuracy: 0.537109375\n",
      "Epoch: 9200, Loss: 1.6911385138687556, Accuracy: 0.54296875\n",
      "Epoch: 9300, Loss: 1.7148986883532729, Accuracy: 0.5234375\n",
      "Epoch: 9400, Loss: 1.7021090593268924, Accuracy: 0.5283203125\n",
      "Epoch: 9500, Loss: 1.6503388049508465, Accuracy: 0.5498046875\n",
      "Epoch: 9600, Loss: 1.6326641725724222, Accuracy: 0.5439453125\n",
      "Epoch: 9700, Loss: 1.7162130251857932, Accuracy: 0.51953125\n",
      "Epoch: 9800, Loss: 1.6864311067587896, Accuracy: 0.533203125\n",
      "Epoch: 9900, Loss: 1.7386128253771531, Accuracy: 0.521484375\n",
      "Epoch: 10000, Loss: 1.7461348012799616, Accuracy: 0.5\n",
      "Epoch: 10100, Loss: 1.5788773072021214, Accuracy: 0.5654296875\n",
      "Epoch: 10200, Loss: 1.6326506458280283, Accuracy: 0.55078125\n",
      "Epoch: 10300, Loss: 1.6937306608419462, Accuracy: 0.5302734375\n",
      "Epoch: 10400, Loss: 1.61131677256378, Accuracy: 0.55078125\n",
      "Epoch: 10500, Loss: 1.6777663147085198, Accuracy: 0.5302734375\n",
      "Epoch: 10600, Loss: 1.6126239850556272, Accuracy: 0.552734375\n",
      "Epoch: 10700, Loss: 1.7541986237309721, Accuracy: 0.513671875\n",
      "Epoch: 10800, Loss: 1.6561086434863896, Accuracy: 0.5419921875\n",
      "Epoch: 10900, Loss: 1.5960930281313352, Accuracy: 0.556640625\n",
      "Epoch: 11000, Loss: 1.6638546925984783, Accuracy: 0.5341796875\n",
      "Epoch: 11100, Loss: 1.617377311453903, Accuracy: 0.548828125\n",
      "Epoch: 11200, Loss: 1.620109695166557, Accuracy: 0.544921875\n",
      "Epoch: 11300, Loss: 1.647394058323167, Accuracy: 0.5400390625\n",
      "Epoch: 11400, Loss: 1.7076749773461843, Accuracy: 0.5341796875\n",
      "Epoch: 11500, Loss: 1.620887687497841, Accuracy: 0.55078125\n",
      "Epoch: 11600, Loss: 1.567665550712778, Accuracy: 0.5517578125\n",
      "Epoch: 11700, Loss: 1.6500648505001165, Accuracy: 0.525390625\n",
      "Epoch: 11800, Loss: 1.6826313107897688, Accuracy: 0.5166015625\n",
      "Epoch: 11900, Loss: 1.598353156608756, Accuracy: 0.5576171875\n",
      "Epoch: 12000, Loss: 1.6259787170773183, Accuracy: 0.552734375\n",
      "Epoch: 12100, Loss: 1.6298026752774808, Accuracy: 0.546875\n",
      "Epoch: 12200, Loss: 1.606530508124256, Accuracy: 0.560546875\n",
      "Epoch: 12300, Loss: 1.5862061679312602, Accuracy: 0.5625\n",
      "Epoch: 12400, Loss: 1.633206275912441, Accuracy: 0.548828125\n",
      "Epoch: 12500, Loss: 1.6421589810240156, Accuracy: 0.5400390625\n",
      "Epoch: 12600, Loss: 1.6276392240768165, Accuracy: 0.53515625\n",
      "Epoch: 12700, Loss: 1.6825442140647566, Accuracy: 0.529296875\n",
      "Epoch: 12800, Loss: 1.649955269640528, Accuracy: 0.53515625\n",
      "Epoch: 12900, Loss: 1.6700181238704994, Accuracy: 0.5400390625\n",
      "Epoch: 13000, Loss: 1.6288075792749943, Accuracy: 0.546875\n",
      "Epoch: 13100, Loss: 1.5733589907648635, Accuracy: 0.5517578125\n",
      "Epoch: 13200, Loss: 1.5721785524689817, Accuracy: 0.5673828125\n",
      "Epoch: 13300, Loss: 1.6138916672332444, Accuracy: 0.5400390625\n",
      "Epoch: 13400, Loss: 1.6180640404798847, Accuracy: 0.5400390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13500, Loss: 1.6605809543458527, Accuracy: 0.5341796875\n",
      "Epoch: 13600, Loss: 1.680857013603923, Accuracy: 0.5263671875\n",
      "Epoch: 13700, Loss: 1.6105766792645038, Accuracy: 0.5322265625\n",
      "Epoch: 13800, Loss: 1.5961570443123516, Accuracy: 0.556640625\n",
      "Epoch: 13900, Loss: 1.668517927018617, Accuracy: 0.529296875\n",
      "Epoch: 14000, Loss: 1.6026234858300175, Accuracy: 0.560546875\n",
      "Epoch: 14100, Loss: 1.5473103621529207, Accuracy: 0.5654296875\n",
      "Epoch: 14200, Loss: 1.5992724143498926, Accuracy: 0.5615234375\n",
      "Epoch: 14300, Loss: 1.616562502260152, Accuracy: 0.5498046875\n",
      "Epoch: 14400, Loss: 1.6103081369275767, Accuracy: 0.5595703125\n",
      "Epoch: 14500, Loss: 1.577670773517526, Accuracy: 0.5537109375\n",
      "Epoch: 14600, Loss: 1.558229027267974, Accuracy: 0.5595703125\n",
      "Epoch: 14700, Loss: 1.6616964497249094, Accuracy: 0.5478515625\n",
      "Epoch: 14800, Loss: 1.623146510744499, Accuracy: 0.5361328125\n",
      "Epoch: 14900, Loss: 1.6604885475259854, Accuracy: 0.533203125\n",
      "Epoch: 15000, Loss: 1.5996557023340456, Accuracy: 0.5361328125\n",
      "Epoch: 15100, Loss: 1.6076285112183568, Accuracy: 0.5537109375\n",
      "Epoch: 15200, Loss: 1.6199587013866728, Accuracy: 0.5625\n",
      "Epoch: 15300, Loss: 1.546247437849714, Accuracy: 0.5537109375\n",
      "Epoch: 15400, Loss: 1.5570505729972197, Accuracy: 0.5673828125\n",
      "Epoch: 15500, Loss: 1.5769075364501095, Accuracy: 0.533203125\n",
      "Epoch: 15600, Loss: 1.5712049903406624, Accuracy: 0.5732421875\n",
      "Epoch: 15700, Loss: 1.5593481558825548, Accuracy: 0.5625\n",
      "Epoch: 15800, Loss: 1.605535925816603, Accuracy: 0.5302734375\n",
      "Epoch: 15900, Loss: 1.5976273697192926, Accuracy: 0.537109375\n",
      "Epoch: 16000, Loss: 1.6114374578283326, Accuracy: 0.5556640625\n",
      "Epoch: 16100, Loss: 1.6167342227590122, Accuracy: 0.5625\n",
      "Epoch: 16200, Loss: 1.4679531277248905, Accuracy: 0.580078125\n",
      "Epoch: 16300, Loss: 1.5774045777646404, Accuracy: 0.5419921875\n",
      "Epoch: 16400, Loss: 1.521234510866962, Accuracy: 0.5654296875\n",
      "Epoch: 16500, Loss: 1.5649864036817775, Accuracy: 0.5595703125\n",
      "Epoch: 16600, Loss: 1.6356207429074823, Accuracy: 0.5302734375\n",
      "Epoch: 16700, Loss: 1.5053862882718363, Accuracy: 0.568359375\n",
      "Epoch: 16800, Loss: 1.6150938551141025, Accuracy: 0.541015625\n",
      "Epoch: 16900, Loss: 1.525335593129728, Accuracy: 0.5478515625\n",
      "Epoch: 17000, Loss: 1.5618424980383028, Accuracy: 0.560546875\n",
      "Epoch: 17100, Loss: 1.5527803040577421, Accuracy: 0.57421875\n",
      "Epoch: 17200, Loss: 1.5923380265568285, Accuracy: 0.5517578125\n",
      "Epoch: 17300, Loss: 1.4891384833326828, Accuracy: 0.5927734375\n",
      "Epoch: 17400, Loss: 1.5310336327687883, Accuracy: 0.5712890625\n",
      "Epoch: 17500, Loss: 1.675913907742066, Accuracy: 0.5126953125\n",
      "Epoch: 17600, Loss: 1.563843157460326, Accuracy: 0.560546875\n",
      "Epoch: 17700, Loss: 1.5634268520824657, Accuracy: 0.5546875\n",
      "Epoch: 17800, Loss: 1.5450882839403204, Accuracy: 0.5634765625\n",
      "Epoch: 17900, Loss: 1.5902329292991446, Accuracy: 0.5478515625\n",
      "Epoch: 18000, Loss: 1.521372958410892, Accuracy: 0.5439453125\n",
      "Epoch: 18100, Loss: 1.5764324757123154, Accuracy: 0.56640625\n",
      "Epoch: 18200, Loss: 1.5469424451587657, Accuracy: 0.55859375\n",
      "Epoch: 18300, Loss: 1.6346930749087347, Accuracy: 0.54296875\n",
      "Epoch: 18400, Loss: 1.5453090701272632, Accuracy: 0.5751953125\n",
      "Epoch: 18500, Loss: 1.5550973005911577, Accuracy: 0.5703125\n",
      "Epoch: 18600, Loss: 1.5992911762866373, Accuracy: 0.53515625\n",
      "Epoch: 18700, Loss: 1.4982220363269263, Accuracy: 0.578125\n",
      "Epoch: 18800, Loss: 1.5125919497282332, Accuracy: 0.564453125\n",
      "Epoch: 18900, Loss: 1.5107173450887283, Accuracy: 0.5693359375\n",
      "Epoch: 19000, Loss: 1.6127846937711885, Accuracy: 0.5419921875\n",
      "Epoch: 19100, Loss: 1.5771669837739897, Accuracy: 0.5419921875\n",
      "Epoch: 19200, Loss: 1.5106408652262504, Accuracy: 0.5830078125\n",
      "Epoch: 19300, Loss: 1.5350463290948677, Accuracy: 0.552734375\n",
      "Epoch: 19400, Loss: 1.5740551791054727, Accuracy: 0.5634765625\n",
      "Epoch: 19500, Loss: 1.5562123832916686, Accuracy: 0.5703125\n",
      "Epoch: 19600, Loss: 1.6970886825021125, Accuracy: 0.525390625\n",
      "Epoch: 19700, Loss: 1.5834475542541504, Accuracy: 0.5712890625\n",
      "Epoch: 19800, Loss: 1.5369084869567398, Accuracy: 0.572265625\n",
      "Epoch: 19900, Loss: 1.4984863373691544, Accuracy: 0.580078125\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20000\n",
    "print_every = 100\n",
    "test_every = 500\n",
    "\n",
    "lr = 1e-1\n",
    "rs = 1e-5\n",
    "\n",
    "model = layer.Model() # Create a model instance\n",
    "\n",
    "layers = [layer.AffineLayer(2500,512), layer.ReLU(), \n",
    "          layer.AffineLayer(512,32), layer.Softmax()]\n",
    "\n",
    "model(layers) # Load layers to model object\n",
    "\n",
    "initialW1 = model.layers[0].W\n",
    "initialW2 = model.layers[2].W\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "optimizer = layer.SGDWithMomentum(model, lr=lr, regularization_str=rs)\n",
    "\n",
    "for epoch in range(n_epochs):   #train all config parameters\n",
    "\n",
    "    samples = np.random.choice(x_train.shape[0], size=m_batch)  #mini batch size samples are selected\n",
    "\n",
    "    x = x_train[samples,:]\n",
    "    y = y_train[samples]\n",
    "\n",
    "    softmax_out = model.forward(x)                  #forward of all layers are executed and final layer gives probs mtrx.\n",
    "    predictions = np.argmax(softmax_out, axis=1)    #Highest prob will be our predicted result\n",
    "    train_acc = np.mean(predictions == y)           #Compare with correct class avg them, get accuracy\n",
    "    loss = layer.loss(softmax_out, y)               #Calculate loss\n",
    "\n",
    "    train_accs.append(train_acc)\n",
    "    train_loss.append(loss)\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss, train_acc))\n",
    "\n",
    "    model.backward(y)                               #Calculate derivatives\n",
    "    optimizer.optimize()                            #Update weights and biases\n",
    "        \n",
    "       \n",
    "finalW1 = model.layers[0].W\n",
    "finalW2 = model.layers[2].W\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Plot histogram of the weights of affine layers to see whether the weights vanish or not and comment.\n",
    "\n",
    "When we compare the initial weights and final weights we can see that weights are not vanished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.,   0.,   0., ..., 478., 391.,  21.],\n",
       "        [  0.,   0.,   0., ..., 481., 383.,  16.],\n",
       "        [  0.,   0.,   0., ..., 467., 386.,  18.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., ..., 467., 422.,  20.],\n",
       "        [  0.,   0.,   1., ..., 481., 369.,  21.],\n",
       "        [  0.,   0.,   4., ..., 477., 393.,  26.]]),\n",
       " array([-0.60850006, -0.43249473, -0.25648939, -0.08048406,  0.09552127,\n",
       "         0.2715266 ,  0.44753194,  0.62353727,  0.7995426 ,  0.97554793,\n",
       "         1.15155327]),\n",
       " <a list of 512 Lists of Patches objects>)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(initialW1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.,   5.,  31., 117., 154., 144.,  55.,   6.,   0.,   0.],\n",
       "        [  0.,   1.,  29., 103., 185., 155.,  34.,   5.,   0.,   0.],\n",
       "        [  0.,  11.,  38., 109., 149., 124.,  65.,  15.,   1.,   0.],\n",
       "        [  2.,   4.,  44., 117., 136., 124.,  69.,  16.,   0.,   0.],\n",
       "        [  1.,  12.,  50., 107., 137., 120.,  65.,  17.,   3.,   0.],\n",
       "        [  1.,   6.,  36., 122., 151., 127.,  55.,  13.,   1.,   0.],\n",
       "        [  2.,  16.,  54.,  98., 124., 127.,  68.,  20.,   2.,   1.],\n",
       "        [  0.,  12.,  54.,  98., 143., 117.,  64.,  22.,   2.,   0.],\n",
       "        [  1.,  11.,  33., 103., 165., 125.,  58.,  14.,   2.,   0.],\n",
       "        [  0.,   4.,  50.,  98., 165., 122.,  56.,  15.,   2.,   0.],\n",
       "        [  0.,   6.,  31., 116., 164., 123.,  63.,   9.,   0.,   0.],\n",
       "        [  0.,   8.,  37., 121., 154., 108.,  70.,  14.,   0.,   0.],\n",
       "        [  2.,   5.,  32., 108., 168., 136.,  50.,   9.,   2.,   0.],\n",
       "        [  0.,   3.,  34., 105., 176., 134.,  55.,   5.,   0.,   0.],\n",
       "        [  1.,   7.,  27., 113., 154., 148.,  47.,  13.,   2.,   0.],\n",
       "        [  0.,   1.,  37., 106., 170., 146.,  44.,   8.,   0.,   0.],\n",
       "        [  1.,   8.,  43., 108., 156., 120.,  54.,  21.,   1.,   0.],\n",
       "        [  0.,   6.,  43., 102., 165., 121.,  64.,  10.,   1.,   0.],\n",
       "        [  0.,   3.,  31., 116., 171., 128.,  52.,  11.,   0.,   0.],\n",
       "        [  0.,   1.,  21., 106., 200., 138.,  45.,   1.,   0.,   0.],\n",
       "        [  0.,   3.,  26., 113., 178., 140.,  45.,   7.,   0.,   0.],\n",
       "        [  2.,   4.,  40., 102., 178., 115.,  57.,  13.,   1.,   0.],\n",
       "        [  0.,  16.,  41., 108., 142., 133.,  54.,  17.,   1.,   0.],\n",
       "        [  2.,   5.,  34., 112., 169., 117.,  58.,  15.,   0.,   0.],\n",
       "        [  1.,  12.,  37., 110., 151., 129.,  54.,  16.,   2.,   0.],\n",
       "        [  0.,   4.,  36., 109., 170., 132.,  50.,  10.,   1.,   0.],\n",
       "        [  3.,   3.,  35., 119., 149., 141.,  52.,  10.,   0.,   0.],\n",
       "        [  0.,   6.,  33., 106., 173., 127.,  54.,  11.,   2.,   0.],\n",
       "        [  0.,  14.,  40., 110., 154.,  99.,  76.,  16.,   2.,   1.],\n",
       "        [  1.,  12.,  39., 131., 121., 114.,  74.,  17.,   2.,   1.],\n",
       "        [  0.,   4.,  25., 115., 176., 130.,  59.,   3.,   0.,   0.],\n",
       "        [  0.,   7.,  44.,  97., 156., 139.,  58.,  11.,   0.,   0.]]),\n",
       " array([-0.55759562, -0.33440577, -0.11121592,  0.11197394,  0.33516379,\n",
       "         0.55835364,  0.7815435 ,  1.00473335,  1.2279232 ,  1.45111306,\n",
       "         1.67430291]),\n",
       " <a list of 32 Lists of Patches objects>)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(initialW2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.,   0.,   0., ..., 478., 391.,  21.],\n",
       "        [  0.,   0.,   0., ..., 481., 383.,  16.],\n",
       "        [  0.,   0.,   0., ..., 467., 386.,  18.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0., ..., 467., 422.,  20.],\n",
       "        [  0.,   0.,   1., ..., 481., 369.,  21.],\n",
       "        [  0.,   0.,   4., ..., 477., 393.,  26.]]),\n",
       " array([-0.60850006, -0.43249473, -0.25648939, -0.08048406,  0.09552127,\n",
       "         0.2715266 ,  0.44753194,  0.62353727,  0.7995426 ,  0.97554793,\n",
       "         1.15155327]),\n",
       " <a list of 512 Lists of Patches objects>)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(finalW1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.,   5.,  31., 117., 154., 144.,  55.,   6.,   0.,   0.],\n",
       "        [  0.,   1.,  29., 103., 185., 155.,  34.,   5.,   0.,   0.],\n",
       "        [  0.,  11.,  38., 109., 149., 124.,  65.,  15.,   1.,   0.],\n",
       "        [  2.,   4.,  44., 117., 136., 124.,  69.,  16.,   0.,   0.],\n",
       "        [  1.,  12.,  50., 107., 137., 120.,  65.,  17.,   3.,   0.],\n",
       "        [  1.,   6.,  36., 122., 151., 127.,  55.,  13.,   1.,   0.],\n",
       "        [  2.,  16.,  54.,  98., 124., 127.,  68.,  20.,   2.,   1.],\n",
       "        [  0.,  12.,  54.,  98., 143., 117.,  64.,  22.,   2.,   0.],\n",
       "        [  1.,  11.,  33., 103., 165., 125.,  58.,  14.,   2.,   0.],\n",
       "        [  0.,   4.,  50.,  98., 165., 122.,  56.,  15.,   2.,   0.],\n",
       "        [  0.,   6.,  31., 116., 164., 123.,  63.,   9.,   0.,   0.],\n",
       "        [  0.,   8.,  37., 121., 154., 108.,  70.,  14.,   0.,   0.],\n",
       "        [  2.,   5.,  32., 108., 168., 136.,  50.,   9.,   2.,   0.],\n",
       "        [  0.,   3.,  34., 105., 176., 134.,  55.,   5.,   0.,   0.],\n",
       "        [  1.,   7.,  27., 113., 154., 148.,  47.,  13.,   2.,   0.],\n",
       "        [  0.,   1.,  37., 106., 170., 146.,  44.,   8.,   0.,   0.],\n",
       "        [  1.,   8.,  43., 108., 156., 120.,  54.,  21.,   1.,   0.],\n",
       "        [  0.,   6.,  43., 102., 165., 121.,  64.,  10.,   1.,   0.],\n",
       "        [  0.,   3.,  31., 116., 171., 128.,  52.,  11.,   0.,   0.],\n",
       "        [  0.,   1.,  21., 106., 200., 138.,  45.,   1.,   0.,   0.],\n",
       "        [  0.,   3.,  26., 113., 178., 140.,  45.,   7.,   0.,   0.],\n",
       "        [  2.,   4.,  40., 102., 178., 115.,  57.,  13.,   1.,   0.],\n",
       "        [  0.,  16.,  41., 108., 142., 133.,  54.,  17.,   1.,   0.],\n",
       "        [  2.,   5.,  34., 112., 169., 117.,  58.,  15.,   0.,   0.],\n",
       "        [  1.,  12.,  37., 110., 151., 129.,  54.,  16.,   2.,   0.],\n",
       "        [  0.,   4.,  36., 109., 170., 132.,  50.,  10.,   1.,   0.],\n",
       "        [  3.,   3.,  35., 119., 149., 141.,  52.,  10.,   0.,   0.],\n",
       "        [  0.,   6.,  33., 106., 173., 127.,  54.,  11.,   2.,   0.],\n",
       "        [  0.,  14.,  40., 110., 154.,  99.,  76.,  16.,   2.,   1.],\n",
       "        [  1.,  12.,  39., 131., 121., 114.,  74.,  17.,   2.,   1.],\n",
       "        [  0.,   4.,  25., 115., 176., 130.,  59.,   3.,   0.,   0.],\n",
       "        [  0.,   7.,  44.,  97., 156., 139.,  58.,  11.,   0.,   0.]]),\n",
       " array([-0.55759562, -0.33440577, -0.11121592,  0.11197394,  0.33516379,\n",
       "         0.55835364,  0.7815435 ,  1.00473335,  1.2279232 ,  1.45111306,\n",
       "         1.67430291]),\n",
       " <a list of 32 Lists of Patches objects>)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(finalW2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Run diagnostics of your model : Try different hyperparameter settings such as number of layers in your model, learning rate, regularization parameter and such.  Avoid overfitting and underfitting as much as possible. We expect you to get at least 50% test accuracy with your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 16.449520977364468, Accuracy: 0.0458984375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 0, Momentum: True\n",
      "Val Loss: 13.967881161014313, Val Accuracy: 0.04426666666666667\n",
      "-----------\n",
      "Epoch: 100, Loss: 6.783168883546804, Accuracy: 0.0703125\n",
      "Epoch: 200, Loss: 5.248463829323683, Accuracy: 0.12890625\n",
      "Epoch: 300, Loss: 3.118983140391065, Accuracy: 0.23046875\n",
      "Epoch: 400, Loss: 2.962408654442673, Accuracy: 0.2548828125\n",
      "Epoch: 500, Loss: 2.8619121518495856, Accuracy: 0.2666015625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 500, Momentum: True\n",
      "Val Loss: 2.827353057100638, Val Accuracy: 0.27673333333333333\n",
      "-----------\n",
      "Epoch: 600, Loss: 2.5860804622571436, Accuracy: 0.333984375\n",
      "Epoch: 700, Loss: 2.5353528968691323, Accuracy: 0.3466796875\n",
      "Epoch: 800, Loss: 2.522705204922657, Accuracy: 0.34375\n",
      "Epoch: 900, Loss: 2.502802278782286, Accuracy: 0.36328125\n",
      "Epoch: 1000, Loss: 2.4292500576948384, Accuracy: 0.3662109375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 1000, Momentum: True\n",
      "Val Loss: 2.410804413921816, Val Accuracy: 0.3686333333333333\n",
      "-----------\n",
      "Epoch: 1100, Loss: 2.331746447989726, Accuracy: 0.392578125\n",
      "Epoch: 1200, Loss: 2.310501683315506, Accuracy: 0.3935546875\n",
      "Epoch: 1300, Loss: 2.247758419323499, Accuracy: 0.4169921875\n",
      "Epoch: 1400, Loss: 2.182650439373586, Accuracy: 0.419921875\n",
      "Epoch: 1500, Loss: 2.1909299749758087, Accuracy: 0.4267578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 1500, Momentum: True\n",
      "Val Loss: 2.253265645451866, Val Accuracy: 0.4095\n",
      "-----------\n",
      "Epoch: 1600, Loss: 2.2448887706230285, Accuracy: 0.4072265625\n",
      "Epoch: 1700, Loss: 2.1472769839021484, Accuracy: 0.4541015625\n",
      "Epoch: 1800, Loss: 2.185157876120829, Accuracy: 0.427734375\n",
      "Epoch: 1900, Loss: 2.0813413724022283, Accuracy: 0.4619140625\n",
      "Epoch: 2000, Loss: 2.1098951636465886, Accuracy: 0.466796875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 2000, Momentum: True\n",
      "Val Loss: 2.172105126579547, Val Accuracy: 0.4325\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.0795007278192648, Accuracy: 0.4794921875\n",
      "Epoch: 2200, Loss: 2.060374919374234, Accuracy: 0.4873046875\n",
      "Epoch: 2300, Loss: 2.1177263433710882, Accuracy: 0.4521484375\n",
      "Epoch: 2400, Loss: 2.034005342727197, Accuracy: 0.4638671875\n",
      "Epoch: 2500, Loss: 2.08338885756722, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 2500, Momentum: True\n",
      "Val Loss: 2.1216806284419265, Val Accuracy: 0.4499\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.124431453498312, Accuracy: 0.4345703125\n",
      "Epoch: 2700, Loss: 2.0444288753722026, Accuracy: 0.474609375\n",
      "Epoch: 2800, Loss: 2.022650499593476, Accuracy: 0.4775390625\n",
      "Epoch: 2900, Loss: 2.033191324970012, Accuracy: 0.4794921875\n",
      "Epoch: 3000, Loss: 1.994656489458615, Accuracy: 0.482421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 3000, Momentum: True\n",
      "Val Loss: 2.0905128599456164, Val Accuracy: 0.4575666666666667\n",
      "-----------\n",
      "Epoch: 3100, Loss: 1.9564208418729638, Accuracy: 0.5048828125\n",
      "Epoch: 3200, Loss: 2.0910204358144333, Accuracy: 0.4580078125\n",
      "Epoch: 3300, Loss: 2.0394318358720867, Accuracy: 0.466796875\n",
      "Epoch: 3400, Loss: 2.038754761365561, Accuracy: 0.484375\n",
      "Epoch: 3500, Loss: 2.03742375572565, Accuracy: 0.474609375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 3500, Momentum: True\n",
      "Val Loss: 2.0664382823473546, Val Accuracy: 0.4648333333333333\n",
      "-----------\n",
      "Epoch: 3600, Loss: 2.0450529757372684, Accuracy: 0.4755859375\n",
      "Epoch: 3700, Loss: 2.018765547591614, Accuracy: 0.466796875\n",
      "Epoch: 3800, Loss: 2.0615329113220056, Accuracy: 0.4765625\n",
      "Epoch: 3900, Loss: 2.0839310600681875, Accuracy: 0.47265625\n",
      "Epoch: 4000, Loss: 2.0123560149205875, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 4000, Momentum: True\n",
      "Val Loss: 2.0486850492378053, Val Accuracy: 0.47186666666666666\n",
      "-----------\n",
      "Epoch: 4100, Loss: 1.9556862604592458, Accuracy: 0.5048828125\n",
      "Epoch: 4200, Loss: 1.9729038746875613, Accuracy: 0.505859375\n",
      "Epoch: 4300, Loss: 2.0654390280724844, Accuracy: 0.4580078125\n",
      "Epoch: 4400, Loss: 1.9554737256206243, Accuracy: 0.5\n",
      "Epoch: 4500, Loss: 1.9441395563786843, Accuracy: 0.4912109375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 4500, Momentum: True\n",
      "Val Loss: 2.0331705960351796, Val Accuracy: 0.47423333333333334\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.0097803960158247, Accuracy: 0.47265625\n",
      "Epoch: 4700, Loss: 2.0448927352536983, Accuracy: 0.4677734375\n",
      "Epoch: 4800, Loss: 2.033932020937257, Accuracy: 0.4765625\n",
      "Epoch: 4900, Loss: 1.9624215885469283, Accuracy: 0.521484375\n",
      "Epoch: 5000, Loss: 1.9515787007723504, Accuracy: 0.5146484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 5000, Momentum: True\n",
      "Val Loss: 2.022329031486806, Val Accuracy: 0.47633333333333333\n",
      "-----------\n",
      "Epoch: 5100, Loss: 1.9314853860304428, Accuracy: 0.5029296875\n",
      "Epoch: 5200, Loss: 1.9962824081019122, Accuracy: 0.478515625\n",
      "Epoch: 5300, Loss: 1.9674333927761247, Accuracy: 0.4873046875\n",
      "Epoch: 5400, Loss: 1.9443155115369029, Accuracy: 0.4951171875\n",
      "Epoch: 5500, Loss: 1.9294277211127808, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 5500, Momentum: True\n",
      "Val Loss: 2.014041494388639, Val Accuracy: 0.4811\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.016386049127923, Accuracy: 0.478515625\n",
      "Epoch: 5700, Loss: 1.9889350667478964, Accuracy: 0.4970703125\n",
      "Epoch: 5800, Loss: 1.9437619191525042, Accuracy: 0.4970703125\n",
      "Epoch: 5900, Loss: 2.0065394528014218, Accuracy: 0.484375\n",
      "Epoch: 6000, Loss: 1.9841845455311038, Accuracy: 0.470703125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 6000, Momentum: True\n",
      "Val Loss: 2.00620785425879, Val Accuracy: 0.48423333333333335\n",
      "-----------\n",
      "Epoch: 6100, Loss: 1.9031515463971749, Accuracy: 0.5244140625\n",
      "Epoch: 6200, Loss: 2.0063414370459007, Accuracy: 0.4755859375\n",
      "Epoch: 6300, Loss: 1.9283310278364207, Accuracy: 0.5087890625\n",
      "Epoch: 6400, Loss: 1.8757433529818455, Accuracy: 0.52734375\n",
      "Epoch: 6500, Loss: 1.9902726065767253, Accuracy: 0.49609375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 6500, Momentum: True\n",
      "Val Loss: 2.000029781972256, Val Accuracy: 0.48486666666666667\n",
      "-----------\n",
      "Epoch: 6600, Loss: 1.957690003851538, Accuracy: 0.501953125\n",
      "Epoch: 6700, Loss: 1.9873702077817632, Accuracy: 0.4873046875\n",
      "Epoch: 6800, Loss: 1.9156343541272813, Accuracy: 0.525390625\n",
      "Epoch: 6900, Loss: 1.9326917535011017, Accuracy: 0.5400390625\n",
      "Epoch: 7000, Loss: 1.9336639583120352, Accuracy: 0.4912109375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 7000, Momentum: True\n",
      "Val Loss: 1.9955537282674718, Val Accuracy: 0.4871666666666667\n",
      "-----------\n",
      "Epoch: 7100, Loss: 1.9453689682738409, Accuracy: 0.5048828125\n",
      "Epoch: 7200, Loss: 1.9588315654668171, Accuracy: 0.4990234375\n",
      "Epoch: 7300, Loss: 1.9168860994131662, Accuracy: 0.5107421875\n",
      "Epoch: 7400, Loss: 1.9274974319713414, Accuracy: 0.5234375\n",
      "Epoch: 7500, Loss: 1.953973026476194, Accuracy: 0.4990234375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 7500, Momentum: True\n",
      "Val Loss: 1.9919457380067978, Val Accuracy: 0.48793333333333333\n",
      "-----------\n",
      "Epoch: 7600, Loss: 1.973826414661111, Accuracy: 0.4970703125\n",
      "Epoch: 7700, Loss: 1.8636611322679986, Accuracy: 0.544921875\n",
      "Epoch: 7800, Loss: 1.9325448981297768, Accuracy: 0.5029296875\n",
      "Epoch: 7900, Loss: 2.0294778763307324, Accuracy: 0.4794921875\n",
      "Epoch: 8000, Loss: 1.9216610681798043, Accuracy: 0.494140625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 8000, Momentum: True\n",
      "Val Loss: 1.988083237516022, Val Accuracy: 0.4866333333333333\n",
      "-----------\n",
      "Epoch: 8100, Loss: 1.9725112129740325, Accuracy: 0.48828125\n",
      "Epoch: 8200, Loss: 1.9480286872514259, Accuracy: 0.501953125\n",
      "Epoch: 8300, Loss: 1.9822072120657224, Accuracy: 0.4990234375\n",
      "Epoch: 8400, Loss: 1.9129569724742976, Accuracy: 0.5234375\n",
      "Epoch: 8500, Loss: 1.9864849631006591, Accuracy: 0.501953125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 8500, Momentum: True\n",
      "Val Loss: 1.985596357244424, Val Accuracy: 0.4867666666666667\n",
      "-----------\n",
      "Epoch: 8600, Loss: 1.9792082753981528, Accuracy: 0.501953125\n",
      "Epoch: 8700, Loss: 1.9055764189484115, Accuracy: 0.525390625\n",
      "Epoch: 8800, Loss: 1.9601673860131803, Accuracy: 0.4853515625\n",
      "Epoch: 8900, Loss: 1.9513101705661189, Accuracy: 0.501953125\n",
      "Epoch: 9000, Loss: 1.9473498267804503, Accuracy: 0.501953125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 9000, Momentum: True\n",
      "Val Loss: 1.983440121403032, Val Accuracy: 0.48923333333333335\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9100, Loss: 2.030940438553653, Accuracy: 0.4765625\n",
      "Epoch: 9200, Loss: 1.9115373321588067, Accuracy: 0.5224609375\n",
      "Epoch: 9300, Loss: 1.9268676395214994, Accuracy: 0.4990234375\n",
      "Epoch: 9400, Loss: 1.919728746647035, Accuracy: 0.5087890625\n",
      "Epoch: 9500, Loss: 1.886151323351974, Accuracy: 0.5322265625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 9500, Momentum: True\n",
      "Val Loss: 1.9830409946926446, Val Accuracy: 0.4887666666666667\n",
      "-----------\n",
      "Epoch: 9600, Loss: 1.9861000971622966, Accuracy: 0.486328125\n",
      "Epoch: 9700, Loss: 1.9865080385548863, Accuracy: 0.48828125\n",
      "Epoch: 9800, Loss: 1.924077257713741, Accuracy: 0.4990234375\n",
      "Epoch: 9900, Loss: 1.992335665187602, Accuracy: 0.474609375\n",
      "Epoch: 10000, Loss: 1.9252263419733837, Accuracy: 0.5107421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 10000, Momentum: True\n",
      "Val Loss: 1.9820552700591456, Val Accuracy: 0.488\n",
      "-----------\n",
      "Epoch: 10100, Loss: 1.9065433185319316, Accuracy: 0.53125\n",
      "Epoch: 10200, Loss: 1.9365452681467357, Accuracy: 0.5244140625\n",
      "Epoch: 10300, Loss: 1.9287497642146734, Accuracy: 0.5146484375\n",
      "Epoch: 10400, Loss: 1.9536955532102553, Accuracy: 0.4814453125\n",
      "Epoch: 10500, Loss: 1.9437540581036465, Accuracy: 0.521484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 10500, Momentum: True\n",
      "Val Loss: 1.9812037930733135, Val Accuracy: 0.48786666666666667\n",
      "-----------\n",
      "Epoch: 10600, Loss: 2.020728285324048, Accuracy: 0.4892578125\n",
      "Epoch: 10700, Loss: 1.9244223472141075, Accuracy: 0.5\n",
      "Epoch: 10800, Loss: 1.9824405757834413, Accuracy: 0.498046875\n",
      "Epoch: 10900, Loss: 1.9044951426500516, Accuracy: 0.521484375\n",
      "Epoch: 11000, Loss: 1.9252443470369789, Accuracy: 0.513671875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 11000, Momentum: True\n",
      "Val Loss: 1.9815551226474746, Val Accuracy: 0.4905\n",
      "-----------\n",
      "Epoch: 11100, Loss: 1.909190412692704, Accuracy: 0.5107421875\n",
      "Epoch: 11200, Loss: 1.9849254237677054, Accuracy: 0.486328125\n",
      "Epoch: 11300, Loss: 1.8822503972404032, Accuracy: 0.537109375\n",
      "Epoch: 11400, Loss: 1.9670273440247015, Accuracy: 0.494140625\n",
      "Epoch: 11500, Loss: 1.9368386278937295, Accuracy: 0.5087890625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 11500, Momentum: True\n",
      "Val Loss: 1.9815911812211795, Val Accuracy: 0.48793333333333333\n",
      "-----------\n",
      "Epoch: 11600, Loss: 1.9673335791996331, Accuracy: 0.484375\n",
      "Epoch: 11700, Loss: 1.9464418649778616, Accuracy: 0.4990234375\n",
      "Epoch: 11800, Loss: 1.8887009240595451, Accuracy: 0.529296875\n",
      "Epoch: 11900, Loss: 1.9570997168680648, Accuracy: 0.4970703125\n",
      "Epoch: 12000, Loss: 1.9574909624977126, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 12000, Momentum: True\n",
      "Val Loss: 1.981751321063856, Val Accuracy: 0.4875333333333333\n",
      "-----------\n",
      "Epoch: 12100, Loss: 1.9274412473709284, Accuracy: 0.5048828125\n",
      "Epoch: 12200, Loss: 1.931347019348255, Accuracy: 0.5009765625\n",
      "Epoch: 12300, Loss: 1.9569823518420466, Accuracy: 0.482421875\n",
      "Epoch: 12400, Loss: 1.8836481664219398, Accuracy: 0.5537109375\n",
      "Epoch: 12500, Loss: 1.9316468022819087, Accuracy: 0.4873046875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 12500, Momentum: True\n",
      "Val Loss: 1.9821591026851664, Val Accuracy: 0.4881\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.888613899622976, Accuracy: 0.5078125\n",
      "Epoch: 12700, Loss: 1.914885841779118, Accuracy: 0.5185546875\n",
      "Epoch: 12800, Loss: 1.944722787033763, Accuracy: 0.494140625\n",
      "Epoch: 12900, Loss: 1.911564532215469, Accuracy: 0.5087890625\n",
      "Epoch: 13000, Loss: 1.913200453153807, Accuracy: 0.509765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 13000, Momentum: True\n",
      "Val Loss: 1.9811332213599677, Val Accuracy: 0.4889\n",
      "-----------\n",
      "Epoch: 13100, Loss: 1.9152893626998249, Accuracy: 0.509765625\n",
      "Epoch: 13200, Loss: 1.919937589282491, Accuracy: 0.515625\n",
      "Epoch: 13300, Loss: 1.9374476552410747, Accuracy: 0.490234375\n",
      "Epoch: 13400, Loss: 1.8914660493795834, Accuracy: 0.5107421875\n",
      "Epoch: 13500, Loss: 1.9460856074024184, Accuracy: 0.484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 13500, Momentum: True\n",
      "Val Loss: 1.9813212481151519, Val Accuracy: 0.48823333333333335\n",
      "-----------\n",
      "Epoch: 13600, Loss: 1.9359739868026868, Accuracy: 0.5048828125\n",
      "Epoch: 13700, Loss: 1.9629217456048185, Accuracy: 0.48828125\n",
      "Epoch: 13800, Loss: 1.8554173792806963, Accuracy: 0.5400390625\n",
      "Epoch: 13900, Loss: 1.9907842151629693, Accuracy: 0.4775390625\n",
      "Epoch: 14000, Loss: 1.878028130418121, Accuracy: 0.5390625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 14000, Momentum: True\n",
      "Val Loss: 1.9818524864170346, Val Accuracy: 0.4886\n",
      "-----------\n",
      "Epoch: 14100, Loss: 1.9406897797633373, Accuracy: 0.5068359375\n",
      "Epoch: 14200, Loss: 1.909797473808656, Accuracy: 0.5263671875\n",
      "Epoch: 14300, Loss: 1.9419266073208612, Accuracy: 0.498046875\n",
      "Epoch: 14400, Loss: 1.9263581108860666, Accuracy: 0.501953125\n",
      "Epoch: 14500, Loss: 1.9857696215263156, Accuracy: 0.4892578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 14500, Momentum: True\n",
      "Val Loss: 1.9826111727035491, Val Accuracy: 0.48896666666666666\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.8960885891971824, Accuracy: 0.5302734375\n",
      "Epoch: 14700, Loss: 1.983830825368385, Accuracy: 0.48046875\n",
      "Epoch: 14800, Loss: 1.8145342119688534, Accuracy: 0.533203125\n",
      "Epoch: 14900, Loss: 1.9129339497803735, Accuracy: 0.5185546875\n",
      "Epoch: 15000, Loss: 2.01437632183715, Accuracy: 0.4716796875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 15000, Momentum: True\n",
      "Val Loss: 1.983341434877669, Val Accuracy: 0.48743333333333333\n",
      "-----------\n",
      "Epoch: 15100, Loss: 1.9659637453056575, Accuracy: 0.490234375\n",
      "Epoch: 15200, Loss: 1.9431871805123075, Accuracy: 0.4970703125\n",
      "Epoch: 15300, Loss: 1.9935466985523447, Accuracy: 0.4833984375\n",
      "Epoch: 15400, Loss: 1.9587068179996745, Accuracy: 0.5087890625\n",
      "Epoch: 15500, Loss: 1.9823757948102876, Accuracy: 0.4892578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 15500, Momentum: True\n",
      "Val Loss: 1.9836030338077764, Val Accuracy: 0.49006666666666665\n",
      "-----------\n",
      "Epoch: 15600, Loss: 1.9361801064820203, Accuracy: 0.5\n",
      "Epoch: 15700, Loss: 1.8807862991840834, Accuracy: 0.5205078125\n",
      "Epoch: 15800, Loss: 1.902788817930359, Accuracy: 0.505859375\n",
      "Epoch: 15900, Loss: 1.9505054138227513, Accuracy: 0.4951171875\n",
      "Epoch: 16000, Loss: 1.97555385488634, Accuracy: 0.4892578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 16000, Momentum: True\n",
      "Val Loss: 1.9835789240806427, Val Accuracy: 0.48906666666666665\n",
      "-----------\n",
      "Epoch: 16100, Loss: 1.8899984052826169, Accuracy: 0.5322265625\n",
      "Epoch: 16200, Loss: 1.9300993062416087, Accuracy: 0.5078125\n",
      "Epoch: 16300, Loss: 1.9110779525580657, Accuracy: 0.5048828125\n",
      "Epoch: 16400, Loss: 1.9433636306023352, Accuracy: 0.517578125\n",
      "Epoch: 16500, Loss: 2.01575705744388, Accuracy: 0.478515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 16500, Momentum: True\n",
      "Val Loss: 1.9841316746469342, Val Accuracy: 0.48906666666666665\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.9246532688637967, Accuracy: 0.515625\n",
      "Epoch: 16700, Loss: 1.9193894544744752, Accuracy: 0.50390625\n",
      "Epoch: 16800, Loss: 1.9903726515564448, Accuracy: 0.494140625\n",
      "Epoch: 16900, Loss: 1.926024472120551, Accuracy: 0.5048828125\n",
      "Epoch: 17000, Loss: 1.9558122634125257, Accuracy: 0.4970703125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 17000, Momentum: True\n",
      "Val Loss: 1.9848265334585862, Val Accuracy: 0.4884\n",
      "-----------\n",
      "Epoch: 17100, Loss: 1.9384655470221088, Accuracy: 0.5029296875\n",
      "Epoch: 17200, Loss: 1.9449330624209509, Accuracy: 0.515625\n",
      "Epoch: 17300, Loss: 1.9767236023310386, Accuracy: 0.49609375\n",
      "Epoch: 17400, Loss: 1.8987041929612616, Accuracy: 0.52734375\n",
      "Epoch: 17500, Loss: 1.9124212796830773, Accuracy: 0.501953125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 17500, Momentum: True\n",
      "Val Loss: 1.985405068389708, Val Accuracy: 0.4876666666666667\n",
      "-----------\n",
      "Epoch: 17600, Loss: 2.0020635023316236, Accuracy: 0.4921875\n",
      "Epoch: 17700, Loss: 1.9662917110275513, Accuracy: 0.4951171875\n",
      "Epoch: 17800, Loss: 1.989037319928289, Accuracy: 0.4853515625\n",
      "Epoch: 17900, Loss: 1.8754332388897132, Accuracy: 0.513671875\n",
      "Epoch: 18000, Loss: 1.9762582709022325, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 18000, Momentum: True\n",
      "Val Loss: 1.9867585798647236, Val Accuracy: 0.48596666666666666\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18100, Loss: 2.0279335373920726, Accuracy: 0.470703125\n",
      "Epoch: 18200, Loss: 1.8806488504632806, Accuracy: 0.525390625\n",
      "Epoch: 18300, Loss: 2.0052727662432726, Accuracy: 0.4853515625\n",
      "Epoch: 18400, Loss: 1.9388090853382804, Accuracy: 0.4873046875\n",
      "Epoch: 18500, Loss: 1.9046324263371182, Accuracy: 0.5234375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 18500, Momentum: True\n",
      "Val Loss: 1.9868544642951869, Val Accuracy: 0.48706666666666665\n",
      "-----------\n",
      "Epoch: 18600, Loss: 1.9729940829279216, Accuracy: 0.4951171875\n",
      "Epoch: 18700, Loss: 1.9330228866762342, Accuracy: 0.5185546875\n",
      "Epoch: 18800, Loss: 1.9706856649123345, Accuracy: 0.4677734375\n",
      "Epoch: 18900, Loss: 1.9418358230325614, Accuracy: 0.5166015625\n",
      "Epoch: 19000, Loss: 1.9220988442348397, Accuracy: 0.5302734375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 19000, Momentum: True\n",
      "Val Loss: 1.9869236579275387, Val Accuracy: 0.488\n",
      "-----------\n",
      "Epoch: 19100, Loss: 1.9569430632704599, Accuracy: 0.49609375\n",
      "Epoch: 19200, Loss: 2.065742869935362, Accuracy: 0.45703125\n",
      "Epoch: 19300, Loss: 1.9124768674900872, Accuracy: 0.5087890625\n",
      "Epoch: 19400, Loss: 1.9854376318507696, Accuracy: 0.4765625\n",
      "Epoch: 19500, Loss: 1.9305304571054664, Accuracy: 0.5029296875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 19500, Momentum: True\n",
      "Val Loss: 1.9876471256128039, Val Accuracy: 0.4875\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.9970572731741365, Accuracy: 0.4794921875\n",
      "Epoch: 19700, Loss: 1.8972815587537957, Accuracy: 0.5029296875\n",
      "Epoch: 19800, Loss: 1.9519978195123593, Accuracy: 0.50390625\n",
      "Epoch: 19900, Loss: 1.9969819110587441, Accuracy: 0.490234375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 11000, Momentum: True\n",
      "Test Loss: 2.005704352071947, Test Accuracy: 0.4841868562309589\n",
      "-----------\n",
      "Epoch: 0, Loss: 11.990639147305796, Accuracy: 0.02734375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 0, Momentum: False\n",
      "Val Loss: 8.956024511052942, Val Accuracy: 0.05386666666666667\n",
      "-----------\n",
      "Epoch: 100, Loss: 5.680567362955625, Accuracy: 0.0986328125\n",
      "Epoch: 200, Loss: 4.529280792808135, Accuracy: 0.12109375\n",
      "Epoch: 300, Loss: 4.538026081923034, Accuracy: 0.123046875\n",
      "Epoch: 400, Loss: 3.757626637508684, Accuracy: 0.1650390625\n",
      "Epoch: 500, Loss: 3.4713576881822608, Accuracy: 0.1806640625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 500, Momentum: False\n",
      "Val Loss: 3.4029228200999446, Val Accuracy: 0.199\n",
      "-----------\n",
      "Epoch: 600, Loss: 3.3080087954476087, Accuracy: 0.2109375\n",
      "Epoch: 700, Loss: 3.211061132841146, Accuracy: 0.2177734375\n",
      "Epoch: 800, Loss: 3.0777722467441313, Accuracy: 0.251953125\n",
      "Epoch: 900, Loss: 3.042530054237953, Accuracy: 0.2431640625\n",
      "Epoch: 1000, Loss: 2.7891273188726946, Accuracy: 0.2802734375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 1000, Momentum: False\n",
      "Val Loss: 2.8948734525213795, Val Accuracy: 0.27086666666666664\n",
      "-----------\n",
      "Epoch: 1100, Loss: 2.757911283360378, Accuracy: 0.2890625\n",
      "Epoch: 1200, Loss: 2.674606909648544, Accuracy: 0.2939453125\n",
      "Epoch: 1300, Loss: 2.710264178665895, Accuracy: 0.296875\n",
      "Epoch: 1400, Loss: 2.6644698782976963, Accuracy: 0.3017578125\n",
      "Epoch: 1500, Loss: 2.569658187278039, Accuracy: 0.330078125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 1500, Momentum: False\n",
      "Val Loss: 2.591968516813648, Val Accuracy: 0.32153333333333334\n",
      "-----------\n",
      "Epoch: 1600, Loss: 2.651621822999886, Accuracy: 0.3291015625\n",
      "Epoch: 1700, Loss: 2.4790882176552946, Accuracy: 0.3642578125\n",
      "Epoch: 1800, Loss: 2.4695157783670583, Accuracy: 0.345703125\n",
      "Epoch: 1900, Loss: 2.4444893128638894, Accuracy: 0.3603515625\n",
      "Epoch: 2000, Loss: 2.393056236389408, Accuracy: 0.37109375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 2000, Momentum: False\n",
      "Val Loss: 2.4250079094295054, Val Accuracy: 0.3640333333333333\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.3598221181734935, Accuracy: 0.3916015625\n",
      "Epoch: 2200, Loss: 2.288376474140677, Accuracy: 0.3779296875\n",
      "Epoch: 2300, Loss: 2.328713120797864, Accuracy: 0.396484375\n",
      "Epoch: 2400, Loss: 2.3234326765266315, Accuracy: 0.380859375\n",
      "Epoch: 2500, Loss: 2.2283133489748974, Accuracy: 0.412109375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 2500, Momentum: False\n",
      "Val Loss: 2.3144098213371422, Val Accuracy: 0.3920666666666667\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.2937835227398584, Accuracy: 0.396484375\n",
      "Epoch: 2700, Loss: 2.2763564213860894, Accuracy: 0.40625\n",
      "Epoch: 2800, Loss: 2.252696169988747, Accuracy: 0.4169921875\n",
      "Epoch: 2900, Loss: 2.2247766361750116, Accuracy: 0.4189453125\n",
      "Epoch: 3000, Loss: 2.210146827203773, Accuracy: 0.4404296875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 3000, Momentum: False\n",
      "Val Loss: 2.2555139161783777, Val Accuracy: 0.40676666666666667\n",
      "-----------\n",
      "Epoch: 3100, Loss: 2.181932765531763, Accuracy: 0.4189453125\n",
      "Epoch: 3200, Loss: 2.136951671750873, Accuracy: 0.443359375\n",
      "Epoch: 3300, Loss: 2.156431503742433, Accuracy: 0.4296875\n",
      "Epoch: 3400, Loss: 2.224500504113001, Accuracy: 0.4267578125\n",
      "Epoch: 3500, Loss: 2.1721594019157147, Accuracy: 0.4228515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 3500, Momentum: False\n",
      "Val Loss: 2.199907694774241, Val Accuracy: 0.42583333333333334\n",
      "-----------\n",
      "Epoch: 3600, Loss: 2.1053016203909984, Accuracy: 0.466796875\n",
      "Epoch: 3700, Loss: 2.104727082452392, Accuracy: 0.4453125\n",
      "Epoch: 3800, Loss: 2.184465211089332, Accuracy: 0.435546875\n",
      "Epoch: 3900, Loss: 2.07227844473468, Accuracy: 0.470703125\n",
      "Epoch: 4000, Loss: 2.2168981193516037, Accuracy: 0.4365234375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 4000, Momentum: False\n",
      "Val Loss: 2.160961529218957, Val Accuracy: 0.43556666666666666\n",
      "-----------\n",
      "Epoch: 4100, Loss: 2.1618189277868556, Accuracy: 0.447265625\n",
      "Epoch: 4200, Loss: 2.046930303442853, Accuracy: 0.4619140625\n",
      "Epoch: 4300, Loss: 2.1293305992586444, Accuracy: 0.4287109375\n",
      "Epoch: 4400, Loss: 2.0731836682497344, Accuracy: 0.462890625\n",
      "Epoch: 4500, Loss: 2.092577703806863, Accuracy: 0.46875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 4500, Momentum: False\n",
      "Val Loss: 2.133315358096071, Val Accuracy: 0.4448\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.0538356066648062, Accuracy: 0.4560546875\n",
      "Epoch: 4700, Loss: 2.003536755727275, Accuracy: 0.482421875\n",
      "Epoch: 4800, Loss: 2.134269495001302, Accuracy: 0.4248046875\n",
      "Epoch: 4900, Loss: 2.10277673541935, Accuracy: 0.45703125\n",
      "Epoch: 5000, Loss: 2.0664537288773426, Accuracy: 0.455078125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 5000, Momentum: False\n",
      "Val Loss: 2.111557571065307, Val Accuracy: 0.4493666666666667\n",
      "-----------\n",
      "Epoch: 5100, Loss: 2.0963907392178127, Accuracy: 0.4541015625\n",
      "Epoch: 5200, Loss: 2.0673336882945357, Accuracy: 0.4541015625\n",
      "Epoch: 5300, Loss: 2.0638280842868406, Accuracy: 0.4697265625\n",
      "Epoch: 5400, Loss: 1.998226322892585, Accuracy: 0.4736328125\n",
      "Epoch: 5500, Loss: 2.0403602236482334, Accuracy: 0.474609375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 5500, Momentum: False\n",
      "Val Loss: 2.098214760592842, Val Accuracy: 0.4538333333333333\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.009858087278055, Accuracy: 0.4833984375\n",
      "Epoch: 5700, Loss: 2.0407014567926263, Accuracy: 0.4677734375\n",
      "Epoch: 5800, Loss: 2.018373942027474, Accuracy: 0.486328125\n",
      "Epoch: 5900, Loss: 2.072834075074387, Accuracy: 0.4443359375\n",
      "Epoch: 6000, Loss: 2.0378543784702092, Accuracy: 0.470703125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 6000, Momentum: False\n",
      "Val Loss: 2.0796712941165048, Val Accuracy: 0.4619333333333333\n",
      "-----------\n",
      "Epoch: 6100, Loss: 2.0578297058768644, Accuracy: 0.470703125\n",
      "Epoch: 6200, Loss: 2.0026021491783474, Accuracy: 0.4853515625\n",
      "Epoch: 6300, Loss: 2.0271969720488325, Accuracy: 0.4755859375\n",
      "Epoch: 6400, Loss: 2.0095811182713827, Accuracy: 0.4833984375\n",
      "Epoch: 6500, Loss: 2.1162338605056297, Accuracy: 0.4501953125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 6500, Momentum: False\n",
      "Val Loss: 2.065957105959064, Val Accuracy: 0.4649\n",
      "-----------\n",
      "Epoch: 6600, Loss: 1.9727730185867778, Accuracy: 0.5\n",
      "Epoch: 6700, Loss: 2.030554303050729, Accuracy: 0.4873046875\n",
      "Epoch: 6800, Loss: 1.986594914806747, Accuracy: 0.4853515625\n",
      "Epoch: 6900, Loss: 2.045415873875397, Accuracy: 0.48046875\n",
      "Epoch: 7000, Loss: 2.041002134842523, Accuracy: 0.4716796875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 7000, Momentum: False\n",
      "Val Loss: 2.0561830680912885, Val Accuracy: 0.466\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7100, Loss: 1.9640208560036054, Accuracy: 0.5029296875\n",
      "Epoch: 7200, Loss: 1.9421643544551488, Accuracy: 0.5\n",
      "Epoch: 7300, Loss: 2.0004750737172703, Accuracy: 0.4736328125\n",
      "Epoch: 7400, Loss: 1.9980644415834505, Accuracy: 0.4736328125\n",
      "Epoch: 7500, Loss: 2.0718848812011066, Accuracy: 0.4765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 7500, Momentum: False\n",
      "Val Loss: 2.046223990055186, Val Accuracy: 0.47036666666666666\n",
      "-----------\n",
      "Epoch: 7600, Loss: 1.9513433583245856, Accuracy: 0.515625\n",
      "Epoch: 7700, Loss: 2.002548088419575, Accuracy: 0.4697265625\n",
      "Epoch: 7800, Loss: 2.0152168275778037, Accuracy: 0.482421875\n",
      "Epoch: 7900, Loss: 1.9716410587489366, Accuracy: 0.494140625\n",
      "Epoch: 8000, Loss: 2.0171273866264943, Accuracy: 0.490234375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 8000, Momentum: False\n",
      "Val Loss: 2.038467581264859, Val Accuracy: 0.4734333333333333\n",
      "-----------\n",
      "Epoch: 8100, Loss: 1.9915100171361133, Accuracy: 0.505859375\n",
      "Epoch: 8200, Loss: 1.8776355726475742, Accuracy: 0.5234375\n",
      "Epoch: 8300, Loss: 1.989491697858595, Accuracy: 0.486328125\n",
      "Epoch: 8400, Loss: 1.9350356665204247, Accuracy: 0.5107421875\n",
      "Epoch: 8500, Loss: 1.969990013841333, Accuracy: 0.48046875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 8500, Momentum: False\n",
      "Val Loss: 2.0316588502242157, Val Accuracy: 0.4744333333333333\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.0361736992611856, Accuracy: 0.4755859375\n",
      "Epoch: 8700, Loss: 2.0055527424962163, Accuracy: 0.482421875\n",
      "Epoch: 8800, Loss: 2.0195606207971215, Accuracy: 0.48046875\n",
      "Epoch: 8900, Loss: 2.002481956990583, Accuracy: 0.478515625\n",
      "Epoch: 9000, Loss: 1.9670877163151284, Accuracy: 0.4951171875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 9000, Momentum: False\n",
      "Val Loss: 2.02594220868861, Val Accuracy: 0.4755666666666667\n",
      "-----------\n",
      "Epoch: 9100, Loss: 2.000676493435907, Accuracy: 0.490234375\n",
      "Epoch: 9200, Loss: 1.9620530101819564, Accuracy: 0.484375\n",
      "Epoch: 9300, Loss: 2.0274101709018497, Accuracy: 0.4853515625\n",
      "Epoch: 9400, Loss: 2.00871803021726, Accuracy: 0.474609375\n",
      "Epoch: 9500, Loss: 2.0169019108871726, Accuracy: 0.4794921875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 9500, Momentum: False\n",
      "Val Loss: 2.0184421089232063, Val Accuracy: 0.4785\n",
      "-----------\n",
      "Epoch: 9600, Loss: 1.9847253565801117, Accuracy: 0.482421875\n",
      "Epoch: 9700, Loss: 1.9831891995427509, Accuracy: 0.482421875\n",
      "Epoch: 9800, Loss: 1.9927207727038838, Accuracy: 0.478515625\n",
      "Epoch: 9900, Loss: 2.0007823277308585, Accuracy: 0.4833984375\n",
      "Epoch: 10000, Loss: 1.9428296107771865, Accuracy: 0.513671875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 10000, Momentum: False\n",
      "Val Loss: 2.014039863693653, Val Accuracy: 0.4793\n",
      "-----------\n",
      "Epoch: 10100, Loss: 1.953821956389329, Accuracy: 0.49609375\n",
      "Epoch: 10200, Loss: 1.9756221565142023, Accuracy: 0.4814453125\n",
      "Epoch: 10300, Loss: 1.9403832339082911, Accuracy: 0.5107421875\n",
      "Epoch: 10400, Loss: 1.994209059075359, Accuracy: 0.486328125\n",
      "Epoch: 10500, Loss: 1.9737454048131773, Accuracy: 0.4755859375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 10500, Momentum: False\n",
      "Val Loss: 2.0097004196713546, Val Accuracy: 0.48183333333333334\n",
      "-----------\n",
      "Epoch: 10600, Loss: 1.9196719617293674, Accuracy: 0.5361328125\n",
      "Epoch: 10700, Loss: 1.9785586652796168, Accuracy: 0.490234375\n",
      "Epoch: 10800, Loss: 2.0130519157704594, Accuracy: 0.4755859375\n",
      "Epoch: 10900, Loss: 1.9670874281248154, Accuracy: 0.4873046875\n",
      "Epoch: 11000, Loss: 1.914540291849848, Accuracy: 0.513671875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 11000, Momentum: False\n",
      "Val Loss: 2.0051165311473205, Val Accuracy: 0.48123333333333335\n",
      "-----------\n",
      "Epoch: 11100, Loss: 1.9835683716600816, Accuracy: 0.5009765625\n",
      "Epoch: 11200, Loss: 2.030610715941015, Accuracy: 0.4794921875\n",
      "Epoch: 11300, Loss: 1.9736613081880097, Accuracy: 0.4951171875\n",
      "Epoch: 11400, Loss: 2.0330335600126506, Accuracy: 0.4638671875\n",
      "Epoch: 11500, Loss: 1.9904306406100643, Accuracy: 0.474609375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 11500, Momentum: False\n",
      "Val Loss: 2.002871691035405, Val Accuracy: 0.4843\n",
      "-----------\n",
      "Epoch: 11600, Loss: 2.0049642861716146, Accuracy: 0.46875\n",
      "Epoch: 11700, Loss: 1.8944423890719457, Accuracy: 0.51171875\n",
      "Epoch: 11800, Loss: 1.9496849868802721, Accuracy: 0.5126953125\n",
      "Epoch: 11900, Loss: 1.9761679385537496, Accuracy: 0.5126953125\n",
      "Epoch: 12000, Loss: 1.9549885563774339, Accuracy: 0.509765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 12000, Momentum: False\n",
      "Val Loss: 1.9991751616512818, Val Accuracy: 0.48306666666666664\n",
      "-----------\n",
      "Epoch: 12100, Loss: 1.9460445862495728, Accuracy: 0.494140625\n",
      "Epoch: 12200, Loss: 1.8854390331919118, Accuracy: 0.513671875\n",
      "Epoch: 12300, Loss: 1.9503419962946156, Accuracy: 0.4921875\n",
      "Epoch: 12400, Loss: 1.9594197181461983, Accuracy: 0.5\n",
      "Epoch: 12500, Loss: 2.0026788730649376, Accuracy: 0.48046875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 12500, Momentum: False\n",
      "Val Loss: 1.997116264309061, Val Accuracy: 0.488\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.982220433162669, Accuracy: 0.4931640625\n",
      "Epoch: 12700, Loss: 1.9544376540836534, Accuracy: 0.4921875\n",
      "Epoch: 12800, Loss: 1.9799808449331462, Accuracy: 0.470703125\n",
      "Epoch: 12900, Loss: 1.9025898299832382, Accuracy: 0.5146484375\n",
      "Epoch: 13000, Loss: 1.9824219617955752, Accuracy: 0.482421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 13000, Momentum: False\n",
      "Val Loss: 1.994067029132519, Val Accuracy: 0.4873\n",
      "-----------\n",
      "Epoch: 13100, Loss: 1.9555371235969436, Accuracy: 0.5166015625\n",
      "Epoch: 13200, Loss: 1.9717815520711817, Accuracy: 0.490234375\n",
      "Epoch: 13300, Loss: 1.9826094850349034, Accuracy: 0.5009765625\n",
      "Epoch: 13400, Loss: 1.9390311080088636, Accuracy: 0.494140625\n",
      "Epoch: 13500, Loss: 1.8945323277277968, Accuracy: 0.5146484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 13500, Momentum: False\n",
      "Val Loss: 1.9924677282771717, Val Accuracy: 0.4868\n",
      "-----------\n",
      "Epoch: 13600, Loss: 1.9539492424992508, Accuracy: 0.513671875\n",
      "Epoch: 13700, Loss: 1.9684491023261175, Accuracy: 0.4921875\n",
      "Epoch: 13800, Loss: 1.993078837660371, Accuracy: 0.4873046875\n",
      "Epoch: 13900, Loss: 1.9885138651163352, Accuracy: 0.490234375\n",
      "Epoch: 14000, Loss: 1.9468783090935002, Accuracy: 0.494140625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 14000, Momentum: False\n",
      "Val Loss: 1.9906509553835234, Val Accuracy: 0.4865333333333333\n",
      "-----------\n",
      "Epoch: 14100, Loss: 1.9071488028934769, Accuracy: 0.5068359375\n",
      "Epoch: 14200, Loss: 1.9800661871664869, Accuracy: 0.4775390625\n",
      "Epoch: 14300, Loss: 1.9725398251608102, Accuracy: 0.48828125\n",
      "Epoch: 14400, Loss: 1.9474621684485713, Accuracy: 0.51171875\n",
      "Epoch: 14500, Loss: 1.9746879746901882, Accuracy: 0.48828125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 14500, Momentum: False\n",
      "Val Loss: 1.9888109348672667, Val Accuracy: 0.48806666666666665\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.928893784053945, Accuracy: 0.5029296875\n",
      "Epoch: 14700, Loss: 1.8931703376348774, Accuracy: 0.5234375\n",
      "Epoch: 14800, Loss: 1.9012883476573097, Accuracy: 0.517578125\n",
      "Epoch: 14900, Loss: 1.9279990487828522, Accuracy: 0.5126953125\n",
      "Epoch: 15000, Loss: 1.9631973363739674, Accuracy: 0.4892578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 15000, Momentum: False\n",
      "Val Loss: 1.9870386062746601, Val Accuracy: 0.4872666666666667\n",
      "-----------\n",
      "Epoch: 15100, Loss: 1.9540862790412348, Accuracy: 0.4814453125\n",
      "Epoch: 15200, Loss: 1.8438616894114772, Accuracy: 0.55078125\n",
      "Epoch: 15300, Loss: 1.995471407310605, Accuracy: 0.5009765625\n",
      "Epoch: 15400, Loss: 1.977984845162319, Accuracy: 0.484375\n",
      "Epoch: 15500, Loss: 2.0265746333923524, Accuracy: 0.478515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 15500, Momentum: False\n",
      "Val Loss: 1.9863896708433852, Val Accuracy: 0.4877666666666667\n",
      "-----------\n",
      "Epoch: 15600, Loss: 1.9856412593567327, Accuracy: 0.490234375\n",
      "Epoch: 15700, Loss: 1.9438252080117406, Accuracy: 0.513671875\n",
      "Epoch: 15800, Loss: 1.9929731417060736, Accuracy: 0.494140625\n",
      "Epoch: 15900, Loss: 1.9953874208916706, Accuracy: 0.4814453125\n",
      "Epoch: 16000, Loss: 1.954668816218963, Accuracy: 0.517578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 16000, Momentum: False\n",
      "Val Loss: 1.9844943838856344, Val Accuracy: 0.4882666666666667\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16100, Loss: 1.9764510316067114, Accuracy: 0.48046875\n",
      "Epoch: 16200, Loss: 1.8726514169966144, Accuracy: 0.53125\n",
      "Epoch: 16300, Loss: 1.9717863253206025, Accuracy: 0.501953125\n",
      "Epoch: 16400, Loss: 1.9393936749115435, Accuracy: 0.4970703125\n",
      "Epoch: 16500, Loss: 1.9430322588807165, Accuracy: 0.498046875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 16500, Momentum: False\n",
      "Val Loss: 1.983429202337306, Val Accuracy: 0.48873333333333335\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.9053364292589494, Accuracy: 0.5146484375\n",
      "Epoch: 16700, Loss: 1.9317856452805737, Accuracy: 0.5029296875\n",
      "Epoch: 16800, Loss: 1.913593417840111, Accuracy: 0.5126953125\n",
      "Epoch: 16900, Loss: 1.9526557913186284, Accuracy: 0.4912109375\n",
      "Epoch: 17000, Loss: 1.96238645803615, Accuracy: 0.5068359375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 17000, Momentum: False\n",
      "Val Loss: 1.9827073259895625, Val Accuracy: 0.4908666666666667\n",
      "-----------\n",
      "Epoch: 17100, Loss: 1.9122772572242546, Accuracy: 0.5205078125\n",
      "Epoch: 17200, Loss: 1.9287604139237104, Accuracy: 0.5078125\n",
      "Epoch: 17300, Loss: 1.9535737372917357, Accuracy: 0.5087890625\n",
      "Epoch: 17400, Loss: 1.9335422032874616, Accuracy: 0.4921875\n",
      "Epoch: 17500, Loss: 1.972285017780111, Accuracy: 0.494140625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 17500, Momentum: False\n",
      "Val Loss: 1.9827656138200735, Val Accuracy: 0.48966666666666664\n",
      "-----------\n",
      "Epoch: 17600, Loss: 1.982711886106567, Accuracy: 0.486328125\n",
      "Epoch: 17700, Loss: 1.9206685777965713, Accuracy: 0.5126953125\n",
      "Epoch: 17800, Loss: 1.9467721375534688, Accuracy: 0.51171875\n",
      "Epoch: 17900, Loss: 1.9783932693072308, Accuracy: 0.5087890625\n",
      "Epoch: 18000, Loss: 1.9502049510264303, Accuracy: 0.49609375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 18000, Momentum: False\n",
      "Val Loss: 1.981859990999047, Val Accuracy: 0.4886333333333333\n",
      "-----------\n",
      "Epoch: 18100, Loss: 1.956399546283073, Accuracy: 0.482421875\n",
      "Epoch: 18200, Loss: 1.8819634832102086, Accuracy: 0.509765625\n",
      "Epoch: 18300, Loss: 2.0221949166487616, Accuracy: 0.4580078125\n",
      "Epoch: 18400, Loss: 1.8987663082998414, Accuracy: 0.525390625\n",
      "Epoch: 18500, Loss: 1.9641988098168746, Accuracy: 0.5126953125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 18500, Momentum: False\n",
      "Val Loss: 1.9817690224440392, Val Accuracy: 0.4877\n",
      "-----------\n",
      "Epoch: 18600, Loss: 2.025969704256708, Accuracy: 0.4794921875\n",
      "Epoch: 18700, Loss: 2.016620752210568, Accuracy: 0.486328125\n",
      "Epoch: 18800, Loss: 2.0378203777090427, Accuracy: 0.4677734375\n",
      "Epoch: 18900, Loss: 1.8804764969609762, Accuracy: 0.521484375\n",
      "Epoch: 19000, Loss: 1.9838351515239472, Accuracy: 0.501953125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 19000, Momentum: False\n",
      "Val Loss: 1.9811599361172723, Val Accuracy: 0.4892666666666667\n",
      "-----------\n",
      "Epoch: 19100, Loss: 2.009265166291482, Accuracy: 0.4794921875\n",
      "Epoch: 19200, Loss: 1.9176466707709368, Accuracy: 0.5068359375\n",
      "Epoch: 19300, Loss: 1.920856965049927, Accuracy: 0.5029296875\n",
      "Epoch: 19400, Loss: 1.9953737010142962, Accuracy: 0.470703125\n",
      "Epoch: 19500, Loss: 1.9428001150057024, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 19500, Momentum: False\n",
      "Val Loss: 1.981059292350973, Val Accuracy: 0.4896\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.9932145493201876, Accuracy: 0.4892578125\n",
      "Epoch: 19700, Loss: 1.943968039552984, Accuracy: 0.5068359375\n",
      "Epoch: 19800, Loss: 1.9411012775709675, Accuracy: 0.498046875\n",
      "Epoch: 19900, Loss: 1.90190637712586, Accuracy: 0.517578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 0.001, Num Epoch: 17000, Momentum: False\n",
      "Test Loss: 2.000690381695011, Test Accuracy: 0.486000290149427\n",
      "-----------\n",
      "Epoch: 0, Loss: 16.59162467384818, Accuracy: 0.0048828125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 0, Momentum: True\n",
      "Val Loss: 11.583320233935297, Val Accuracy: 0.03666666666666667\n",
      "-----------\n",
      "Epoch: 100, Loss: 6.94283436346495, Accuracy: 0.1015625\n",
      "Epoch: 200, Loss: 3.9270544877524136, Accuracy: 0.1796875\n",
      "Epoch: 300, Loss: 3.7274568120611233, Accuracy: 0.193359375\n",
      "Epoch: 400, Loss: 5.585653704824312, Accuracy: 0.171875\n",
      "Epoch: 500, Loss: 3.1468402534067677, Accuracy: 0.2724609375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 500, Momentum: True\n",
      "Val Loss: 3.087648569850203, Val Accuracy: 0.26116666666666666\n",
      "-----------\n",
      "Epoch: 600, Loss: 2.8145853033837946, Accuracy: 0.2998046875\n",
      "Epoch: 700, Loss: 2.7473407188171146, Accuracy: 0.3095703125\n",
      "Epoch: 800, Loss: 2.5304700767957105, Accuracy: 0.361328125\n",
      "Epoch: 900, Loss: 2.580167569379595, Accuracy: 0.3486328125\n",
      "Epoch: 1000, Loss: 2.3527733010435354, Accuracy: 0.4013671875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 1000, Momentum: True\n",
      "Val Loss: 2.521623996574495, Val Accuracy: 0.36143333333333333\n",
      "-----------\n",
      "Epoch: 1100, Loss: 2.45764459620106, Accuracy: 0.380859375\n",
      "Epoch: 1200, Loss: 2.363267338074721, Accuracy: 0.3818359375\n",
      "Epoch: 1300, Loss: 2.2742449375507237, Accuracy: 0.408203125\n",
      "Epoch: 1400, Loss: 2.319579246973112, Accuracy: 0.384765625\n",
      "Epoch: 1500, Loss: 2.3070312893003484, Accuracy: 0.421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 1500, Momentum: True\n",
      "Val Loss: 2.327371544362777, Val Accuracy: 0.40026666666666666\n",
      "-----------\n",
      "Epoch: 1600, Loss: 2.2805806524509964, Accuracy: 0.421875\n",
      "Epoch: 1700, Loss: 2.226863202775574, Accuracy: 0.4228515625\n",
      "Epoch: 1800, Loss: 2.350969541224271, Accuracy: 0.392578125\n",
      "Epoch: 1900, Loss: 2.205960751869058, Accuracy: 0.431640625\n",
      "Epoch: 2000, Loss: 2.145170714558444, Accuracy: 0.431640625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 2000, Momentum: True\n",
      "Val Loss: 2.2157787601799455, Val Accuracy: 0.423\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.270994303712566, Accuracy: 0.4296875\n",
      "Epoch: 2200, Loss: 2.0820191852208696, Accuracy: 0.4462890625\n",
      "Epoch: 2300, Loss: 2.225383320616305, Accuracy: 0.427734375\n",
      "Epoch: 2400, Loss: 2.1398121683404785, Accuracy: 0.4453125\n",
      "Epoch: 2500, Loss: 2.099274789295093, Accuracy: 0.4482421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 2500, Momentum: True\n",
      "Val Loss: 2.139830581133453, Val Accuracy: 0.4404666666666667\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.0026185321866525, Accuracy: 0.4814453125\n",
      "Epoch: 2700, Loss: 2.0302362590286283, Accuracy: 0.4619140625\n",
      "Epoch: 2800, Loss: 2.0139973895143273, Accuracy: 0.4384765625\n",
      "Epoch: 2900, Loss: 1.9861258073043015, Accuracy: 0.4716796875\n",
      "Epoch: 3000, Loss: 2.025809572197816, Accuracy: 0.4677734375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 3000, Momentum: True\n",
      "Val Loss: 2.062558417579466, Val Accuracy: 0.4583\n",
      "-----------\n",
      "Epoch: 3100, Loss: 1.9246251835022137, Accuracy: 0.486328125\n",
      "Epoch: 3200, Loss: 1.938996684928798, Accuracy: 0.4892578125\n",
      "Epoch: 3300, Loss: 1.8711591319708436, Accuracy: 0.4814453125\n",
      "Epoch: 3400, Loss: 1.9265535205805562, Accuracy: 0.4775390625\n",
      "Epoch: 3500, Loss: 2.0599945534140156, Accuracy: 0.4462890625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 3500, Momentum: True\n",
      "Val Loss: 2.0437685761861437, Val Accuracy: 0.46036666666666665\n",
      "-----------\n",
      "Epoch: 3600, Loss: 1.980828449909548, Accuracy: 0.4677734375\n",
      "Epoch: 3700, Loss: 1.842016024900178, Accuracy: 0.517578125\n",
      "Epoch: 3800, Loss: 1.8889334166885585, Accuracy: 0.494140625\n",
      "Epoch: 3900, Loss: 1.9357971899000574, Accuracy: 0.490234375\n",
      "Epoch: 4000, Loss: 1.8567828549942609, Accuracy: 0.5\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 4000, Momentum: True\n",
      "Val Loss: 1.9971223829747873, Val Accuracy: 0.4709333333333333\n",
      "-----------\n",
      "Epoch: 4100, Loss: 1.8445728943851067, Accuracy: 0.498046875\n",
      "Epoch: 4200, Loss: 1.863344313833169, Accuracy: 0.482421875\n",
      "Epoch: 4300, Loss: 1.9625076176402807, Accuracy: 0.4658203125\n",
      "Epoch: 4400, Loss: 1.819245447641332, Accuracy: 0.5\n",
      "Epoch: 4500, Loss: 1.8462085256792777, Accuracy: 0.509765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 4500, Momentum: True\n",
      "Val Loss: 1.968328653224219, Val Accuracy: 0.4778\n",
      "-----------\n",
      "Epoch: 4600, Loss: 1.8971652910484171, Accuracy: 0.509765625\n",
      "Epoch: 4700, Loss: 1.8190671100538862, Accuracy: 0.5185546875\n",
      "Epoch: 4800, Loss: 1.8266625681040867, Accuracy: 0.4873046875\n",
      "Epoch: 4900, Loss: 1.918145950478864, Accuracy: 0.466796875\n",
      "Epoch: 5000, Loss: 1.8064472650834884, Accuracy: 0.5078125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 5000, Momentum: True\n",
      "Val Loss: 1.9509212768614208, Val Accuracy: 0.4786666666666667\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5100, Loss: 1.7793086528959314, Accuracy: 0.51953125\n",
      "Epoch: 5200, Loss: 1.858077987358909, Accuracy: 0.4990234375\n",
      "Epoch: 5300, Loss: 1.8470969780807995, Accuracy: 0.505859375\n",
      "Epoch: 5400, Loss: 1.7900722782786613, Accuracy: 0.5185546875\n",
      "Epoch: 5500, Loss: 1.8426293166466539, Accuracy: 0.49609375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 5500, Momentum: True\n",
      "Val Loss: 1.92680278676788, Val Accuracy: 0.48533333333333334\n",
      "-----------\n",
      "Epoch: 5600, Loss: 1.7613339581276746, Accuracy: 0.5419921875\n",
      "Epoch: 5700, Loss: 1.9120683677484267, Accuracy: 0.48046875\n",
      "Epoch: 5800, Loss: 1.7686697675151763, Accuracy: 0.5087890625\n",
      "Epoch: 5900, Loss: 1.7957976571483933, Accuracy: 0.5224609375\n",
      "Epoch: 6000, Loss: 1.8011054277238627, Accuracy: 0.509765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 6000, Momentum: True\n",
      "Val Loss: 1.9037428693318463, Val Accuracy: 0.4898\n",
      "-----------\n",
      "Epoch: 6100, Loss: 1.776084383421093, Accuracy: 0.5224609375\n",
      "Epoch: 6200, Loss: 1.7856896235058324, Accuracy: 0.5126953125\n",
      "Epoch: 6300, Loss: 1.796140138060982, Accuracy: 0.53125\n",
      "Epoch: 6400, Loss: 1.781617070684122, Accuracy: 0.5107421875\n",
      "Epoch: 6500, Loss: 1.7293238063694218, Accuracy: 0.5263671875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 6500, Momentum: True\n",
      "Val Loss: 1.894038576838166, Val Accuracy: 0.49116666666666664\n",
      "-----------\n",
      "Epoch: 6600, Loss: 1.7032842026005874, Accuracy: 0.5576171875\n",
      "Epoch: 6700, Loss: 1.8263787602071464, Accuracy: 0.4951171875\n",
      "Epoch: 6800, Loss: 1.7828513296849615, Accuracy: 0.5107421875\n",
      "Epoch: 6900, Loss: 1.770547132281568, Accuracy: 0.509765625\n",
      "Epoch: 7000, Loss: 1.7534484703503748, Accuracy: 0.5166015625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 7000, Momentum: True\n",
      "Val Loss: 1.874782474642702, Val Accuracy: 0.49566666666666664\n",
      "-----------\n",
      "Epoch: 7100, Loss: 1.8030903382058465, Accuracy: 0.5029296875\n",
      "Epoch: 7200, Loss: 1.7296940617528507, Accuracy: 0.53515625\n",
      "Epoch: 7300, Loss: 1.7383429111794613, Accuracy: 0.53515625\n",
      "Epoch: 7400, Loss: 1.7962611335271854, Accuracy: 0.5009765625\n",
      "Epoch: 7500, Loss: 1.7094857842229498, Accuracy: 0.53125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 7500, Momentum: True\n",
      "Val Loss: 1.8657099874685723, Val Accuracy: 0.49903333333333333\n",
      "-----------\n",
      "Epoch: 7600, Loss: 1.6760411793152135, Accuracy: 0.5234375\n",
      "Epoch: 7700, Loss: 1.8216260982810382, Accuracy: 0.50390625\n",
      "Epoch: 7800, Loss: 1.7339775322099937, Accuracy: 0.5029296875\n",
      "Epoch: 7900, Loss: 1.6981967189399285, Accuracy: 0.5341796875\n",
      "Epoch: 8000, Loss: 1.6347132310111299, Accuracy: 0.54296875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 8000, Momentum: True\n",
      "Val Loss: 1.8441574482616336, Val Accuracy: 0.5034\n",
      "-----------\n",
      "Epoch: 8100, Loss: 1.7173456670345613, Accuracy: 0.529296875\n",
      "Epoch: 8200, Loss: 1.6217170525793074, Accuracy: 0.5478515625\n",
      "Epoch: 8300, Loss: 1.729826204676531, Accuracy: 0.5322265625\n",
      "Epoch: 8400, Loss: 1.7468823200241796, Accuracy: 0.5185546875\n",
      "Epoch: 8500, Loss: 1.7692460968119224, Accuracy: 0.5166015625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 8500, Momentum: True\n",
      "Val Loss: 1.8441671843733418, Val Accuracy: 0.5026666666666667\n",
      "-----------\n",
      "Epoch: 8600, Loss: 1.6357261937176615, Accuracy: 0.546875\n",
      "Epoch: 8700, Loss: 1.7457196368897774, Accuracy: 0.5126953125\n",
      "Epoch: 8800, Loss: 1.7280090453471044, Accuracy: 0.5166015625\n",
      "Epoch: 8900, Loss: 1.6860975219794598, Accuracy: 0.5380859375\n",
      "Epoch: 9000, Loss: 1.6615424224974746, Accuracy: 0.5498046875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 9000, Momentum: True\n",
      "Val Loss: 1.8383706889281064, Val Accuracy: 0.5014\n",
      "-----------\n",
      "Epoch: 9100, Loss: 1.6580865802285492, Accuracy: 0.552734375\n",
      "Epoch: 9200, Loss: 1.6572635272997815, Accuracy: 0.5283203125\n",
      "Epoch: 9300, Loss: 1.6850996863641856, Accuracy: 0.5400390625\n",
      "Epoch: 9400, Loss: 1.6769458585549581, Accuracy: 0.5361328125\n",
      "Epoch: 9500, Loss: 1.6733220153285964, Accuracy: 0.5244140625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 9500, Momentum: True\n",
      "Val Loss: 1.8232022767977052, Val Accuracy: 0.5050666666666667\n",
      "-----------\n",
      "Epoch: 9600, Loss: 1.5979565220361915, Accuracy: 0.544921875\n",
      "Epoch: 9700, Loss: 1.6926600902028741, Accuracy: 0.533203125\n",
      "Epoch: 9800, Loss: 1.671896661984949, Accuracy: 0.5361328125\n",
      "Epoch: 9900, Loss: 1.74939535153791, Accuracy: 0.5205078125\n",
      "Epoch: 10000, Loss: 1.6987905040201288, Accuracy: 0.53515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 10000, Momentum: True\n",
      "Val Loss: 1.815975922017137, Val Accuracy: 0.5093666666666666\n",
      "-----------\n",
      "Epoch: 10100, Loss: 1.6609074101460881, Accuracy: 0.5361328125\n",
      "Epoch: 10200, Loss: 1.649783275644603, Accuracy: 0.5400390625\n",
      "Epoch: 10300, Loss: 1.653791756292496, Accuracy: 0.5380859375\n",
      "Epoch: 10400, Loss: 1.6797953611771566, Accuracy: 0.5390625\n",
      "Epoch: 10500, Loss: 1.6108450171178976, Accuracy: 0.5556640625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 10500, Momentum: True\n",
      "Val Loss: 1.8108579386511046, Val Accuracy: 0.5094333333333333\n",
      "-----------\n",
      "Epoch: 10600, Loss: 1.736259726884665, Accuracy: 0.5048828125\n",
      "Epoch: 10700, Loss: 1.5390743563964207, Accuracy: 0.5732421875\n",
      "Epoch: 10800, Loss: 1.7004372209977936, Accuracy: 0.5478515625\n",
      "Epoch: 10900, Loss: 1.6513798068938912, Accuracy: 0.5400390625\n",
      "Epoch: 11000, Loss: 1.6458322188295478, Accuracy: 0.5390625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 11000, Momentum: True\n",
      "Val Loss: 1.8096085587636934, Val Accuracy: 0.5085333333333333\n",
      "-----------\n",
      "Epoch: 11100, Loss: 1.6096524090078563, Accuracy: 0.5341796875\n",
      "Epoch: 11200, Loss: 1.6060016617370019, Accuracy: 0.537109375\n",
      "Epoch: 11300, Loss: 1.6558232434236704, Accuracy: 0.5322265625\n",
      "Epoch: 11400, Loss: 1.6080446184415855, Accuracy: 0.5478515625\n",
      "Epoch: 11500, Loss: 1.6891676355719025, Accuracy: 0.5322265625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 11500, Momentum: True\n",
      "Val Loss: 1.8056613838793765, Val Accuracy: 0.5096666666666667\n",
      "-----------\n",
      "Epoch: 11600, Loss: 1.66435823666876, Accuracy: 0.5185546875\n",
      "Epoch: 11700, Loss: 1.6544537308072742, Accuracy: 0.541015625\n",
      "Epoch: 11800, Loss: 1.6184271401219288, Accuracy: 0.5537109375\n",
      "Epoch: 11900, Loss: 1.6231829113117364, Accuracy: 0.546875\n",
      "Epoch: 12000, Loss: 1.621738177053284, Accuracy: 0.55078125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 12000, Momentum: True\n",
      "Val Loss: 1.7927776166233094, Val Accuracy: 0.5138666666666667\n",
      "-----------\n",
      "Epoch: 12100, Loss: 1.6057498928613971, Accuracy: 0.5546875\n",
      "Epoch: 12200, Loss: 1.6530305063842712, Accuracy: 0.541015625\n",
      "Epoch: 12300, Loss: 1.6550313951865783, Accuracy: 0.541015625\n",
      "Epoch: 12400, Loss: 1.5925213502041, Accuracy: 0.5439453125\n",
      "Epoch: 12500, Loss: 1.6139097766696924, Accuracy: 0.54296875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 12500, Momentum: True\n",
      "Val Loss: 1.7933454570274587, Val Accuracy: 0.5117\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.6463066868611151, Accuracy: 0.5322265625\n",
      "Epoch: 12700, Loss: 1.6439239135272206, Accuracy: 0.5615234375\n",
      "Epoch: 12800, Loss: 1.5813159550806857, Accuracy: 0.5615234375\n",
      "Epoch: 12900, Loss: 1.5925480490811994, Accuracy: 0.5556640625\n",
      "Epoch: 13000, Loss: 1.6705214431917907, Accuracy: 0.537109375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 13000, Momentum: True\n",
      "Val Loss: 1.793383125981224, Val Accuracy: 0.5115\n",
      "-----------\n",
      "Epoch: 13100, Loss: 1.7019565295234034, Accuracy: 0.5234375\n",
      "Epoch: 13200, Loss: 1.6290053666242585, Accuracy: 0.5556640625\n",
      "Epoch: 13300, Loss: 1.496542060777719, Accuracy: 0.5810546875\n",
      "Epoch: 13400, Loss: 1.6110900912628163, Accuracy: 0.5478515625\n",
      "Epoch: 13500, Loss: 1.4990787793403877, Accuracy: 0.5771484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 13500, Momentum: True\n",
      "Val Loss: 1.7906146404629646, Val Accuracy: 0.5126\n",
      "-----------\n",
      "Epoch: 13600, Loss: 1.5847506818635249, Accuracy: 0.5517578125\n",
      "Epoch: 13700, Loss: 1.6397937288710307, Accuracy: 0.544921875\n",
      "Epoch: 13800, Loss: 1.5927064449781532, Accuracy: 0.5546875\n",
      "Epoch: 13900, Loss: 1.6214029709552396, Accuracy: 0.5556640625\n",
      "Epoch: 14000, Loss: 1.6248917324289565, Accuracy: 0.5517578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 14000, Momentum: True\n",
      "Val Loss: 1.78489665448509, Val Accuracy: 0.5131666666666667\n",
      "-----------\n",
      "Epoch: 14100, Loss: 1.6312450659087177, Accuracy: 0.537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14200, Loss: 1.5279959235202676, Accuracy: 0.5576171875\n",
      "Epoch: 14300, Loss: 1.517760761385544, Accuracy: 0.568359375\n",
      "Epoch: 14400, Loss: 1.5572533674879026, Accuracy: 0.564453125\n",
      "Epoch: 14500, Loss: 1.6473168962148856, Accuracy: 0.5458984375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 14500, Momentum: True\n",
      "Val Loss: 1.7774574883563208, Val Accuracy: 0.5175333333333333\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.5601464278411692, Accuracy: 0.5595703125\n",
      "Epoch: 14700, Loss: 1.5976005642674447, Accuracy: 0.5380859375\n",
      "Epoch: 14800, Loss: 1.5936531568905001, Accuracy: 0.5498046875\n",
      "Epoch: 14900, Loss: 1.6140568313200607, Accuracy: 0.5537109375\n",
      "Epoch: 15000, Loss: 1.5725481734958493, Accuracy: 0.5517578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 15000, Momentum: True\n",
      "Val Loss: 1.772856107583448, Val Accuracy: 0.5156333333333334\n",
      "-----------\n",
      "Epoch: 15100, Loss: 1.5197072867812063, Accuracy: 0.564453125\n",
      "Epoch: 15200, Loss: 1.5538941376663677, Accuracy: 0.572265625\n",
      "Epoch: 15300, Loss: 1.5333749180520442, Accuracy: 0.578125\n",
      "Epoch: 15400, Loss: 1.5445996173541614, Accuracy: 0.5576171875\n",
      "Epoch: 15500, Loss: 1.5905130304467587, Accuracy: 0.5439453125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 15500, Momentum: True\n",
      "Val Loss: 1.7857563739747968, Val Accuracy: 0.5134333333333333\n",
      "-----------\n",
      "Epoch: 15600, Loss: 1.6716138010664912, Accuracy: 0.5244140625\n",
      "Epoch: 15700, Loss: 1.6072092627143304, Accuracy: 0.556640625\n",
      "Epoch: 15800, Loss: 1.5532637951362385, Accuracy: 0.548828125\n",
      "Epoch: 15900, Loss: 1.570067407893155, Accuracy: 0.5439453125\n",
      "Epoch: 16000, Loss: 1.5920099899223512, Accuracy: 0.568359375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 16000, Momentum: True\n",
      "Val Loss: 1.772766720943891, Val Accuracy: 0.5169666666666667\n",
      "-----------\n",
      "Epoch: 16100, Loss: 1.5103945652618853, Accuracy: 0.5537109375\n",
      "Epoch: 16200, Loss: 1.5024532929647734, Accuracy: 0.55859375\n",
      "Epoch: 16300, Loss: 1.5957195807821738, Accuracy: 0.53515625\n",
      "Epoch: 16400, Loss: 1.5149974621306423, Accuracy: 0.5751953125\n",
      "Epoch: 16500, Loss: 1.5886105109445325, Accuracy: 0.53515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 16500, Momentum: True\n",
      "Val Loss: 1.7663728244574513, Val Accuracy: 0.5176\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.515800777394876, Accuracy: 0.5712890625\n",
      "Epoch: 16700, Loss: 1.5818512781447005, Accuracy: 0.5263671875\n",
      "Epoch: 16800, Loss: 1.552408577819542, Accuracy: 0.5595703125\n",
      "Epoch: 16900, Loss: 1.5288154067991093, Accuracy: 0.5810546875\n",
      "Epoch: 17000, Loss: 1.5535273276926027, Accuracy: 0.5634765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 17000, Momentum: True\n",
      "Val Loss: 1.767695499033592, Val Accuracy: 0.5184333333333333\n",
      "-----------\n",
      "Epoch: 17100, Loss: 1.5342781120230544, Accuracy: 0.5556640625\n",
      "Epoch: 17200, Loss: 1.6338033942748709, Accuracy: 0.5419921875\n",
      "Epoch: 17300, Loss: 1.536865436447071, Accuracy: 0.568359375\n",
      "Epoch: 17400, Loss: 1.5647393177195226, Accuracy: 0.54296875\n",
      "Epoch: 17500, Loss: 1.5772690926006598, Accuracy: 0.544921875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 17500, Momentum: True\n",
      "Val Loss: 1.7655588214474087, Val Accuracy: 0.5184666666666666\n",
      "-----------\n",
      "Epoch: 17600, Loss: 1.5617445478969967, Accuracy: 0.548828125\n",
      "Epoch: 17700, Loss: 1.5271979005430798, Accuracy: 0.57421875\n",
      "Epoch: 17800, Loss: 1.49789178367585, Accuracy: 0.5712890625\n",
      "Epoch: 17900, Loss: 1.5074221925786686, Accuracy: 0.572265625\n",
      "Epoch: 18000, Loss: 1.4915419922196294, Accuracy: 0.57421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 18000, Momentum: True\n",
      "Val Loss: 1.7589784456732476, Val Accuracy: 0.5183333333333333\n",
      "-----------\n",
      "Epoch: 18100, Loss: 1.5876650696841308, Accuracy: 0.546875\n",
      "Epoch: 18200, Loss: 1.5611771779803687, Accuracy: 0.5634765625\n",
      "Epoch: 18300, Loss: 1.5257258552423125, Accuracy: 0.5732421875\n",
      "Epoch: 18400, Loss: 1.4887857474736952, Accuracy: 0.5732421875\n",
      "Epoch: 18500, Loss: 1.5103041044054228, Accuracy: 0.5771484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 18500, Momentum: True\n",
      "Val Loss: 1.7641718801027615, Val Accuracy: 0.5178333333333334\n",
      "-----------\n",
      "Epoch: 18600, Loss: 1.5062314462466266, Accuracy: 0.5771484375\n",
      "Epoch: 18700, Loss: 1.5298467273764587, Accuracy: 0.5869140625\n",
      "Epoch: 18800, Loss: 1.527623286052622, Accuracy: 0.576171875\n",
      "Epoch: 18900, Loss: 1.588544997189067, Accuracy: 0.5439453125\n",
      "Epoch: 19000, Loss: 1.4476423276999535, Accuracy: 0.5927734375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 19000, Momentum: True\n",
      "Val Loss: 1.7637369617051861, Val Accuracy: 0.5183333333333333\n",
      "-----------\n",
      "Epoch: 19100, Loss: 1.5910208936030488, Accuracy: 0.5595703125\n",
      "Epoch: 19200, Loss: 1.5268509994786452, Accuracy: 0.564453125\n",
      "Epoch: 19300, Loss: 1.5316785122561438, Accuracy: 0.55078125\n",
      "Epoch: 19400, Loss: 1.4646774408413745, Accuracy: 0.57421875\n",
      "Epoch: 19500, Loss: 1.4803461152976414, Accuracy: 0.56640625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 19500, Momentum: True\n",
      "Val Loss: 1.7597588417937018, Val Accuracy: 0.5195\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.5258548427196534, Accuracy: 0.5654296875\n",
      "Epoch: 19700, Loss: 1.5802344160052153, Accuracy: 0.5693359375\n",
      "Epoch: 19800, Loss: 1.5117998768453589, Accuracy: 0.5615234375\n",
      "Epoch: 19900, Loss: 1.4842934475556333, Accuracy: 0.568359375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 19500, Momentum: True\n",
      "Test Loss: 1.7745222737860966, Test Accuracy: 0.5157768750906717\n",
      "-----------\n",
      "Epoch: 0, Loss: 10.653683420341022, Accuracy: 0.0283203125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 0, Momentum: False\n",
      "Val Loss: 8.84333794792065, Val Accuracy: 0.0697\n",
      "-----------\n",
      "Epoch: 100, Loss: 5.888257750288078, Accuracy: 0.044921875\n",
      "Epoch: 200, Loss: 5.538374718399399, Accuracy: 0.0869140625\n",
      "Epoch: 300, Loss: 4.81196100443082, Accuracy: 0.126953125\n",
      "Epoch: 400, Loss: 4.05257817112674, Accuracy: 0.1435546875\n",
      "Epoch: 500, Loss: 4.118371080008438, Accuracy: 0.142578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 500, Momentum: False\n",
      "Val Loss: 3.705928567609507, Val Accuracy: 0.17993333333333333\n",
      "-----------\n",
      "Epoch: 600, Loss: 3.824823724406259, Accuracy: 0.1884765625\n",
      "Epoch: 700, Loss: 3.3090991106265424, Accuracy: 0.208984375\n",
      "Epoch: 800, Loss: 3.389580300657271, Accuracy: 0.220703125\n",
      "Epoch: 900, Loss: 3.1482501641988385, Accuracy: 0.2275390625\n",
      "Epoch: 1000, Loss: 3.077707473596838, Accuracy: 0.271484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 1000, Momentum: False\n",
      "Val Loss: 3.119776560816912, Val Accuracy: 0.24713333333333334\n",
      "-----------\n",
      "Epoch: 1100, Loss: 2.9686086467704005, Accuracy: 0.2841796875\n",
      "Epoch: 1200, Loss: 3.0275867088533674, Accuracy: 0.248046875\n",
      "Epoch: 1300, Loss: 2.867486695860502, Accuracy: 0.3017578125\n",
      "Epoch: 1400, Loss: 2.9128696736329913, Accuracy: 0.3017578125\n",
      "Epoch: 1500, Loss: 2.7289522463732467, Accuracy: 0.3134765625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 1500, Momentum: False\n",
      "Val Loss: 2.7100288283628307, Val Accuracy: 0.3207\n",
      "-----------\n",
      "Epoch: 1600, Loss: 2.8595740465737753, Accuracy: 0.29296875\n",
      "Epoch: 1700, Loss: 2.6660683211561196, Accuracy: 0.3291015625\n",
      "Epoch: 1800, Loss: 2.632281216210507, Accuracy: 0.30859375\n",
      "Epoch: 1900, Loss: 2.530855341610958, Accuracy: 0.3466796875\n",
      "Epoch: 2000, Loss: 2.4374235867851226, Accuracy: 0.37890625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 2000, Momentum: False\n",
      "Val Loss: 2.5170709310066792, Val Accuracy: 0.36383333333333334\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.372641838217344, Accuracy: 0.380859375\n",
      "Epoch: 2200, Loss: 2.5010390068351347, Accuracy: 0.3271484375\n",
      "Epoch: 2300, Loss: 2.324256335596158, Accuracy: 0.40625\n",
      "Epoch: 2400, Loss: 2.421949196139935, Accuracy: 0.3701171875\n",
      "Epoch: 2500, Loss: 2.2994131953654686, Accuracy: 0.39453125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 2500, Momentum: False\n",
      "Val Loss: 2.392984523959286, Val Accuracy: 0.3871\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.3733768868935154, Accuracy: 0.3818359375\n",
      "Epoch: 2700, Loss: 2.4742158338540516, Accuracy: 0.392578125\n",
      "Epoch: 2800, Loss: 2.388725771907038, Accuracy: 0.3935546875\n",
      "Epoch: 2900, Loss: 2.290949692692717, Accuracy: 0.4150390625\n",
      "Epoch: 3000, Loss: 2.3365866064311716, Accuracy: 0.39453125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 3000, Momentum: False\n",
      "Val Loss: 2.3506297556409836, Val Accuracy: 0.39853333333333335\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3100, Loss: 2.281778108708427, Accuracy: 0.4111328125\n",
      "Epoch: 3200, Loss: 2.2044390615572427, Accuracy: 0.412109375\n",
      "Epoch: 3300, Loss: 2.2066620216108896, Accuracy: 0.4326171875\n",
      "Epoch: 3400, Loss: 2.226195838016827, Accuracy: 0.3984375\n",
      "Epoch: 3500, Loss: 2.3662493836673573, Accuracy: 0.4345703125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 3500, Momentum: False\n",
      "Val Loss: 2.2558053489075767, Val Accuracy: 0.41806666666666664\n",
      "-----------\n",
      "Epoch: 3600, Loss: 2.20217671350862, Accuracy: 0.4140625\n",
      "Epoch: 3700, Loss: 2.2721115461161205, Accuracy: 0.4052734375\n",
      "Epoch: 3800, Loss: 2.1849804885019175, Accuracy: 0.431640625\n",
      "Epoch: 3900, Loss: 2.062900968103474, Accuracy: 0.46484375\n",
      "Epoch: 4000, Loss: 2.126453125871463, Accuracy: 0.431640625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 4000, Momentum: False\n",
      "Val Loss: 2.1975494293071636, Val Accuracy: 0.4257666666666667\n",
      "-----------\n",
      "Epoch: 4100, Loss: 2.2053854020999344, Accuracy: 0.4150390625\n",
      "Epoch: 4200, Loss: 2.1012987919257844, Accuracy: 0.4482421875\n",
      "Epoch: 4300, Loss: 2.1068627306750476, Accuracy: 0.447265625\n",
      "Epoch: 4400, Loss: 2.001585340637613, Accuracy: 0.4794921875\n",
      "Epoch: 4500, Loss: 2.056581317552261, Accuracy: 0.4541015625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 4500, Momentum: False\n",
      "Val Loss: 2.142794219168498, Val Accuracy: 0.4385\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.0933433395746945, Accuracy: 0.453125\n",
      "Epoch: 4700, Loss: 2.0345376151699615, Accuracy: 0.439453125\n",
      "Epoch: 4800, Loss: 1.941765426452232, Accuracy: 0.5\n",
      "Epoch: 4900, Loss: 2.051001886628311, Accuracy: 0.4619140625\n",
      "Epoch: 5000, Loss: 2.131619578481335, Accuracy: 0.4365234375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 5000, Momentum: False\n",
      "Val Loss: 2.1136284827741503, Val Accuracy: 0.44626666666666664\n",
      "-----------\n",
      "Epoch: 5100, Loss: 1.99683096092715, Accuracy: 0.455078125\n",
      "Epoch: 5200, Loss: 2.062941408120489, Accuracy: 0.45703125\n",
      "Epoch: 5300, Loss: 1.9725704008204257, Accuracy: 0.4951171875\n",
      "Epoch: 5400, Loss: 2.0491784198327423, Accuracy: 0.4697265625\n",
      "Epoch: 5500, Loss: 1.9496664912507362, Accuracy: 0.46875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 5500, Momentum: False\n",
      "Val Loss: 2.1009202812642207, Val Accuracy: 0.44726666666666665\n",
      "-----------\n",
      "Epoch: 5600, Loss: 1.9690528774507736, Accuracy: 0.4658203125\n",
      "Epoch: 5700, Loss: 2.0070414701366586, Accuracy: 0.4736328125\n",
      "Epoch: 5800, Loss: 2.0236915670294495, Accuracy: 0.44140625\n",
      "Epoch: 5900, Loss: 1.9850569583373752, Accuracy: 0.46484375\n",
      "Epoch: 6000, Loss: 2.0535204688568918, Accuracy: 0.4638671875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 6000, Momentum: False\n",
      "Val Loss: 2.0528258009773306, Val Accuracy: 0.45826666666666666\n",
      "-----------\n",
      "Epoch: 6100, Loss: 2.041253657073225, Accuracy: 0.4599609375\n",
      "Epoch: 6200, Loss: 2.062603685434257, Accuracy: 0.455078125\n",
      "Epoch: 6300, Loss: 1.9331044065875527, Accuracy: 0.4970703125\n",
      "Epoch: 6400, Loss: 1.9984815543716983, Accuracy: 0.478515625\n",
      "Epoch: 6500, Loss: 1.9465923997479633, Accuracy: 0.478515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 6500, Momentum: False\n",
      "Val Loss: 2.0306139131774095, Val Accuracy: 0.4644666666666667\n",
      "-----------\n",
      "Epoch: 6600, Loss: 2.0101041443326944, Accuracy: 0.4697265625\n",
      "Epoch: 6700, Loss: 1.9253099178245323, Accuracy: 0.4853515625\n",
      "Epoch: 6800, Loss: 1.9467822632722727, Accuracy: 0.4921875\n",
      "Epoch: 6900, Loss: 1.9446158960254394, Accuracy: 0.49609375\n",
      "Epoch: 7000, Loss: 1.9579912486645048, Accuracy: 0.4775390625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 7000, Momentum: False\n",
      "Val Loss: 2.0300385130740626, Val Accuracy: 0.4639\n",
      "-----------\n",
      "Epoch: 7100, Loss: 1.9077284983872551, Accuracy: 0.49609375\n",
      "Epoch: 7200, Loss: 1.8645438754099222, Accuracy: 0.517578125\n",
      "Epoch: 7300, Loss: 1.935680595658806, Accuracy: 0.46875\n",
      "Epoch: 7400, Loss: 1.8739198643646202, Accuracy: 0.4892578125\n",
      "Epoch: 7500, Loss: 1.9537611081996498, Accuracy: 0.4697265625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 7500, Momentum: False\n",
      "Val Loss: 2.0002801001535206, Val Accuracy: 0.4687\n",
      "-----------\n",
      "Epoch: 7600, Loss: 1.9372032773985366, Accuracy: 0.4833984375\n",
      "Epoch: 7700, Loss: 1.8622489778350324, Accuracy: 0.5009765625\n",
      "Epoch: 7800, Loss: 1.7932860265232753, Accuracy: 0.5185546875\n",
      "Epoch: 7900, Loss: 1.9372572268176, Accuracy: 0.4873046875\n",
      "Epoch: 8000, Loss: 1.8806888195414069, Accuracy: 0.4921875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 8000, Momentum: False\n",
      "Val Loss: 1.991527656643132, Val Accuracy: 0.47163333333333335\n",
      "-----------\n",
      "Epoch: 8100, Loss: 1.863144839413716, Accuracy: 0.5078125\n",
      "Epoch: 8200, Loss: 1.8799958814870554, Accuracy: 0.5\n",
      "Epoch: 8300, Loss: 1.865437620274779, Accuracy: 0.5087890625\n",
      "Epoch: 8400, Loss: 2.0011779254720103, Accuracy: 0.47265625\n",
      "Epoch: 8500, Loss: 1.9502691125375384, Accuracy: 0.47265625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 8500, Momentum: False\n",
      "Val Loss: 2.014675131059427, Val Accuracy: 0.4648\n",
      "-----------\n",
      "Epoch: 8600, Loss: 1.8301825398574252, Accuracy: 0.4990234375\n",
      "Epoch: 8700, Loss: 1.8715452556410894, Accuracy: 0.51171875\n",
      "Epoch: 8800, Loss: 1.920215175546248, Accuracy: 0.4775390625\n",
      "Epoch: 8900, Loss: 1.8372339357765017, Accuracy: 0.50390625\n",
      "Epoch: 9000, Loss: 1.8151930819859818, Accuracy: 0.5126953125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 9000, Momentum: False\n",
      "Val Loss: 1.9772235830474088, Val Accuracy: 0.4723\n",
      "-----------\n",
      "Epoch: 9100, Loss: 1.8173595668798663, Accuracy: 0.5146484375\n",
      "Epoch: 9200, Loss: 1.93245329496161, Accuracy: 0.4853515625\n",
      "Epoch: 9300, Loss: 1.822019683460703, Accuracy: 0.4990234375\n",
      "Epoch: 9400, Loss: 1.8697354238487238, Accuracy: 0.513671875\n",
      "Epoch: 9500, Loss: 1.8340258985160887, Accuracy: 0.5\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 9500, Momentum: False\n",
      "Val Loss: 1.944472636948609, Val Accuracy: 0.4783\n",
      "-----------\n",
      "Epoch: 9600, Loss: 1.782784728173031, Accuracy: 0.505859375\n",
      "Epoch: 9700, Loss: 1.8400560293572843, Accuracy: 0.4970703125\n",
      "Epoch: 9800, Loss: 1.8158088685346492, Accuracy: 0.5244140625\n",
      "Epoch: 9900, Loss: 1.8651284457098058, Accuracy: 0.5048828125\n",
      "Epoch: 10000, Loss: 1.7950362414431136, Accuracy: 0.5107421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 10000, Momentum: False\n",
      "Val Loss: 1.930887668041007, Val Accuracy: 0.48306666666666664\n",
      "-----------\n",
      "Epoch: 10100, Loss: 1.7963122842349128, Accuracy: 0.4970703125\n",
      "Epoch: 10200, Loss: 1.7624570196030256, Accuracy: 0.5244140625\n",
      "Epoch: 10300, Loss: 1.8763121859789722, Accuracy: 0.4716796875\n",
      "Epoch: 10400, Loss: 1.793825897032218, Accuracy: 0.5205078125\n",
      "Epoch: 10500, Loss: 1.7905155754313213, Accuracy: 0.515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 10500, Momentum: False\n",
      "Val Loss: 1.9189518422090643, Val Accuracy: 0.48636666666666667\n",
      "-----------\n",
      "Epoch: 10600, Loss: 1.8178665562938812, Accuracy: 0.5224609375\n",
      "Epoch: 10700, Loss: 1.8954290369855884, Accuracy: 0.484375\n",
      "Epoch: 10800, Loss: 1.75973382044885, Accuracy: 0.5234375\n",
      "Epoch: 10900, Loss: 1.7526976022840717, Accuracy: 0.5302734375\n",
      "Epoch: 11000, Loss: 1.824788611561723, Accuracy: 0.5166015625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 11000, Momentum: False\n",
      "Val Loss: 1.9087828641325537, Val Accuracy: 0.4885333333333333\n",
      "-----------\n",
      "Epoch: 11100, Loss: 1.8285001098112827, Accuracy: 0.498046875\n",
      "Epoch: 11200, Loss: 1.7669569024675995, Accuracy: 0.51953125\n",
      "Epoch: 11300, Loss: 1.8426791896441297, Accuracy: 0.4794921875\n",
      "Epoch: 11400, Loss: 1.8452662572741387, Accuracy: 0.48828125\n",
      "Epoch: 11500, Loss: 1.7763602711859636, Accuracy: 0.5302734375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 11500, Momentum: False\n",
      "Val Loss: 1.9022819025985611, Val Accuracy: 0.4892\n",
      "-----------\n",
      "Epoch: 11600, Loss: 1.805198276883364, Accuracy: 0.5068359375\n",
      "Epoch: 11700, Loss: 1.7579362360348558, Accuracy: 0.5087890625\n",
      "Epoch: 11800, Loss: 1.784981264032341, Accuracy: 0.51171875\n",
      "Epoch: 11900, Loss: 1.7666994838414372, Accuracy: 0.51953125\n",
      "Epoch: 12000, Loss: 1.744640625827341, Accuracy: 0.5263671875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 12000, Momentum: False\n",
      "Val Loss: 1.8942890547625388, Val Accuracy: 0.4914\n",
      "-----------\n",
      "Epoch: 12100, Loss: 1.7249986954595444, Accuracy: 0.517578125\n",
      "Epoch: 12200, Loss: 1.841407954891526, Accuracy: 0.482421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12300, Loss: 1.7625617721802174, Accuracy: 0.5302734375\n",
      "Epoch: 12400, Loss: 1.7730924927395284, Accuracy: 0.5234375\n",
      "Epoch: 12500, Loss: 1.7426107804958304, Accuracy: 0.5283203125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 12500, Momentum: False\n",
      "Val Loss: 1.8858037032672097, Val Accuracy: 0.49123333333333336\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.8180267453492829, Accuracy: 0.4912109375\n",
      "Epoch: 12700, Loss: 1.7760759879903107, Accuracy: 0.4951171875\n",
      "Epoch: 12800, Loss: 1.7856575827958951, Accuracy: 0.5185546875\n",
      "Epoch: 12900, Loss: 1.7304595790473638, Accuracy: 0.5234375\n",
      "Epoch: 13000, Loss: 1.7701347477477059, Accuracy: 0.5146484375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 13000, Momentum: False\n",
      "Val Loss: 1.8861355824727681, Val Accuracy: 0.49146666666666666\n",
      "-----------\n",
      "Epoch: 13100, Loss: 1.7546021405333874, Accuracy: 0.515625\n",
      "Epoch: 13200, Loss: 1.6643934567015468, Accuracy: 0.5302734375\n",
      "Epoch: 13300, Loss: 1.7583352185005454, Accuracy: 0.525390625\n",
      "Epoch: 13400, Loss: 1.663497685863316, Accuracy: 0.556640625\n",
      "Epoch: 13500, Loss: 1.6753799202439155, Accuracy: 0.544921875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 13500, Momentum: False\n",
      "Val Loss: 1.88323732367675, Val Accuracy: 0.49143333333333333\n",
      "-----------\n",
      "Epoch: 13600, Loss: 1.7707956632702464, Accuracy: 0.51171875\n",
      "Epoch: 13700, Loss: 1.7916032207185175, Accuracy: 0.529296875\n",
      "Epoch: 13800, Loss: 1.743939999567682, Accuracy: 0.498046875\n",
      "Epoch: 13900, Loss: 1.7730641670718879, Accuracy: 0.5009765625\n",
      "Epoch: 14000, Loss: 1.6050624355011158, Accuracy: 0.5732421875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 14000, Momentum: False\n",
      "Val Loss: 1.8635217718986523, Val Accuracy: 0.49656666666666666\n",
      "-----------\n",
      "Epoch: 14100, Loss: 1.7090451297047404, Accuracy: 0.53125\n",
      "Epoch: 14200, Loss: 1.7901112338907075, Accuracy: 0.5009765625\n",
      "Epoch: 14300, Loss: 1.7116768154968094, Accuracy: 0.5302734375\n",
      "Epoch: 14400, Loss: 1.7388724657538768, Accuracy: 0.5107421875\n",
      "Epoch: 14500, Loss: 1.6775785860019334, Accuracy: 0.5166015625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 14500, Momentum: False\n",
      "Val Loss: 1.8582633539860816, Val Accuracy: 0.49856666666666666\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.7282734612035329, Accuracy: 0.53125\n",
      "Epoch: 14700, Loss: 1.755464448213957, Accuracy: 0.5205078125\n",
      "Epoch: 14800, Loss: 1.7336899043764955, Accuracy: 0.515625\n",
      "Epoch: 14900, Loss: 1.768480255448884, Accuracy: 0.5126953125\n",
      "Epoch: 15000, Loss: 1.6710719934916238, Accuracy: 0.5380859375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 15000, Momentum: False\n",
      "Val Loss: 1.8513189265942434, Val Accuracy: 0.5005666666666667\n",
      "-----------\n",
      "Epoch: 15100, Loss: 1.6856170560513086, Accuracy: 0.53515625\n",
      "Epoch: 15200, Loss: 1.7550030819689892, Accuracy: 0.529296875\n",
      "Epoch: 15300, Loss: 1.6683550633504294, Accuracy: 0.5439453125\n",
      "Epoch: 15400, Loss: 1.7905054954869675, Accuracy: 0.5048828125\n",
      "Epoch: 15500, Loss: 1.7122792833791047, Accuracy: 0.53125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 15500, Momentum: False\n",
      "Val Loss: 1.8651014988230623, Val Accuracy: 0.4952\n",
      "-----------\n",
      "Epoch: 15600, Loss: 1.6894722067242411, Accuracy: 0.5341796875\n",
      "Epoch: 15700, Loss: 1.6440616940356738, Accuracy: 0.5400390625\n",
      "Epoch: 15800, Loss: 1.7283946886968806, Accuracy: 0.5322265625\n",
      "Epoch: 15900, Loss: 1.623556635059797, Accuracy: 0.546875\n",
      "Epoch: 16000, Loss: 1.7474662264537353, Accuracy: 0.53515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 16000, Momentum: False\n",
      "Val Loss: 1.850192906627626, Val Accuracy: 0.4986333333333333\n",
      "-----------\n",
      "Epoch: 16100, Loss: 1.7327750782714988, Accuracy: 0.5400390625\n",
      "Epoch: 16200, Loss: 1.672243681490537, Accuracy: 0.541015625\n",
      "Epoch: 16300, Loss: 1.7033330958036599, Accuracy: 0.533203125\n",
      "Epoch: 16400, Loss: 1.7372198605525362, Accuracy: 0.5234375\n",
      "Epoch: 16500, Loss: 1.6974202274320147, Accuracy: 0.5400390625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 16500, Momentum: False\n",
      "Val Loss: 1.8439113556883076, Val Accuracy: 0.49996666666666667\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.615186021581073, Accuracy: 0.5576171875\n",
      "Epoch: 16700, Loss: 1.6003156512221983, Accuracy: 0.55859375\n",
      "Epoch: 16800, Loss: 1.6981709598748176, Accuracy: 0.5322265625\n",
      "Epoch: 16900, Loss: 1.6186498039874149, Accuracy: 0.548828125\n",
      "Epoch: 17000, Loss: 1.6465401643643163, Accuracy: 0.55078125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 17000, Momentum: False\n",
      "Val Loss: 1.8334392252719027, Val Accuracy: 0.5017666666666667\n",
      "-----------\n",
      "Epoch: 17100, Loss: 1.6639327707108285, Accuracy: 0.541015625\n",
      "Epoch: 17200, Loss: 1.7564772660805512, Accuracy: 0.5107421875\n",
      "Epoch: 17300, Loss: 1.6372203313554232, Accuracy: 0.55859375\n",
      "Epoch: 17400, Loss: 1.7227845970016678, Accuracy: 0.52734375\n",
      "Epoch: 17500, Loss: 1.6792375725413715, Accuracy: 0.53515625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 17500, Momentum: False\n",
      "Val Loss: 1.8293207479127507, Val Accuracy: 0.5043\n",
      "-----------\n",
      "Epoch: 17600, Loss: 1.6804584632697268, Accuracy: 0.546875\n",
      "Epoch: 17700, Loss: 1.5985092946657145, Accuracy: 0.5546875\n",
      "Epoch: 17800, Loss: 1.65533036691444, Accuracy: 0.54296875\n",
      "Epoch: 17900, Loss: 1.5778097698130233, Accuracy: 0.552734375\n",
      "Epoch: 18000, Loss: 1.7276164226285118, Accuracy: 0.5302734375\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 18000, Momentum: False\n",
      "Val Loss: 1.8293924341968761, Val Accuracy: 0.5059333333333333\n",
      "-----------\n",
      "Epoch: 18100, Loss: 1.7312074270944207, Accuracy: 0.5234375\n",
      "Epoch: 18200, Loss: 1.684166558504229, Accuracy: 0.541015625\n",
      "Epoch: 18300, Loss: 1.6960821268144979, Accuracy: 0.537109375\n",
      "Epoch: 18400, Loss: 1.7474181962160102, Accuracy: 0.5263671875\n",
      "Epoch: 18500, Loss: 1.618970043267609, Accuracy: 0.5517578125\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 18500, Momentum: False\n",
      "Val Loss: 1.827015881010435, Val Accuracy: 0.5046333333333334\n",
      "-----------\n",
      "Epoch: 18600, Loss: 1.662385967245784, Accuracy: 0.5341796875\n",
      "Epoch: 18700, Loss: 1.7754435550311785, Accuracy: 0.50390625\n",
      "Epoch: 18800, Loss: 1.7171206102564458, Accuracy: 0.513671875\n",
      "Epoch: 18900, Loss: 1.6703785307788408, Accuracy: 0.5537109375\n",
      "Epoch: 19000, Loss: 1.674954302888159, Accuracy: 0.5341796875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 19000, Momentum: False\n",
      "Val Loss: 1.8170761500630168, Val Accuracy: 0.5081\n",
      "-----------\n",
      "Epoch: 19100, Loss: 1.7317526697971313, Accuracy: 0.525390625\n",
      "Epoch: 19200, Loss: 1.6125500387708227, Accuracy: 0.548828125\n",
      "Epoch: 19300, Loss: 1.6898678034347094, Accuracy: 0.51171875\n",
      "Epoch: 19400, Loss: 1.7267783850710137, Accuracy: 0.5322265625\n",
      "Epoch: 19500, Loss: 1.6863063083329872, Accuracy: 0.5244140625\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 19500, Momentum: False\n",
      "Val Loss: 1.8175745287251477, Val Accuracy: 0.5068333333333334\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.6864314913356742, Accuracy: 0.5361328125\n",
      "Epoch: 19700, Loss: 1.6872942661916384, Accuracy: 0.544921875\n",
      "Epoch: 19800, Loss: 1.603459743367663, Accuracy: 0.5322265625\n",
      "Epoch: 19900, Loss: 1.515554462547057, Accuracy: 0.576171875\n",
      "-----------\n",
      "Learning Rate: 0.1, Reg: 1e-05, Num Epoch: 19000, Momentum: False\n",
      "Test Loss: 1.8399905076129361, Test Accuracy: 0.5\n",
      "-----------\n",
      "Epoch: 0, Loss: 15.848908705391981, Accuracy: 0.0126953125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 0, Momentum: True\n",
      "Val Loss: 11.397134568406736, Val Accuracy: 0.029966666666666666\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.314138647801587, Accuracy: 0.076171875\n",
      "Epoch: 200, Loss: 4.00134539784305, Accuracy: 0.119140625\n",
      "Epoch: 300, Loss: 3.6572560945100916, Accuracy: 0.130859375\n",
      "Epoch: 400, Loss: 3.4668479916219566, Accuracy: 0.1826171875\n",
      "Epoch: 500, Loss: 3.443736778871157, Accuracy: 0.1611328125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 500, Momentum: True\n",
      "Val Loss: 3.310831172118786, Val Accuracy: 0.1931\n",
      "-----------\n",
      "Epoch: 600, Loss: 3.1439521840243083, Accuracy: 0.2236328125\n",
      "Epoch: 700, Loss: 3.0656271908890007, Accuracy: 0.2314453125\n",
      "Epoch: 800, Loss: 2.9787229639868125, Accuracy: 0.244140625\n",
      "Epoch: 900, Loss: 2.8586371181148467, Accuracy: 0.2705078125\n",
      "Epoch: 1000, Loss: 2.816186393916508, Accuracy: 0.279296875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 1000, Momentum: True\n",
      "Val Loss: 2.8091197242628803, Val Accuracy: 0.2818333333333333\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1100, Loss: 2.6695480283294293, Accuracy: 0.3203125\n",
      "Epoch: 1200, Loss: 2.7455395829069875, Accuracy: 0.298828125\n",
      "Epoch: 1300, Loss: 2.6436448691688774, Accuracy: 0.3212890625\n",
      "Epoch: 1400, Loss: 2.601917369206593, Accuracy: 0.3271484375\n",
      "Epoch: 1500, Loss: 2.4585313766444115, Accuracy: 0.3701171875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 1500, Momentum: True\n",
      "Val Loss: 2.5610001800059004, Val Accuracy: 0.33486666666666665\n",
      "-----------\n",
      "Epoch: 1600, Loss: 2.4651233362005165, Accuracy: 0.36328125\n",
      "Epoch: 1700, Loss: 2.473775506751937, Accuracy: 0.345703125\n",
      "Epoch: 1800, Loss: 2.4808626823268725, Accuracy: 0.36328125\n",
      "Epoch: 1900, Loss: 2.4030906830191383, Accuracy: 0.3583984375\n",
      "Epoch: 2000, Loss: 2.3250148761267733, Accuracy: 0.3916015625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 2000, Momentum: True\n",
      "Val Loss: 2.419788123403445, Val Accuracy: 0.36806666666666665\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.4222671374316, Accuracy: 0.3759765625\n",
      "Epoch: 2200, Loss: 2.3423427681607145, Accuracy: 0.3916015625\n",
      "Epoch: 2300, Loss: 2.274317317622295, Accuracy: 0.392578125\n",
      "Epoch: 2400, Loss: 2.2540809462144344, Accuracy: 0.4111328125\n",
      "Epoch: 2500, Loss: 2.227775548585766, Accuracy: 0.4130859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 2500, Momentum: True\n",
      "Val Loss: 2.3194989391415826, Val Accuracy: 0.3920666666666667\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.3058514930637557, Accuracy: 0.4072265625\n",
      "Epoch: 2700, Loss: 2.2754114822610516, Accuracy: 0.4072265625\n",
      "Epoch: 2800, Loss: 2.2148755759513166, Accuracy: 0.4130859375\n",
      "Epoch: 2900, Loss: 2.289983761715064, Accuracy: 0.39453125\n",
      "Epoch: 3000, Loss: 2.208592690617276, Accuracy: 0.423828125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 3000, Momentum: True\n",
      "Val Loss: 2.2585982947760104, Val Accuracy: 0.4099\n",
      "-----------\n",
      "Epoch: 3100, Loss: 2.238446819418371, Accuracy: 0.40234375\n",
      "Epoch: 3200, Loss: 2.1889252366748044, Accuracy: 0.4228515625\n",
      "Epoch: 3300, Loss: 2.139666154637628, Accuracy: 0.4443359375\n",
      "Epoch: 3400, Loss: 2.244191418988222, Accuracy: 0.4150390625\n",
      "Epoch: 3500, Loss: 2.148753003516404, Accuracy: 0.4501953125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 3500, Momentum: True\n",
      "Val Loss: 2.206008574899611, Val Accuracy: 0.42346666666666666\n",
      "-----------\n",
      "Epoch: 3600, Loss: 2.245467116753371, Accuracy: 0.4130859375\n",
      "Epoch: 3700, Loss: 2.071632991589269, Accuracy: 0.470703125\n",
      "Epoch: 3800, Loss: 2.0723142318079297, Accuracy: 0.486328125\n",
      "Epoch: 3900, Loss: 2.1714157366411007, Accuracy: 0.451171875\n",
      "Epoch: 4000, Loss: 2.1507959059568824, Accuracy: 0.4462890625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 4000, Momentum: True\n",
      "Val Loss: 2.1710508188467785, Val Accuracy: 0.4357333333333333\n",
      "-----------\n",
      "Epoch: 4100, Loss: 2.1920646755819138, Accuracy: 0.4248046875\n",
      "Epoch: 4200, Loss: 2.0881890840192243, Accuracy: 0.44921875\n",
      "Epoch: 4300, Loss: 2.1186873057292215, Accuracy: 0.44140625\n",
      "Epoch: 4400, Loss: 2.106122666253697, Accuracy: 0.44140625\n",
      "Epoch: 4500, Loss: 2.0602007633057484, Accuracy: 0.4658203125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 4500, Momentum: True\n",
      "Val Loss: 2.1417771049998833, Val Accuracy: 0.44326666666666664\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.0819630580390127, Accuracy: 0.4501953125\n",
      "Epoch: 4700, Loss: 2.076034354211988, Accuracy: 0.4697265625\n",
      "Epoch: 4800, Loss: 2.180200617329609, Accuracy: 0.4169921875\n",
      "Epoch: 4900, Loss: 2.143596295364253, Accuracy: 0.4423828125\n",
      "Epoch: 5000, Loss: 2.1312751265445558, Accuracy: 0.4560546875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 5000, Momentum: True\n",
      "Val Loss: 2.1172876168875643, Val Accuracy: 0.45226666666666665\n",
      "-----------\n",
      "Epoch: 5100, Loss: 2.133776305753157, Accuracy: 0.4423828125\n",
      "Epoch: 5200, Loss: 2.058085911524725, Accuracy: 0.4775390625\n",
      "Epoch: 5300, Loss: 2.087777053124399, Accuracy: 0.4609375\n",
      "Epoch: 5400, Loss: 2.0225855856047783, Accuracy: 0.4814453125\n",
      "Epoch: 5500, Loss: 2.1046151768145247, Accuracy: 0.4541015625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 5500, Momentum: True\n",
      "Val Loss: 2.0998273818477338, Val Accuracy: 0.45626666666666665\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.077908668948313, Accuracy: 0.4462890625\n",
      "Epoch: 5700, Loss: 2.032844500259576, Accuracy: 0.4599609375\n",
      "Epoch: 5800, Loss: 2.036539108478333, Accuracy: 0.4736328125\n",
      "Epoch: 5900, Loss: 2.0333160997202735, Accuracy: 0.478515625\n",
      "Epoch: 6000, Loss: 2.061695332716814, Accuracy: 0.4619140625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 6000, Momentum: True\n",
      "Val Loss: 2.0831389514162986, Val Accuracy: 0.4578333333333333\n",
      "-----------\n",
      "Epoch: 6100, Loss: 2.0695898965072344, Accuracy: 0.4775390625\n",
      "Epoch: 6200, Loss: 2.027788949177879, Accuracy: 0.4990234375\n",
      "Epoch: 6300, Loss: 2.041445950635075, Accuracy: 0.46875\n",
      "Epoch: 6400, Loss: 2.0407799895874073, Accuracy: 0.4638671875\n",
      "Epoch: 6500, Loss: 1.9939403812495629, Accuracy: 0.490234375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 6500, Momentum: True\n",
      "Val Loss: 2.0722153294651395, Val Accuracy: 0.46103333333333335\n",
      "-----------\n",
      "Epoch: 6600, Loss: 2.0023578271383022, Accuracy: 0.494140625\n",
      "Epoch: 6700, Loss: 2.0789890836571496, Accuracy: 0.474609375\n",
      "Epoch: 6800, Loss: 2.0404317773141827, Accuracy: 0.4833984375\n",
      "Epoch: 6900, Loss: 1.9616022408679932, Accuracy: 0.5107421875\n",
      "Epoch: 7000, Loss: 2.030832088262438, Accuracy: 0.4716796875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 7000, Momentum: True\n",
      "Val Loss: 2.058645602440646, Val Accuracy: 0.47026666666666667\n",
      "-----------\n",
      "Epoch: 7100, Loss: 1.9646724450889494, Accuracy: 0.4921875\n",
      "Epoch: 7200, Loss: 1.9623172285503172, Accuracy: 0.505859375\n",
      "Epoch: 7300, Loss: 2.044687588119099, Accuracy: 0.47265625\n",
      "Epoch: 7400, Loss: 2.0732343128611617, Accuracy: 0.47265625\n",
      "Epoch: 7500, Loss: 2.0257446942584107, Accuracy: 0.486328125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 7500, Momentum: True\n",
      "Val Loss: 2.049327930597438, Val Accuracy: 0.4666\n",
      "-----------\n",
      "Epoch: 7600, Loss: 2.0136415727793526, Accuracy: 0.484375\n",
      "Epoch: 7700, Loss: 2.004012758943743, Accuracy: 0.4814453125\n",
      "Epoch: 7800, Loss: 1.9539775785485833, Accuracy: 0.4990234375\n",
      "Epoch: 7900, Loss: 1.9638450966870613, Accuracy: 0.50390625\n",
      "Epoch: 8000, Loss: 2.0117999055787967, Accuracy: 0.4921875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 8000, Momentum: True\n",
      "Val Loss: 2.040858692873398, Val Accuracy: 0.47013333333333335\n",
      "-----------\n",
      "Epoch: 8100, Loss: 1.9754171592957976, Accuracy: 0.4990234375\n",
      "Epoch: 8200, Loss: 2.0637637561792443, Accuracy: 0.4609375\n",
      "Epoch: 8300, Loss: 1.9670018724090843, Accuracy: 0.5068359375\n",
      "Epoch: 8400, Loss: 1.9941305586358755, Accuracy: 0.48828125\n",
      "Epoch: 8500, Loss: 2.0824310498252654, Accuracy: 0.4619140625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 8500, Momentum: True\n",
      "Val Loss: 2.0327319973214344, Val Accuracy: 0.47686666666666666\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.0209822092845275, Accuracy: 0.470703125\n",
      "Epoch: 8700, Loss: 1.9218431177939794, Accuracy: 0.5234375\n",
      "Epoch: 8800, Loss: 1.9577620865408043, Accuracy: 0.50390625\n",
      "Epoch: 8900, Loss: 2.0364454003040624, Accuracy: 0.4658203125\n",
      "Epoch: 9000, Loss: 1.9636601208043314, Accuracy: 0.4873046875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 9000, Momentum: True\n",
      "Val Loss: 2.027912238024308, Val Accuracy: 0.4749\n",
      "-----------\n",
      "Epoch: 9100, Loss: 2.0244890544815877, Accuracy: 0.4921875\n",
      "Epoch: 9200, Loss: 2.003924254496604, Accuracy: 0.4951171875\n",
      "Epoch: 9300, Loss: 2.0472573117472868, Accuracy: 0.4736328125\n",
      "Epoch: 9400, Loss: 2.06835326309084, Accuracy: 0.455078125\n",
      "Epoch: 9500, Loss: 2.0256471549911814, Accuracy: 0.4794921875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 9500, Momentum: True\n",
      "Val Loss: 2.0228641274919803, Val Accuracy: 0.47946666666666665\n",
      "-----------\n",
      "Epoch: 9600, Loss: 1.9706818464724831, Accuracy: 0.490234375\n",
      "Epoch: 9700, Loss: 2.055198482570762, Accuracy: 0.4716796875\n",
      "Epoch: 9800, Loss: 2.003602281039231, Accuracy: 0.4775390625\n",
      "Epoch: 9900, Loss: 1.9700883669252138, Accuracy: 0.5009765625\n",
      "Epoch: 10000, Loss: 1.9794845255568903, Accuracy: 0.4892578125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 10000, Momentum: True\n",
      "Val Loss: 2.0154916652721506, Val Accuracy: 0.4811\n",
      "-----------\n",
      "Epoch: 10100, Loss: 1.944629738426943, Accuracy: 0.505859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10200, Loss: 2.00644227731833, Accuracy: 0.5009765625\n",
      "Epoch: 10300, Loss: 2.0128803964866657, Accuracy: 0.490234375\n",
      "Epoch: 10400, Loss: 1.990298129076697, Accuracy: 0.49609375\n",
      "Epoch: 10500, Loss: 1.9011305693670537, Accuracy: 0.525390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 10500, Momentum: True\n",
      "Val Loss: 2.012459402234724, Val Accuracy: 0.48196666666666665\n",
      "-----------\n",
      "Epoch: 10600, Loss: 1.9352148709157464, Accuracy: 0.5283203125\n",
      "Epoch: 10700, Loss: 1.9080860208128123, Accuracy: 0.525390625\n",
      "Epoch: 10800, Loss: 1.9761939466818146, Accuracy: 0.4892578125\n",
      "Epoch: 10900, Loss: 1.992959893479238, Accuracy: 0.4931640625\n",
      "Epoch: 11000, Loss: 1.9373332662611233, Accuracy: 0.505859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 11000, Momentum: True\n",
      "Val Loss: 2.009605731916706, Val Accuracy: 0.48256666666666664\n",
      "-----------\n",
      "Epoch: 11100, Loss: 2.022072472032672, Accuracy: 0.4814453125\n",
      "Epoch: 11200, Loss: 1.945161047639433, Accuracy: 0.51171875\n",
      "Epoch: 11300, Loss: 1.9911626983578832, Accuracy: 0.4912109375\n",
      "Epoch: 11400, Loss: 1.9839949793039864, Accuracy: 0.4921875\n",
      "Epoch: 11500, Loss: 1.9997126611432374, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 11500, Momentum: True\n",
      "Val Loss: 2.00492016523683, Val Accuracy: 0.4820333333333333\n",
      "-----------\n",
      "Epoch: 11600, Loss: 1.9664337588668528, Accuracy: 0.5146484375\n",
      "Epoch: 11700, Loss: 1.9782967203809616, Accuracy: 0.4931640625\n",
      "Epoch: 11800, Loss: 1.9766492868099825, Accuracy: 0.4833984375\n",
      "Epoch: 11900, Loss: 2.031700087719372, Accuracy: 0.478515625\n",
      "Epoch: 12000, Loss: 1.9615346182322952, Accuracy: 0.5087890625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 12000, Momentum: True\n",
      "Val Loss: 2.001859251944583, Val Accuracy: 0.48373333333333335\n",
      "-----------\n",
      "Epoch: 12100, Loss: 2.060451426750684, Accuracy: 0.4638671875\n",
      "Epoch: 12200, Loss: 1.9323687769995401, Accuracy: 0.5087890625\n",
      "Epoch: 12300, Loss: 1.9603714228668072, Accuracy: 0.5146484375\n",
      "Epoch: 12400, Loss: 1.9617053644691758, Accuracy: 0.494140625\n",
      "Epoch: 12500, Loss: 1.9673441562334004, Accuracy: 0.509765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 12500, Momentum: True\n",
      "Val Loss: 1.9992644692409947, Val Accuracy: 0.4853\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.9317255087780618, Accuracy: 0.50390625\n",
      "Epoch: 12700, Loss: 1.9952478902544812, Accuracy: 0.4892578125\n",
      "Epoch: 12800, Loss: 2.066778221167779, Accuracy: 0.4658203125\n",
      "Epoch: 12900, Loss: 1.9950847286058675, Accuracy: 0.4833984375\n",
      "Epoch: 13000, Loss: 1.9661346981982593, Accuracy: 0.498046875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 13000, Momentum: True\n",
      "Val Loss: 1.996921940210143, Val Accuracy: 0.4867\n",
      "-----------\n",
      "Epoch: 13100, Loss: 1.9232579908520013, Accuracy: 0.5302734375\n",
      "Epoch: 13200, Loss: 1.9060470672123355, Accuracy: 0.517578125\n",
      "Epoch: 13300, Loss: 1.9853552786685769, Accuracy: 0.505859375\n",
      "Epoch: 13400, Loss: 1.9325914494083745, Accuracy: 0.5078125\n",
      "Epoch: 13500, Loss: 2.0212859270158905, Accuracy: 0.4951171875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 13500, Momentum: True\n",
      "Val Loss: 1.9950429637534859, Val Accuracy: 0.487\n",
      "-----------\n",
      "Epoch: 13600, Loss: 1.9518549637477625, Accuracy: 0.4892578125\n",
      "Epoch: 13700, Loss: 1.89864650261887, Accuracy: 0.52734375\n",
      "Epoch: 13800, Loss: 1.9866451994624446, Accuracy: 0.4873046875\n",
      "Epoch: 13900, Loss: 1.9753919527019728, Accuracy: 0.4990234375\n",
      "Epoch: 14000, Loss: 1.8865173734628737, Accuracy: 0.5302734375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 14000, Momentum: True\n",
      "Val Loss: 1.993668000909562, Val Accuracy: 0.4851\n",
      "-----------\n",
      "Epoch: 14100, Loss: 1.90390664959038, Accuracy: 0.501953125\n",
      "Epoch: 14200, Loss: 1.9536925222429828, Accuracy: 0.5078125\n",
      "Epoch: 14300, Loss: 1.9047039083854513, Accuracy: 0.51953125\n",
      "Epoch: 14400, Loss: 1.9369275807693382, Accuracy: 0.5107421875\n",
      "Epoch: 14500, Loss: 2.0435731555003445, Accuracy: 0.462890625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 14500, Momentum: True\n",
      "Val Loss: 1.9914302001260005, Val Accuracy: 0.48893333333333333\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.994011307876257, Accuracy: 0.4873046875\n",
      "Epoch: 14700, Loss: 1.9441281740078562, Accuracy: 0.5087890625\n",
      "Epoch: 14800, Loss: 1.9861180945986407, Accuracy: 0.5\n",
      "Epoch: 14900, Loss: 2.0097605837476387, Accuracy: 0.482421875\n",
      "Epoch: 15000, Loss: 1.9796000032459844, Accuracy: 0.4951171875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 15000, Momentum: True\n",
      "Val Loss: 1.9902833295461713, Val Accuracy: 0.4868\n",
      "-----------\n",
      "Epoch: 15100, Loss: 1.9924467519720506, Accuracy: 0.4873046875\n",
      "Epoch: 15200, Loss: 1.9899192073622247, Accuracy: 0.4951171875\n",
      "Epoch: 15300, Loss: 1.9083499373755861, Accuracy: 0.5205078125\n",
      "Epoch: 15400, Loss: 1.8566633228112934, Accuracy: 0.525390625\n",
      "Epoch: 15500, Loss: 1.989246211475039, Accuracy: 0.5\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 15500, Momentum: True\n",
      "Val Loss: 1.9885234948655148, Val Accuracy: 0.48796666666666666\n",
      "-----------\n",
      "Epoch: 15600, Loss: 1.9612950336543697, Accuracy: 0.5009765625\n",
      "Epoch: 15700, Loss: 1.9577316120202135, Accuracy: 0.5068359375\n",
      "Epoch: 15800, Loss: 1.9043009417897476, Accuracy: 0.513671875\n",
      "Epoch: 15900, Loss: 1.920227406903703, Accuracy: 0.521484375\n",
      "Epoch: 16000, Loss: 1.9916282438585622, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 16000, Momentum: True\n",
      "Val Loss: 1.987855896433495, Val Accuracy: 0.48543333333333333\n",
      "-----------\n",
      "Epoch: 16100, Loss: 1.9259391332269522, Accuracy: 0.521484375\n",
      "Epoch: 16200, Loss: 1.941786546815262, Accuracy: 0.509765625\n",
      "Epoch: 16300, Loss: 1.9738653596362639, Accuracy: 0.490234375\n",
      "Epoch: 16400, Loss: 1.9847091986542607, Accuracy: 0.4931640625\n",
      "Epoch: 16500, Loss: 1.9753370397342267, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 16500, Momentum: True\n",
      "Val Loss: 1.9865203659815422, Val Accuracy: 0.48773333333333335\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.9590958145774189, Accuracy: 0.5009765625\n",
      "Epoch: 16700, Loss: 1.9464900356544463, Accuracy: 0.5166015625\n",
      "Epoch: 16800, Loss: 1.9032946360667096, Accuracy: 0.5048828125\n",
      "Epoch: 16900, Loss: 1.9414374990574943, Accuracy: 0.529296875\n",
      "Epoch: 17000, Loss: 1.9436840039825922, Accuracy: 0.5029296875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 17000, Momentum: True\n",
      "Val Loss: 1.9858625151611171, Val Accuracy: 0.48746666666666666\n",
      "-----------\n",
      "Epoch: 17100, Loss: 1.9345944531069565, Accuracy: 0.50390625\n",
      "Epoch: 17200, Loss: 2.0060123601978486, Accuracy: 0.478515625\n",
      "Epoch: 17300, Loss: 1.9845348364351012, Accuracy: 0.4873046875\n",
      "Epoch: 17400, Loss: 1.9778190685352763, Accuracy: 0.5009765625\n",
      "Epoch: 17500, Loss: 1.872741282218365, Accuracy: 0.521484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 17500, Momentum: True\n",
      "Val Loss: 1.9852230019632977, Val Accuracy: 0.48683333333333334\n",
      "-----------\n",
      "Epoch: 17600, Loss: 1.8917241240628289, Accuracy: 0.529296875\n",
      "Epoch: 17700, Loss: 1.9494111411023294, Accuracy: 0.5107421875\n",
      "Epoch: 17800, Loss: 1.9314790920792535, Accuracy: 0.5\n",
      "Epoch: 17900, Loss: 1.8857954603483393, Accuracy: 0.5146484375\n",
      "Epoch: 18000, Loss: 1.9001590732485767, Accuracy: 0.5234375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 18000, Momentum: True\n",
      "Val Loss: 1.9843958681105867, Val Accuracy: 0.4902666666666667\n",
      "-----------\n",
      "Epoch: 18100, Loss: 1.9476052376781112, Accuracy: 0.51171875\n",
      "Epoch: 18200, Loss: 1.9093007053608066, Accuracy: 0.521484375\n",
      "Epoch: 18300, Loss: 1.8974775013126695, Accuracy: 0.5166015625\n",
      "Epoch: 18400, Loss: 1.8748905884941882, Accuracy: 0.5380859375\n",
      "Epoch: 18500, Loss: 1.9049455171856873, Accuracy: 0.505859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 18500, Momentum: True\n",
      "Val Loss: 1.9841164808412446, Val Accuracy: 0.48933333333333334\n",
      "-----------\n",
      "Epoch: 18600, Loss: 1.9214229702310108, Accuracy: 0.498046875\n",
      "Epoch: 18700, Loss: 1.9481639151889576, Accuracy: 0.5048828125\n",
      "Epoch: 18800, Loss: 1.9727417544886383, Accuracy: 0.5\n",
      "Epoch: 18900, Loss: 1.9111170375655082, Accuracy: 0.521484375\n",
      "Epoch: 19000, Loss: 1.9509155197946682, Accuracy: 0.4921875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 19000, Momentum: True\n",
      "Val Loss: 1.9837889413722563, Val Accuracy: 0.48966666666666664\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19100, Loss: 1.9310708960503251, Accuracy: 0.51171875\n",
      "Epoch: 19200, Loss: 1.930103895070302, Accuracy: 0.501953125\n",
      "Epoch: 19300, Loss: 1.9381063435444141, Accuracy: 0.509765625\n",
      "Epoch: 19400, Loss: 1.9675851671900957, Accuracy: 0.5244140625\n",
      "Epoch: 19500, Loss: 1.951645077895724, Accuracy: 0.494140625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 19500, Momentum: True\n",
      "Val Loss: 1.9828275591645292, Val Accuracy: 0.48943333333333333\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.9435026693101785, Accuracy: 0.50390625\n",
      "Epoch: 19700, Loss: 1.8879756998409951, Accuracy: 0.517578125\n",
      "Epoch: 19800, Loss: 1.9857181586447348, Accuracy: 0.48828125\n",
      "Epoch: 19900, Loss: 1.9012098666820814, Accuracy: 0.5166015625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 18000, Momentum: True\n",
      "Test Loss: 2.001575552345277, Test Accuracy: 0.4841868562309589\n",
      "-----------\n",
      "Epoch: 0, Loss: 17.657730595535313, Accuracy: 0.0087890625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 0, Momentum: False\n",
      "Val Loss: 12.255360520511063, Val Accuracy: 0.014466666666666666\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.609804602139094, Accuracy: 0.0634765625\n",
      "Epoch: 200, Loss: 4.302876583955301, Accuracy: 0.0927734375\n",
      "Epoch: 300, Loss: 4.2819841112349994, Accuracy: 0.078125\n",
      "Epoch: 400, Loss: 3.9415856528710975, Accuracy: 0.1171875\n",
      "Epoch: 500, Loss: 3.6721032332312937, Accuracy: 0.146484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 500, Momentum: False\n",
      "Val Loss: 3.8455628094216907, Val Accuracy: 0.12493333333333333\n",
      "-----------\n",
      "Epoch: 600, Loss: 3.679127992530873, Accuracy: 0.1533203125\n",
      "Epoch: 700, Loss: 3.5315146165625135, Accuracy: 0.1572265625\n",
      "Epoch: 800, Loss: 3.5342917087681593, Accuracy: 0.1669921875\n",
      "Epoch: 900, Loss: 3.5462780263824096, Accuracy: 0.166015625\n",
      "Epoch: 1000, Loss: 3.376211017684358, Accuracy: 0.1787109375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 1000, Momentum: False\n",
      "Val Loss: 3.3711194404529445, Val Accuracy: 0.19023333333333334\n",
      "-----------\n",
      "Epoch: 1100, Loss: 3.32775273544821, Accuracy: 0.20703125\n",
      "Epoch: 1200, Loss: 3.184264746551693, Accuracy: 0.208984375\n",
      "Epoch: 1300, Loss: 3.1117028734739307, Accuracy: 0.22265625\n",
      "Epoch: 1400, Loss: 3.129305670401762, Accuracy: 0.224609375\n",
      "Epoch: 1500, Loss: 2.970070854227422, Accuracy: 0.2412109375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 1500, Momentum: False\n",
      "Val Loss: 3.0315964246455045, Val Accuracy: 0.2409\n",
      "-----------\n",
      "Epoch: 1600, Loss: 2.9146682461207867, Accuracy: 0.2529296875\n",
      "Epoch: 1700, Loss: 2.8948209921443784, Accuracy: 0.2587890625\n",
      "Epoch: 1800, Loss: 2.7478067031809377, Accuracy: 0.2958984375\n",
      "Epoch: 1900, Loss: 2.791184133150976, Accuracy: 0.2880859375\n",
      "Epoch: 2000, Loss: 2.7954636990358566, Accuracy: 0.27734375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 2000, Momentum: False\n",
      "Val Loss: 2.8328362972764767, Val Accuracy: 0.2779333333333333\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.6739797299035164, Accuracy: 0.326171875\n",
      "Epoch: 2200, Loss: 2.8187271266760785, Accuracy: 0.2890625\n",
      "Epoch: 2300, Loss: 2.687707366680203, Accuracy: 0.2958984375\n",
      "Epoch: 2400, Loss: 2.657613746778204, Accuracy: 0.3046875\n",
      "Epoch: 2500, Loss: 2.6652426878334, Accuracy: 0.3232421875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 2500, Momentum: False\n",
      "Val Loss: 2.6876831109927157, Val Accuracy: 0.30396666666666666\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.638155602485013, Accuracy: 0.306640625\n",
      "Epoch: 2700, Loss: 2.6187399821374573, Accuracy: 0.318359375\n",
      "Epoch: 2800, Loss: 2.614952292037554, Accuracy: 0.318359375\n",
      "Epoch: 2900, Loss: 2.6389755571481777, Accuracy: 0.310546875\n",
      "Epoch: 3000, Loss: 2.5976646686856935, Accuracy: 0.3359375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 3000, Momentum: False\n",
      "Val Loss: 2.577897121529102, Val Accuracy: 0.3297\n",
      "-----------\n",
      "Epoch: 3100, Loss: 2.4260526195509877, Accuracy: 0.384765625\n",
      "Epoch: 3200, Loss: 2.442995806168961, Accuracy: 0.365234375\n",
      "Epoch: 3300, Loss: 2.471650124255801, Accuracy: 0.34765625\n",
      "Epoch: 3400, Loss: 2.5048111463016447, Accuracy: 0.337890625\n",
      "Epoch: 3500, Loss: 2.5126769318785955, Accuracy: 0.326171875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 3500, Momentum: False\n",
      "Val Loss: 2.4968110866893833, Val Accuracy: 0.34983333333333333\n",
      "-----------\n",
      "Epoch: 3600, Loss: 2.5425061190565055, Accuracy: 0.3359375\n",
      "Epoch: 3700, Loss: 2.440894144510667, Accuracy: 0.357421875\n",
      "Epoch: 3800, Loss: 2.3600766660072843, Accuracy: 0.4013671875\n",
      "Epoch: 3900, Loss: 2.415203531134214, Accuracy: 0.365234375\n",
      "Epoch: 4000, Loss: 2.3394957998961514, Accuracy: 0.3974609375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 4000, Momentum: False\n",
      "Val Loss: 2.4251798823377047, Val Accuracy: 0.36673333333333336\n",
      "-----------\n",
      "Epoch: 4100, Loss: 2.4164266018187046, Accuracy: 0.3662109375\n",
      "Epoch: 4200, Loss: 2.4106814777363432, Accuracy: 0.349609375\n",
      "Epoch: 4300, Loss: 2.392375318893444, Accuracy: 0.3623046875\n",
      "Epoch: 4400, Loss: 2.356260102424791, Accuracy: 0.3759765625\n",
      "Epoch: 4500, Loss: 2.3576528870854325, Accuracy: 0.3759765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 4500, Momentum: False\n",
      "Val Loss: 2.3765785137467095, Val Accuracy: 0.37916666666666665\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.2596703740265456, Accuracy: 0.400390625\n",
      "Epoch: 4700, Loss: 2.3989958027804823, Accuracy: 0.3564453125\n",
      "Epoch: 4800, Loss: 2.29345192527184, Accuracy: 0.400390625\n",
      "Epoch: 4900, Loss: 2.3310883985192286, Accuracy: 0.388671875\n",
      "Epoch: 5000, Loss: 2.3147266603924006, Accuracy: 0.3955078125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 5000, Momentum: False\n",
      "Val Loss: 2.335528419349518, Val Accuracy: 0.3913333333333333\n",
      "-----------\n",
      "Epoch: 5100, Loss: 2.3196386401153144, Accuracy: 0.3779296875\n",
      "Epoch: 5200, Loss: 2.2676366247529094, Accuracy: 0.40625\n",
      "Epoch: 5300, Loss: 2.2853733666415694, Accuracy: 0.408203125\n",
      "Epoch: 5400, Loss: 2.2921218610133067, Accuracy: 0.40234375\n",
      "Epoch: 5500, Loss: 2.3600704488941844, Accuracy: 0.396484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 5500, Momentum: False\n",
      "Val Loss: 2.2980722477776094, Val Accuracy: 0.4010666666666667\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.2266036862396943, Accuracy: 0.4189453125\n",
      "Epoch: 5700, Loss: 2.2360043405945262, Accuracy: 0.4296875\n",
      "Epoch: 5800, Loss: 2.244873824016791, Accuracy: 0.4033203125\n",
      "Epoch: 5900, Loss: 2.224973980041298, Accuracy: 0.396484375\n",
      "Epoch: 6000, Loss: 2.2450351592801994, Accuracy: 0.4140625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 6000, Momentum: False\n",
      "Val Loss: 2.2621775024501227, Val Accuracy: 0.40913333333333335\n",
      "-----------\n",
      "Epoch: 6100, Loss: 2.127928390160615, Accuracy: 0.443359375\n",
      "Epoch: 6200, Loss: 2.2639373566054246, Accuracy: 0.4130859375\n",
      "Epoch: 6300, Loss: 2.2626309503103323, Accuracy: 0.40234375\n",
      "Epoch: 6400, Loss: 2.228915178900162, Accuracy: 0.427734375\n",
      "Epoch: 6500, Loss: 2.2073951098488434, Accuracy: 0.40234375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 6500, Momentum: False\n",
      "Val Loss: 2.2409547508418624, Val Accuracy: 0.4177\n",
      "-----------\n",
      "Epoch: 6600, Loss: 2.2143258596082784, Accuracy: 0.4248046875\n",
      "Epoch: 6700, Loss: 2.2125354509117665, Accuracy: 0.41796875\n",
      "Epoch: 6800, Loss: 2.1509648611666785, Accuracy: 0.4287109375\n",
      "Epoch: 6900, Loss: 2.208745094973773, Accuracy: 0.42578125\n",
      "Epoch: 7000, Loss: 2.2136426750889058, Accuracy: 0.4208984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 7000, Momentum: False\n",
      "Val Loss: 2.2138181057399615, Val Accuracy: 0.4235\n",
      "-----------\n",
      "Epoch: 7100, Loss: 2.1846158643030726, Accuracy: 0.44140625\n",
      "Epoch: 7200, Loss: 2.17661850302029, Accuracy: 0.4423828125\n",
      "Epoch: 7300, Loss: 2.1125253841786105, Accuracy: 0.4541015625\n",
      "Epoch: 7400, Loss: 2.109771655183079, Accuracy: 0.4599609375\n",
      "Epoch: 7500, Loss: 2.160210785513655, Accuracy: 0.4345703125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 7500, Momentum: False\n",
      "Val Loss: 2.1936519226373985, Val Accuracy: 0.431\n",
      "-----------\n",
      "Epoch: 7600, Loss: 2.068988667118508, Accuracy: 0.4716796875\n",
      "Epoch: 7700, Loss: 2.2465531389459548, Accuracy: 0.4111328125\n",
      "Epoch: 7800, Loss: 2.1653594695479637, Accuracy: 0.4453125\n",
      "Epoch: 7900, Loss: 2.098268051153079, Accuracy: 0.451171875\n",
      "Epoch: 8000, Loss: 2.158138724729483, Accuracy: 0.4296875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 8000, Momentum: False\n",
      "Val Loss: 2.178638340191466, Val Accuracy: 0.4335333333333333\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8100, Loss: 2.17140699322705, Accuracy: 0.4326171875\n",
      "Epoch: 8200, Loss: 2.080071467297895, Accuracy: 0.4619140625\n",
      "Epoch: 8300, Loss: 2.200231614717794, Accuracy: 0.439453125\n",
      "Epoch: 8400, Loss: 2.146267262216972, Accuracy: 0.419921875\n",
      "Epoch: 8500, Loss: 2.046529765796033, Accuracy: 0.466796875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 8500, Momentum: False\n",
      "Val Loss: 2.160277753288129, Val Accuracy: 0.4393666666666667\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.1010072676271183, Accuracy: 0.46484375\n",
      "Epoch: 8700, Loss: 2.072907404735569, Accuracy: 0.46484375\n",
      "Epoch: 8800, Loss: 2.204828533840916, Accuracy: 0.4326171875\n",
      "Epoch: 8900, Loss: 2.1136979193499528, Accuracy: 0.44921875\n",
      "Epoch: 9000, Loss: 2.1156075848495197, Accuracy: 0.443359375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 9000, Momentum: False\n",
      "Val Loss: 2.147527151228977, Val Accuracy: 0.4419\n",
      "-----------\n",
      "Epoch: 9100, Loss: 2.1026164023941765, Accuracy: 0.4482421875\n",
      "Epoch: 9200, Loss: 2.091610300841812, Accuracy: 0.4677734375\n",
      "Epoch: 9300, Loss: 2.134710382432532, Accuracy: 0.447265625\n",
      "Epoch: 9400, Loss: 2.1549901745268056, Accuracy: 0.42578125\n",
      "Epoch: 9500, Loss: 2.0239693788776263, Accuracy: 0.4775390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 9500, Momentum: False\n",
      "Val Loss: 2.1329464087790218, Val Accuracy: 0.4497\n",
      "-----------\n",
      "Epoch: 9600, Loss: 2.095100737184623, Accuracy: 0.4716796875\n",
      "Epoch: 9700, Loss: 2.0718016588051325, Accuracy: 0.4765625\n",
      "Epoch: 9800, Loss: 2.100230990989103, Accuracy: 0.451171875\n",
      "Epoch: 9900, Loss: 2.1047780717509297, Accuracy: 0.4501953125\n",
      "Epoch: 10000, Loss: 2.007053492374981, Accuracy: 0.4931640625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 10000, Momentum: False\n",
      "Val Loss: 2.1236018153322633, Val Accuracy: 0.4502333333333333\n",
      "-----------\n",
      "Epoch: 10100, Loss: 2.147479973195294, Accuracy: 0.431640625\n",
      "Epoch: 10200, Loss: 2.04071532568403, Accuracy: 0.482421875\n",
      "Epoch: 10300, Loss: 2.1391194109710225, Accuracy: 0.4453125\n",
      "Epoch: 10400, Loss: 2.0781670888074046, Accuracy: 0.4638671875\n",
      "Epoch: 10500, Loss: 2.041390958466568, Accuracy: 0.46875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 10500, Momentum: False\n",
      "Val Loss: 2.113098558184657, Val Accuracy: 0.4539666666666667\n",
      "-----------\n",
      "Epoch: 10600, Loss: 2.0537208572458856, Accuracy: 0.4794921875\n",
      "Epoch: 10700, Loss: 2.0191828054218113, Accuracy: 0.4765625\n",
      "Epoch: 10800, Loss: 2.095880419076197, Accuracy: 0.466796875\n",
      "Epoch: 10900, Loss: 2.0867969631208005, Accuracy: 0.4677734375\n",
      "Epoch: 11000, Loss: 2.093878717672214, Accuracy: 0.453125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 11000, Momentum: False\n",
      "Val Loss: 2.104023185165641, Val Accuracy: 0.4567\n",
      "-----------\n",
      "Epoch: 11100, Loss: 2.099300856234955, Accuracy: 0.4716796875\n",
      "Epoch: 11200, Loss: 2.0752927197993865, Accuracy: 0.46875\n",
      "Epoch: 11300, Loss: 2.1453347348347847, Accuracy: 0.4482421875\n",
      "Epoch: 11400, Loss: 2.034992209715576, Accuracy: 0.4775390625\n",
      "Epoch: 11500, Loss: 2.1782502437237943, Accuracy: 0.4423828125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 11500, Momentum: False\n",
      "Val Loss: 2.0954188367974718, Val Accuracy: 0.45986666666666665\n",
      "-----------\n",
      "Epoch: 11600, Loss: 2.068355738850937, Accuracy: 0.4814453125\n",
      "Epoch: 11700, Loss: 2.106686877184484, Accuracy: 0.4501953125\n",
      "Epoch: 11800, Loss: 2.030951055176059, Accuracy: 0.455078125\n",
      "Epoch: 11900, Loss: 2.0476381048342827, Accuracy: 0.455078125\n",
      "Epoch: 12000, Loss: 2.062960790015911, Accuracy: 0.4716796875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 12000, Momentum: False\n",
      "Val Loss: 2.0878884435536293, Val Accuracy: 0.45963333333333334\n",
      "-----------\n",
      "Epoch: 12100, Loss: 2.013404279241407, Accuracy: 0.4765625\n",
      "Epoch: 12200, Loss: 2.056846225835801, Accuracy: 0.4658203125\n",
      "Epoch: 12300, Loss: 2.1153409054611565, Accuracy: 0.4501953125\n",
      "Epoch: 12400, Loss: 2.0557967512529194, Accuracy: 0.462890625\n",
      "Epoch: 12500, Loss: 2.1065869237463413, Accuracy: 0.458984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 12500, Momentum: False\n",
      "Val Loss: 2.079945999903474, Val Accuracy: 0.4650666666666667\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.9805649391003584, Accuracy: 0.494140625\n",
      "Epoch: 12700, Loss: 2.0200525595958085, Accuracy: 0.4833984375\n",
      "Epoch: 12800, Loss: 2.02960858977864, Accuracy: 0.484375\n",
      "Epoch: 12900, Loss: 2.02684697528393, Accuracy: 0.4912109375\n",
      "Epoch: 13000, Loss: 2.0682158349199455, Accuracy: 0.4658203125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 13000, Momentum: False\n",
      "Val Loss: 2.0727515056235424, Val Accuracy: 0.466\n",
      "-----------\n",
      "Epoch: 13100, Loss: 2.014274885324374, Accuracy: 0.4921875\n",
      "Epoch: 13200, Loss: 2.03553647086271, Accuracy: 0.486328125\n",
      "Epoch: 13300, Loss: 2.0087178091296574, Accuracy: 0.4912109375\n",
      "Epoch: 13400, Loss: 1.975409897841677, Accuracy: 0.4814453125\n",
      "Epoch: 13500, Loss: 2.0845816063158153, Accuracy: 0.443359375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 13500, Momentum: False\n",
      "Val Loss: 2.0672158721235903, Val Accuracy: 0.4662\n",
      "-----------\n",
      "Epoch: 13600, Loss: 2.064620185190197, Accuracy: 0.4638671875\n",
      "Epoch: 13700, Loss: 2.0144210336419635, Accuracy: 0.4853515625\n",
      "Epoch: 13800, Loss: 2.0256735342160486, Accuracy: 0.46875\n",
      "Epoch: 13900, Loss: 2.042932226460662, Accuracy: 0.47265625\n",
      "Epoch: 14000, Loss: 2.056795807656821, Accuracy: 0.466796875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 14000, Momentum: False\n",
      "Val Loss: 2.0622082630240532, Val Accuracy: 0.4699333333333333\n",
      "-----------\n",
      "Epoch: 14100, Loss: 2.138834785137547, Accuracy: 0.4345703125\n",
      "Epoch: 14200, Loss: 2.046367721538115, Accuracy: 0.466796875\n",
      "Epoch: 14300, Loss: 2.0527859724988056, Accuracy: 0.4501953125\n",
      "Epoch: 14400, Loss: 2.0110916531493612, Accuracy: 0.48046875\n",
      "Epoch: 14500, Loss: 2.0439839939990057, Accuracy: 0.4638671875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 14500, Momentum: False\n",
      "Val Loss: 2.057645965522532, Val Accuracy: 0.4700666666666667\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.9159423639555204, Accuracy: 0.521484375\n",
      "Epoch: 14700, Loss: 1.9955992239925444, Accuracy: 0.4912109375\n",
      "Epoch: 14800, Loss: 1.9960104181459666, Accuracy: 0.48046875\n",
      "Epoch: 14900, Loss: 2.0168813446867437, Accuracy: 0.474609375\n",
      "Epoch: 15000, Loss: 2.0149078684966075, Accuracy: 0.46484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 15000, Momentum: False\n",
      "Val Loss: 2.052518745370503, Val Accuracy: 0.4693333333333333\n",
      "-----------\n",
      "Epoch: 15100, Loss: 2.0032238924858925, Accuracy: 0.4853515625\n",
      "Epoch: 15200, Loss: 2.023269505060812, Accuracy: 0.48046875\n",
      "Epoch: 15300, Loss: 1.9814862506940014, Accuracy: 0.4716796875\n",
      "Epoch: 15400, Loss: 2.0307551695515746, Accuracy: 0.4853515625\n",
      "Epoch: 15500, Loss: 2.0597961856512073, Accuracy: 0.4716796875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 15500, Momentum: False\n",
      "Val Loss: 2.048069684627281, Val Accuracy: 0.47053333333333336\n",
      "-----------\n",
      "Epoch: 15600, Loss: 2.0518304396032825, Accuracy: 0.4814453125\n",
      "Epoch: 15700, Loss: 2.00136134951908, Accuracy: 0.4833984375\n",
      "Epoch: 15800, Loss: 1.9221751183655456, Accuracy: 0.537109375\n",
      "Epoch: 15900, Loss: 2.0407725182127057, Accuracy: 0.478515625\n",
      "Epoch: 16000, Loss: 1.9662877293081555, Accuracy: 0.4970703125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 16000, Momentum: False\n",
      "Val Loss: 2.0442996995203067, Val Accuracy: 0.4734333333333333\n",
      "-----------\n",
      "Epoch: 16100, Loss: 2.022017679281679, Accuracy: 0.484375\n",
      "Epoch: 16200, Loss: 1.9847267776534974, Accuracy: 0.49609375\n",
      "Epoch: 16300, Loss: 2.0865800328560278, Accuracy: 0.462890625\n",
      "Epoch: 16400, Loss: 2.020044791641592, Accuracy: 0.486328125\n",
      "Epoch: 16500, Loss: 1.9761319658750243, Accuracy: 0.4912109375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 16500, Momentum: False\n",
      "Val Loss: 2.0395426324061914, Val Accuracy: 0.4749333333333333\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.9543354169163898, Accuracy: 0.501953125\n",
      "Epoch: 16700, Loss: 2.0466545023507656, Accuracy: 0.4833984375\n",
      "Epoch: 16800, Loss: 2.0339931582914277, Accuracy: 0.47265625\n",
      "Epoch: 16900, Loss: 1.9519364322260842, Accuracy: 0.4755859375\n",
      "Epoch: 17000, Loss: 1.9837906737623934, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 17000, Momentum: False\n",
      "Val Loss: 2.0357419025050367, Val Accuracy: 0.47473333333333334\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17100, Loss: 2.010724231414165, Accuracy: 0.4833984375\n",
      "Epoch: 17200, Loss: 1.9462292322347094, Accuracy: 0.5087890625\n",
      "Epoch: 17300, Loss: 1.9665664693362683, Accuracy: 0.494140625\n",
      "Epoch: 17400, Loss: 1.9670402943939944, Accuracy: 0.498046875\n",
      "Epoch: 17500, Loss: 2.0204298248288444, Accuracy: 0.4775390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 17500, Momentum: False\n",
      "Val Loss: 2.0340530246103485, Val Accuracy: 0.4765333333333333\n",
      "-----------\n",
      "Epoch: 17600, Loss: 2.0598287030816538, Accuracy: 0.4912109375\n",
      "Epoch: 17700, Loss: 1.9412964705524227, Accuracy: 0.505859375\n",
      "Epoch: 17800, Loss: 2.0045523986207776, Accuracy: 0.4716796875\n",
      "Epoch: 17900, Loss: 2.0122884484837025, Accuracy: 0.486328125\n",
      "Epoch: 18000, Loss: 1.9742447830726522, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 18000, Momentum: False\n",
      "Val Loss: 2.0293727277648306, Val Accuracy: 0.4772666666666667\n",
      "-----------\n",
      "Epoch: 18100, Loss: 1.956266168493077, Accuracy: 0.4853515625\n",
      "Epoch: 18200, Loss: 2.0365001370767972, Accuracy: 0.4765625\n",
      "Epoch: 18300, Loss: 2.0002761135726264, Accuracy: 0.474609375\n",
      "Epoch: 18400, Loss: 1.9188979532110197, Accuracy: 0.5087890625\n",
      "Epoch: 18500, Loss: 2.0305794226695983, Accuracy: 0.478515625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 18500, Momentum: False\n",
      "Val Loss: 2.0268190593066517, Val Accuracy: 0.47676666666666667\n",
      "-----------\n",
      "Epoch: 18600, Loss: 2.027072422720865, Accuracy: 0.4814453125\n",
      "Epoch: 18700, Loss: 1.9435799200293111, Accuracy: 0.5107421875\n",
      "Epoch: 18800, Loss: 1.990304930003291, Accuracy: 0.486328125\n",
      "Epoch: 18900, Loss: 2.0196817820311312, Accuracy: 0.4716796875\n",
      "Epoch: 19000, Loss: 1.9103643880676984, Accuracy: 0.5126953125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 19000, Momentum: False\n",
      "Val Loss: 2.0249829501785332, Val Accuracy: 0.4760666666666667\n",
      "-----------\n",
      "Epoch: 19100, Loss: 2.0258918553378082, Accuracy: 0.4931640625\n",
      "Epoch: 19200, Loss: 1.9841297415939603, Accuracy: 0.5107421875\n",
      "Epoch: 19300, Loss: 1.9266855275657675, Accuracy: 0.5107421875\n",
      "Epoch: 19400, Loss: 1.964714723340254, Accuracy: 0.486328125\n",
      "Epoch: 19500, Loss: 2.021745143521243, Accuracy: 0.482421875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 19500, Momentum: False\n",
      "Val Loss: 2.0219319773713744, Val Accuracy: 0.47923333333333334\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.9533368187596605, Accuracy: 0.505859375\n",
      "Epoch: 19700, Loss: 2.0287304691043264, Accuracy: 0.4619140625\n",
      "Epoch: 19800, Loss: 1.9474483307827848, Accuracy: 0.4970703125\n",
      "Epoch: 19900, Loss: 1.971400876489401, Accuracy: 0.4931640625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 0.001, Num Epoch: 19500, Momentum: False\n",
      "Test Loss: 2.0379347146877587, Test Accuracy: 0.4768605832003482\n",
      "-----------\n",
      "Epoch: 0, Loss: 16.251468482545306, Accuracy: 0.021484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 0, Momentum: True\n",
      "Val Loss: 10.51356451729188, Val Accuracy: 0.019033333333333333\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.352930665309141, Accuracy: 0.080078125\n",
      "Epoch: 200, Loss: 4.0013525882699135, Accuracy: 0.1015625\n",
      "Epoch: 300, Loss: 3.815844299312114, Accuracy: 0.14453125\n",
      "Epoch: 400, Loss: 3.561374600533534, Accuracy: 0.14453125\n",
      "Epoch: 500, Loss: 3.399021528794092, Accuracy: 0.1943359375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 500, Momentum: True\n",
      "Val Loss: 3.4279000632527303, Val Accuracy: 0.183\n",
      "-----------\n",
      "Epoch: 600, Loss: 3.204050242362545, Accuracy: 0.2412109375\n",
      "Epoch: 700, Loss: 3.173258527284634, Accuracy: 0.244140625\n",
      "Epoch: 800, Loss: 3.003512111446439, Accuracy: 0.25\n",
      "Epoch: 900, Loss: 2.9550017756869336, Accuracy: 0.263671875\n",
      "Epoch: 1000, Loss: 2.925401094851559, Accuracy: 0.255859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 1000, Momentum: True\n",
      "Val Loss: 2.936090924692887, Val Accuracy: 0.2713333333333333\n",
      "-----------\n",
      "Epoch: 1100, Loss: 2.8521842690470667, Accuracy: 0.302734375\n",
      "Epoch: 1200, Loss: 2.7761357179490904, Accuracy: 0.318359375\n",
      "Epoch: 1300, Loss: 2.600660167983462, Accuracy: 0.33984375\n",
      "Epoch: 1400, Loss: 2.6390465494054505, Accuracy: 0.3271484375\n",
      "Epoch: 1500, Loss: 2.7594897679292822, Accuracy: 0.310546875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 1500, Momentum: True\n",
      "Val Loss: 2.6692213180998188, Val Accuracy: 0.32266666666666666\n",
      "-----------\n",
      "Epoch: 1600, Loss: 2.5858897521054636, Accuracy: 0.3388671875\n",
      "Epoch: 1700, Loss: 2.5616183563848023, Accuracy: 0.357421875\n",
      "Epoch: 1800, Loss: 2.5487438787709764, Accuracy: 0.34375\n",
      "Epoch: 1900, Loss: 2.481673445825975, Accuracy: 0.3564453125\n",
      "Epoch: 2000, Loss: 2.512014329413661, Accuracy: 0.357421875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 2000, Momentum: True\n",
      "Val Loss: 2.530719047140619, Val Accuracy: 0.3516666666666667\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.4396756554601473, Accuracy: 0.3671875\n",
      "Epoch: 2200, Loss: 2.398948614240161, Accuracy: 0.37890625\n",
      "Epoch: 2300, Loss: 2.3845266964695315, Accuracy: 0.3876953125\n",
      "Epoch: 2400, Loss: 2.279108035102805, Accuracy: 0.396484375\n",
      "Epoch: 2500, Loss: 2.3666630792181014, Accuracy: 0.388671875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 2500, Momentum: True\n",
      "Val Loss: 2.404862397392454, Val Accuracy: 0.3801\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.3626674618076056, Accuracy: 0.3701171875\n",
      "Epoch: 2700, Loss: 2.3592730439273426, Accuracy: 0.384765625\n",
      "Epoch: 2800, Loss: 2.3343386054784894, Accuracy: 0.412109375\n",
      "Epoch: 2900, Loss: 2.2629298010551335, Accuracy: 0.41015625\n",
      "Epoch: 3000, Loss: 2.267990272990486, Accuracy: 0.4072265625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 3000, Momentum: True\n",
      "Val Loss: 2.3242605997255468, Val Accuracy: 0.4004333333333333\n",
      "-----------\n",
      "Epoch: 3100, Loss: 2.289853167616949, Accuracy: 0.4033203125\n",
      "Epoch: 3200, Loss: 2.254927623518464, Accuracy: 0.4130859375\n",
      "Epoch: 3300, Loss: 2.244639509737583, Accuracy: 0.435546875\n",
      "Epoch: 3400, Loss: 2.216960814745341, Accuracy: 0.4169921875\n",
      "Epoch: 3500, Loss: 2.1867726188952785, Accuracy: 0.41796875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 3500, Momentum: True\n",
      "Val Loss: 2.2538109497481553, Val Accuracy: 0.4146666666666667\n",
      "-----------\n",
      "Epoch: 3600, Loss: 2.1978306525017994, Accuracy: 0.41796875\n",
      "Epoch: 3700, Loss: 2.157191279893664, Accuracy: 0.4296875\n",
      "Epoch: 3800, Loss: 2.158310797165249, Accuracy: 0.4443359375\n",
      "Epoch: 3900, Loss: 2.0585883986341273, Accuracy: 0.45703125\n",
      "Epoch: 4000, Loss: 2.0784034333457915, Accuracy: 0.447265625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 4000, Momentum: True\n",
      "Val Loss: 2.1913087627087244, Val Accuracy: 0.4269\n",
      "-----------\n",
      "Epoch: 4100, Loss: 2.1171838953982554, Accuracy: 0.44140625\n",
      "Epoch: 4200, Loss: 1.978998952095738, Accuracy: 0.486328125\n",
      "Epoch: 4300, Loss: 2.0491456487323467, Accuracy: 0.4619140625\n",
      "Epoch: 4400, Loss: 2.1003995252761625, Accuracy: 0.4580078125\n",
      "Epoch: 4500, Loss: 2.1044172938498487, Accuracy: 0.4453125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 4500, Momentum: True\n",
      "Val Loss: 2.1515139218928043, Val Accuracy: 0.4377333333333333\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.0588725889746526, Accuracy: 0.4541015625\n",
      "Epoch: 4700, Loss: 2.0319836914339, Accuracy: 0.46875\n",
      "Epoch: 4800, Loss: 1.974277269691957, Accuracy: 0.4638671875\n",
      "Epoch: 4900, Loss: 1.980808266265524, Accuracy: 0.4775390625\n",
      "Epoch: 5000, Loss: 2.0205574167993805, Accuracy: 0.4716796875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 5000, Momentum: True\n",
      "Val Loss: 2.1228842951040985, Val Accuracy: 0.4433666666666667\n",
      "-----------\n",
      "Epoch: 5100, Loss: 2.086006358233088, Accuracy: 0.4482421875\n",
      "Epoch: 5200, Loss: 2.039370071613326, Accuracy: 0.4453125\n",
      "Epoch: 5300, Loss: 1.9877699878424135, Accuracy: 0.470703125\n",
      "Epoch: 5400, Loss: 2.0273993666917773, Accuracy: 0.458984375\n",
      "Epoch: 5500, Loss: 2.0784286962400915, Accuracy: 0.4580078125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 5500, Momentum: True\n",
      "Val Loss: 2.0899888928261077, Val Accuracy: 0.45193333333333335\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.0086264506364597, Accuracy: 0.4716796875\n",
      "Epoch: 5700, Loss: 2.0654357102346657, Accuracy: 0.4443359375\n",
      "Epoch: 5800, Loss: 2.0215419703146575, Accuracy: 0.458984375\n",
      "Epoch: 5900, Loss: 2.022960487641312, Accuracy: 0.4716796875\n",
      "Epoch: 6000, Loss: 1.9806447509575513, Accuracy: 0.4951171875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 6000, Momentum: True\n",
      "Val Loss: 2.059335317538506, Val Accuracy: 0.4555\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6100, Loss: 1.956250330761602, Accuracy: 0.4873046875\n",
      "Epoch: 6200, Loss: 1.8931427253597017, Accuracy: 0.4912109375\n",
      "Epoch: 6300, Loss: 1.996016374742509, Accuracy: 0.462890625\n",
      "Epoch: 6400, Loss: 1.9793190891977157, Accuracy: 0.4736328125\n",
      "Epoch: 6500, Loss: 1.9360811762461743, Accuracy: 0.4951171875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 6500, Momentum: True\n",
      "Val Loss: 2.048194291199943, Val Accuracy: 0.4565666666666667\n",
      "-----------\n",
      "Epoch: 6600, Loss: 1.913971034911616, Accuracy: 0.5009765625\n",
      "Epoch: 6700, Loss: 1.8917277724246717, Accuracy: 0.5029296875\n",
      "Epoch: 6800, Loss: 2.02040892940989, Accuracy: 0.478515625\n",
      "Epoch: 6900, Loss: 1.8596340487770893, Accuracy: 0.5107421875\n",
      "Epoch: 7000, Loss: 1.921812479406206, Accuracy: 0.49609375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 7000, Momentum: True\n",
      "Val Loss: 2.011904268312032, Val Accuracy: 0.46576666666666666\n",
      "-----------\n",
      "Epoch: 7100, Loss: 1.9423617743242998, Accuracy: 0.494140625\n",
      "Epoch: 7200, Loss: 1.9091581072293193, Accuracy: 0.486328125\n",
      "Epoch: 7300, Loss: 2.0104949782014625, Accuracy: 0.4580078125\n",
      "Epoch: 7400, Loss: 1.9899297574030146, Accuracy: 0.4873046875\n",
      "Epoch: 7500, Loss: 1.9440733671383161, Accuracy: 0.4775390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 7500, Momentum: True\n",
      "Val Loss: 2.0012976416771444, Val Accuracy: 0.4661666666666667\n",
      "-----------\n",
      "Epoch: 7600, Loss: 1.8525992679184815, Accuracy: 0.505859375\n",
      "Epoch: 7700, Loss: 1.976028831320972, Accuracy: 0.46875\n",
      "Epoch: 7800, Loss: 1.9481211253680213, Accuracy: 0.48046875\n",
      "Epoch: 7900, Loss: 1.921168798632967, Accuracy: 0.482421875\n",
      "Epoch: 8000, Loss: 1.8977742291056603, Accuracy: 0.4912109375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 8000, Momentum: True\n",
      "Val Loss: 1.978940633145792, Val Accuracy: 0.47263333333333335\n",
      "-----------\n",
      "Epoch: 8100, Loss: 1.8806178881827744, Accuracy: 0.484375\n",
      "Epoch: 8200, Loss: 1.8600356077744147, Accuracy: 0.4873046875\n",
      "Epoch: 8300, Loss: 1.9333695766119998, Accuracy: 0.484375\n",
      "Epoch: 8400, Loss: 1.8539283412690906, Accuracy: 0.513671875\n",
      "Epoch: 8500, Loss: 1.8797040334677728, Accuracy: 0.49609375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 8500, Momentum: True\n",
      "Val Loss: 1.9714936264903393, Val Accuracy: 0.4761\n",
      "-----------\n",
      "Epoch: 8600, Loss: 1.811493429682423, Accuracy: 0.505859375\n",
      "Epoch: 8700, Loss: 1.8857342306174663, Accuracy: 0.484375\n",
      "Epoch: 8800, Loss: 1.788209748817914, Accuracy: 0.5087890625\n",
      "Epoch: 8900, Loss: 1.7717427425266568, Accuracy: 0.5224609375\n",
      "Epoch: 9000, Loss: 1.8177066610360573, Accuracy: 0.5185546875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 9000, Momentum: True\n",
      "Val Loss: 1.957809195828658, Val Accuracy: 0.47946666666666665\n",
      "-----------\n",
      "Epoch: 9100, Loss: 1.865654480456811, Accuracy: 0.48828125\n",
      "Epoch: 9200, Loss: 1.8501760911236154, Accuracy: 0.498046875\n",
      "Epoch: 9300, Loss: 1.7668238793594364, Accuracy: 0.50390625\n",
      "Epoch: 9400, Loss: 1.9108261871263674, Accuracy: 0.4912109375\n",
      "Epoch: 9500, Loss: 1.8479614127987267, Accuracy: 0.5068359375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 9500, Momentum: True\n",
      "Val Loss: 1.945299900867381, Val Accuracy: 0.48013333333333336\n",
      "-----------\n",
      "Epoch: 9600, Loss: 1.7743156232767596, Accuracy: 0.5400390625\n",
      "Epoch: 9700, Loss: 1.8837610274862497, Accuracy: 0.4873046875\n",
      "Epoch: 9800, Loss: 1.9689751432161207, Accuracy: 0.466796875\n",
      "Epoch: 9900, Loss: 1.7880268084488493, Accuracy: 0.5205078125\n",
      "Epoch: 10000, Loss: 1.9105603559940367, Accuracy: 0.484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 10000, Momentum: True\n",
      "Val Loss: 1.9254300508743627, Val Accuracy: 0.4856333333333333\n",
      "-----------\n",
      "Epoch: 10100, Loss: 1.7523597116470315, Accuracy: 0.529296875\n",
      "Epoch: 10200, Loss: 1.7711703246094834, Accuracy: 0.5361328125\n",
      "Epoch: 10300, Loss: 1.851871363062876, Accuracy: 0.4990234375\n",
      "Epoch: 10400, Loss: 1.8114106209193355, Accuracy: 0.5185546875\n",
      "Epoch: 10500, Loss: 1.8506929375111172, Accuracy: 0.490234375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 10500, Momentum: True\n",
      "Val Loss: 1.9263902321014024, Val Accuracy: 0.48336666666666667\n",
      "-----------\n",
      "Epoch: 10600, Loss: 1.7238309779338228, Accuracy: 0.52734375\n",
      "Epoch: 10700, Loss: 1.7951272011833046, Accuracy: 0.51171875\n",
      "Epoch: 10800, Loss: 1.8143617231812974, Accuracy: 0.5263671875\n",
      "Epoch: 10900, Loss: 1.7306564065586605, Accuracy: 0.5390625\n",
      "Epoch: 11000, Loss: 1.704231767439199, Accuracy: 0.5224609375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 11000, Momentum: True\n",
      "Val Loss: 1.9156947853831168, Val Accuracy: 0.48643333333333333\n",
      "-----------\n",
      "Epoch: 11100, Loss: 1.801690822515309, Accuracy: 0.4951171875\n",
      "Epoch: 11200, Loss: 1.7670257842677966, Accuracy: 0.5009765625\n",
      "Epoch: 11300, Loss: 1.7501860473322242, Accuracy: 0.533203125\n",
      "Epoch: 11400, Loss: 1.769954583607357, Accuracy: 0.51171875\n",
      "Epoch: 11500, Loss: 1.819753785554616, Accuracy: 0.5107421875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 11500, Momentum: True\n",
      "Val Loss: 1.9081073737917575, Val Accuracy: 0.4876\n",
      "-----------\n",
      "Epoch: 11600, Loss: 1.7342291131905578, Accuracy: 0.5283203125\n",
      "Epoch: 11700, Loss: 1.8256050787928124, Accuracy: 0.509765625\n",
      "Epoch: 11800, Loss: 1.8073825620803046, Accuracy: 0.5205078125\n",
      "Epoch: 11900, Loss: 1.8061905759360357, Accuracy: 0.505859375\n",
      "Epoch: 12000, Loss: 1.8441804776367268, Accuracy: 0.5244140625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 12000, Momentum: True\n",
      "Val Loss: 1.8935454385671013, Val Accuracy: 0.49393333333333334\n",
      "-----------\n",
      "Epoch: 12100, Loss: 1.6782700731489433, Accuracy: 0.5341796875\n",
      "Epoch: 12200, Loss: 1.8594272213456065, Accuracy: 0.4951171875\n",
      "Epoch: 12300, Loss: 1.7653464248950075, Accuracy: 0.5107421875\n",
      "Epoch: 12400, Loss: 1.73304871431713, Accuracy: 0.5302734375\n",
      "Epoch: 12500, Loss: 1.7495907353686968, Accuracy: 0.517578125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 12500, Momentum: True\n",
      "Val Loss: 1.8826650083720065, Val Accuracy: 0.4960333333333333\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.8028711428942614, Accuracy: 0.5185546875\n",
      "Epoch: 12700, Loss: 1.7819541308360785, Accuracy: 0.517578125\n",
      "Epoch: 12800, Loss: 1.7829255715318293, Accuracy: 0.513671875\n",
      "Epoch: 12900, Loss: 1.7519459207288914, Accuracy: 0.5146484375\n",
      "Epoch: 13000, Loss: 1.7854217503425591, Accuracy: 0.525390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 13000, Momentum: True\n",
      "Val Loss: 1.8809419700724266, Val Accuracy: 0.4963666666666667\n",
      "-----------\n",
      "Epoch: 13100, Loss: 1.7438811508795586, Accuracy: 0.5224609375\n",
      "Epoch: 13200, Loss: 1.7406096854449207, Accuracy: 0.515625\n",
      "Epoch: 13300, Loss: 1.6811538404152093, Accuracy: 0.53515625\n",
      "Epoch: 13400, Loss: 1.819173753101245, Accuracy: 0.5205078125\n",
      "Epoch: 13500, Loss: 1.703497013253715, Accuracy: 0.5283203125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 13500, Momentum: True\n",
      "Val Loss: 1.8754071487016568, Val Accuracy: 0.4970333333333333\n",
      "-----------\n",
      "Epoch: 13600, Loss: 1.698884798657041, Accuracy: 0.5234375\n",
      "Epoch: 13700, Loss: 1.7881628536350562, Accuracy: 0.5048828125\n",
      "Epoch: 13800, Loss: 1.7339669849475006, Accuracy: 0.51171875\n",
      "Epoch: 13900, Loss: 1.7401335786562084, Accuracy: 0.5224609375\n",
      "Epoch: 14000, Loss: 1.7490804553626975, Accuracy: 0.525390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 14000, Momentum: True\n",
      "Val Loss: 1.876724276846495, Val Accuracy: 0.4970333333333333\n",
      "-----------\n",
      "Epoch: 14100, Loss: 1.762466455370006, Accuracy: 0.5302734375\n",
      "Epoch: 14200, Loss: 1.7441848433231804, Accuracy: 0.5107421875\n",
      "Epoch: 14300, Loss: 1.6235423381935146, Accuracy: 0.560546875\n",
      "Epoch: 14400, Loss: 1.7739368926929224, Accuracy: 0.5224609375\n",
      "Epoch: 14500, Loss: 1.709051547677447, Accuracy: 0.5380859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 14500, Momentum: True\n",
      "Val Loss: 1.85976060290445, Val Accuracy: 0.5002333333333333\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.8253026238975114, Accuracy: 0.509765625\n",
      "Epoch: 14700, Loss: 1.741280471102416, Accuracy: 0.51953125\n",
      "Epoch: 14800, Loss: 1.68874213187545, Accuracy: 0.5458984375\n",
      "Epoch: 14900, Loss: 1.7081083034938458, Accuracy: 0.5234375\n",
      "Epoch: 15000, Loss: 1.6730145515949102, Accuracy: 0.5361328125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 15000, Momentum: True\n",
      "Val Loss: 1.8561188633478392, Val Accuracy: 0.5010333333333333\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15100, Loss: 1.7038839144898534, Accuracy: 0.525390625\n",
      "Epoch: 15200, Loss: 1.7399878056488958, Accuracy: 0.5263671875\n",
      "Epoch: 15300, Loss: 1.6900672432817574, Accuracy: 0.5390625\n",
      "Epoch: 15400, Loss: 1.726480384764379, Accuracy: 0.529296875\n",
      "Epoch: 15500, Loss: 1.5952339550737955, Accuracy: 0.5439453125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 15500, Momentum: True\n",
      "Val Loss: 1.855531902296859, Val Accuracy: 0.5013666666666666\n",
      "-----------\n",
      "Epoch: 15600, Loss: 1.7231643462813122, Accuracy: 0.5263671875\n",
      "Epoch: 15700, Loss: 1.7609982987117372, Accuracy: 0.5185546875\n",
      "Epoch: 15800, Loss: 1.668619441589482, Accuracy: 0.5341796875\n",
      "Epoch: 15900, Loss: 1.7477155109408042, Accuracy: 0.53125\n",
      "Epoch: 16000, Loss: 1.7323222500734021, Accuracy: 0.486328125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 16000, Momentum: True\n",
      "Val Loss: 1.8481119598960467, Val Accuracy: 0.5009666666666667\n",
      "-----------\n",
      "Epoch: 16100, Loss: 1.6811729036901943, Accuracy: 0.541015625\n",
      "Epoch: 16200, Loss: 1.6750241961487529, Accuracy: 0.544921875\n",
      "Epoch: 16300, Loss: 1.7540011716267867, Accuracy: 0.5263671875\n",
      "Epoch: 16400, Loss: 1.7354465425984977, Accuracy: 0.513671875\n",
      "Epoch: 16500, Loss: 1.8316086748137184, Accuracy: 0.505859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 16500, Momentum: True\n",
      "Val Loss: 1.8610420515944228, Val Accuracy: 0.4989\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.7425527288059937, Accuracy: 0.5244140625\n",
      "Epoch: 16700, Loss: 1.680066675093002, Accuracy: 0.5341796875\n",
      "Epoch: 16800, Loss: 1.6393829632717487, Accuracy: 0.5673828125\n",
      "Epoch: 16900, Loss: 1.7084751486688017, Accuracy: 0.5126953125\n",
      "Epoch: 17000, Loss: 1.6865351361438252, Accuracy: 0.5380859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 17000, Momentum: True\n",
      "Val Loss: 1.8356349862569903, Val Accuracy: 0.5042\n",
      "-----------\n",
      "Epoch: 17100, Loss: 1.6265379637031216, Accuracy: 0.546875\n",
      "Epoch: 17200, Loss: 1.7011407574750916, Accuracy: 0.5224609375\n",
      "Epoch: 17300, Loss: 1.6646835829100617, Accuracy: 0.5390625\n",
      "Epoch: 17400, Loss: 1.7803021995099542, Accuracy: 0.5029296875\n",
      "Epoch: 17500, Loss: 1.6576803150092245, Accuracy: 0.5390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 17500, Momentum: True\n",
      "Val Loss: 1.8369266896281566, Val Accuracy: 0.5031666666666667\n",
      "-----------\n",
      "Epoch: 17600, Loss: 1.6678184781291157, Accuracy: 0.52734375\n",
      "Epoch: 17700, Loss: 1.6331586041579123, Accuracy: 0.5517578125\n",
      "Epoch: 17800, Loss: 1.6502353405903518, Accuracy: 0.5478515625\n",
      "Epoch: 17900, Loss: 1.7988478473434737, Accuracy: 0.5009765625\n",
      "Epoch: 18000, Loss: 1.7036776063465058, Accuracy: 0.53515625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 18000, Momentum: True\n",
      "Val Loss: 1.8314144296922528, Val Accuracy: 0.5038666666666667\n",
      "-----------\n",
      "Epoch: 18100, Loss: 1.7160979425747345, Accuracy: 0.5361328125\n",
      "Epoch: 18200, Loss: 1.659378806358235, Accuracy: 0.5234375\n",
      "Epoch: 18300, Loss: 1.7248443496265367, Accuracy: 0.529296875\n",
      "Epoch: 18400, Loss: 1.6007363639853245, Accuracy: 0.5458984375\n",
      "Epoch: 18500, Loss: 1.6264750993548946, Accuracy: 0.5478515625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 18500, Momentum: True\n",
      "Val Loss: 1.8237012303946454, Val Accuracy: 0.5072\n",
      "-----------\n",
      "Epoch: 18600, Loss: 1.5766629643506125, Accuracy: 0.560546875\n",
      "Epoch: 18700, Loss: 1.6642821345637593, Accuracy: 0.544921875\n",
      "Epoch: 18800, Loss: 1.6870978274205004, Accuracy: 0.544921875\n",
      "Epoch: 18900, Loss: 1.7214474881694115, Accuracy: 0.5341796875\n",
      "Epoch: 19000, Loss: 1.756748808859347, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 19000, Momentum: True\n",
      "Val Loss: 1.8388026787639555, Val Accuracy: 0.5025666666666667\n",
      "-----------\n",
      "Epoch: 19100, Loss: 1.733426832531782, Accuracy: 0.5107421875\n",
      "Epoch: 19200, Loss: 1.6789871388507764, Accuracy: 0.5361328125\n",
      "Epoch: 19300, Loss: 1.6666564847705172, Accuracy: 0.5322265625\n",
      "Epoch: 19400, Loss: 1.6136569298348329, Accuracy: 0.5458984375\n",
      "Epoch: 19500, Loss: 1.6572856183498723, Accuracy: 0.5595703125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 19500, Momentum: True\n",
      "Val Loss: 1.8281111330939193, Val Accuracy: 0.5056333333333334\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.6933683498957013, Accuracy: 0.5263671875\n",
      "Epoch: 19700, Loss: 1.6358070595695917, Accuracy: 0.5654296875\n",
      "Epoch: 19800, Loss: 1.6542152784966957, Accuracy: 0.544921875\n",
      "Epoch: 19900, Loss: 1.6334140955920313, Accuracy: 0.55859375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 18500, Momentum: True\n",
      "Test Loss: 1.8301666392173725, Test Accuracy: 0.5043522414043232\n",
      "-----------\n",
      "Epoch: 0, Loss: 12.821386189525736, Accuracy: 0.02734375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 0, Momentum: False\n",
      "Val Loss: 10.391394290199216, Val Accuracy: 0.0287\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.578947654494926, Accuracy: 0.0634765625\n",
      "Epoch: 200, Loss: 4.437379706986265, Accuracy: 0.0556640625\n",
      "Epoch: 300, Loss: 4.399305758242132, Accuracy: 0.0732421875\n",
      "Epoch: 400, Loss: 4.228755139521436, Accuracy: 0.0908203125\n",
      "Epoch: 500, Loss: 4.100463620476014, Accuracy: 0.1083984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 500, Momentum: False\n",
      "Val Loss: 3.9413287820231404, Val Accuracy: 0.1141\n",
      "-----------\n",
      "Epoch: 600, Loss: 3.7063163222426723, Accuracy: 0.1572265625\n",
      "Epoch: 700, Loss: 3.702551730976617, Accuracy: 0.1552734375\n",
      "Epoch: 800, Loss: 3.499214868859367, Accuracy: 0.1904296875\n",
      "Epoch: 900, Loss: 3.519867137507134, Accuracy: 0.185546875\n",
      "Epoch: 1000, Loss: 3.424805140556687, Accuracy: 0.189453125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 1000, Momentum: False\n",
      "Val Loss: 3.4529317069532497, Val Accuracy: 0.19386666666666666\n",
      "-----------\n",
      "Epoch: 1100, Loss: 3.314797091331242, Accuracy: 0.2119140625\n",
      "Epoch: 1200, Loss: 3.2132644598969407, Accuracy: 0.216796875\n",
      "Epoch: 1300, Loss: 3.2208541742918806, Accuracy: 0.234375\n",
      "Epoch: 1400, Loss: 3.27686189718969, Accuracy: 0.201171875\n",
      "Epoch: 1500, Loss: 3.0981099893334436, Accuracy: 0.2470703125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 1500, Momentum: False\n",
      "Val Loss: 3.1200543125129037, Val Accuracy: 0.2373\n",
      "-----------\n",
      "Epoch: 1600, Loss: 3.093286760736409, Accuracy: 0.25\n",
      "Epoch: 1700, Loss: 3.001841371956572, Accuracy: 0.265625\n",
      "Epoch: 1800, Loss: 2.862399894580435, Accuracy: 0.2783203125\n",
      "Epoch: 1900, Loss: 2.874544254037648, Accuracy: 0.2861328125\n",
      "Epoch: 2000, Loss: 2.90059151333144, Accuracy: 0.267578125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 2000, Momentum: False\n",
      "Val Loss: 2.9677956943362545, Val Accuracy: 0.2669\n",
      "-----------\n",
      "Epoch: 2100, Loss: 2.833243936432812, Accuracy: 0.2880859375\n",
      "Epoch: 2200, Loss: 2.8760802023342267, Accuracy: 0.2998046875\n",
      "Epoch: 2300, Loss: 3.003609527597597, Accuracy: 0.2734375\n",
      "Epoch: 2400, Loss: 2.7638743598334736, Accuracy: 0.310546875\n",
      "Epoch: 2500, Loss: 2.826329157862012, Accuracy: 0.29296875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 2500, Momentum: False\n",
      "Val Loss: 2.78521365502571, Val Accuracy: 0.2976666666666667\n",
      "-----------\n",
      "Epoch: 2600, Loss: 2.6862070421905013, Accuracy: 0.3017578125\n",
      "Epoch: 2700, Loss: 2.642476777110521, Accuracy: 0.3349609375\n",
      "Epoch: 2800, Loss: 2.6931210112663644, Accuracy: 0.314453125\n",
      "Epoch: 2900, Loss: 2.7154249527499434, Accuracy: 0.3115234375\n",
      "Epoch: 3000, Loss: 2.6809162600147514, Accuracy: 0.306640625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 3000, Momentum: False\n",
      "Val Loss: 2.7016384785882575, Val Accuracy: 0.3166\n",
      "-----------\n",
      "Epoch: 3100, Loss: 2.5600612174458997, Accuracy: 0.3505859375\n",
      "Epoch: 3200, Loss: 2.6698849121965917, Accuracy: 0.3193359375\n",
      "Epoch: 3300, Loss: 2.6083879066807203, Accuracy: 0.3251953125\n",
      "Epoch: 3400, Loss: 2.5453457116133658, Accuracy: 0.349609375\n",
      "Epoch: 3500, Loss: 2.6190567319538434, Accuracy: 0.359375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 3500, Momentum: False\n",
      "Val Loss: 2.5926969309393217, Val Accuracy: 0.34063333333333334\n",
      "-----------\n",
      "Epoch: 3600, Loss: 2.5313141295692905, Accuracy: 0.359375\n",
      "Epoch: 3700, Loss: 2.565949596853649, Accuracy: 0.3505859375\n",
      "Epoch: 3800, Loss: 2.5303782380718705, Accuracy: 0.353515625\n",
      "Epoch: 3900, Loss: 2.5046221023844435, Accuracy: 0.3564453125\n",
      "Epoch: 4000, Loss: 2.549121331619218, Accuracy: 0.3564453125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 4000, Momentum: False\n",
      "Val Loss: 2.497457044464855, Val Accuracy: 0.36256666666666665\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4100, Loss: 2.392640268304296, Accuracy: 0.38671875\n",
      "Epoch: 4200, Loss: 2.4722719300455913, Accuracy: 0.3759765625\n",
      "Epoch: 4300, Loss: 2.362139448699002, Accuracy: 0.404296875\n",
      "Epoch: 4400, Loss: 2.358739412585611, Accuracy: 0.376953125\n",
      "Epoch: 4500, Loss: 2.417814706556814, Accuracy: 0.369140625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 4500, Momentum: False\n",
      "Val Loss: 2.4449765566412354, Val Accuracy: 0.3732666666666667\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.3772696188445837, Accuracy: 0.375\n",
      "Epoch: 4700, Loss: 2.3836090719237113, Accuracy: 0.3896484375\n",
      "Epoch: 4800, Loss: 2.395877322713528, Accuracy: 0.376953125\n",
      "Epoch: 4900, Loss: 2.36297255676246, Accuracy: 0.390625\n",
      "Epoch: 5000, Loss: 2.3805448118232313, Accuracy: 0.400390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 5000, Momentum: False\n",
      "Val Loss: 2.3964421349045515, Val Accuracy: 0.3831\n",
      "-----------\n",
      "Epoch: 5100, Loss: 2.3164737946572576, Accuracy: 0.3994140625\n",
      "Epoch: 5200, Loss: 2.3327096562636918, Accuracy: 0.396484375\n",
      "Epoch: 5300, Loss: 2.2791914969484823, Accuracy: 0.40234375\n",
      "Epoch: 5400, Loss: 2.338671492270371, Accuracy: 0.4169921875\n",
      "Epoch: 5500, Loss: 2.300834783437237, Accuracy: 0.3984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 5500, Momentum: False\n",
      "Val Loss: 2.352001725899614, Val Accuracy: 0.39366666666666666\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.2488179172520093, Accuracy: 0.4111328125\n",
      "Epoch: 5700, Loss: 2.3012964218076712, Accuracy: 0.3828125\n",
      "Epoch: 5800, Loss: 2.265920593117946, Accuracy: 0.4091796875\n",
      "Epoch: 5900, Loss: 2.2534646954705986, Accuracy: 0.41796875\n",
      "Epoch: 6000, Loss: 2.275431179489055, Accuracy: 0.412109375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 6000, Momentum: False\n",
      "Val Loss: 2.2983957917755506, Val Accuracy: 0.4041\n",
      "-----------\n",
      "Epoch: 6100, Loss: 2.2717141324094756, Accuracy: 0.4013671875\n",
      "Epoch: 6200, Loss: 2.2826303679703535, Accuracy: 0.404296875\n",
      "Epoch: 6300, Loss: 2.312570182878856, Accuracy: 0.3916015625\n",
      "Epoch: 6400, Loss: 2.2625697348624376, Accuracy: 0.416015625\n",
      "Epoch: 6500, Loss: 2.258454531711487, Accuracy: 0.408203125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 6500, Momentum: False\n",
      "Val Loss: 2.2727055962960363, Val Accuracy: 0.4111666666666667\n",
      "-----------\n",
      "Epoch: 6600, Loss: 2.236519819037242, Accuracy: 0.4150390625\n",
      "Epoch: 6700, Loss: 2.2472477000622373, Accuracy: 0.4072265625\n",
      "Epoch: 6800, Loss: 2.2726153625757206, Accuracy: 0.4150390625\n",
      "Epoch: 6900, Loss: 2.2574978364503897, Accuracy: 0.39453125\n",
      "Epoch: 7000, Loss: 1.9926936536097888, Accuracy: 0.455078125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 7000, Momentum: False\n",
      "Val Loss: 2.2538156751102356, Val Accuracy: 0.41736666666666666\n",
      "-----------\n",
      "Epoch: 7100, Loss: 2.1341049165551533, Accuracy: 0.439453125\n",
      "Epoch: 7200, Loss: 2.203751716387095, Accuracy: 0.4169921875\n",
      "Epoch: 7300, Loss: 2.2052928081426346, Accuracy: 0.421875\n",
      "Epoch: 7400, Loss: 2.0300402691249695, Accuracy: 0.46484375\n",
      "Epoch: 7500, Loss: 2.18070995626302, Accuracy: 0.443359375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 7500, Momentum: False\n",
      "Val Loss: 2.213377148516982, Val Accuracy: 0.4252666666666667\n",
      "-----------\n",
      "Epoch: 7600, Loss: 2.1721918535248252, Accuracy: 0.427734375\n",
      "Epoch: 7700, Loss: 2.088973562921762, Accuracy: 0.4560546875\n",
      "Epoch: 7800, Loss: 2.176005944734989, Accuracy: 0.4248046875\n",
      "Epoch: 7900, Loss: 2.1926766864961804, Accuracy: 0.423828125\n",
      "Epoch: 8000, Loss: 2.0825518884609777, Accuracy: 0.455078125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 8000, Momentum: False\n",
      "Val Loss: 2.1861757587209563, Val Accuracy: 0.43033333333333335\n",
      "-----------\n",
      "Epoch: 8100, Loss: 2.272103998888868, Accuracy: 0.400390625\n",
      "Epoch: 8200, Loss: 2.0769153245084166, Accuracy: 0.4169921875\n",
      "Epoch: 8300, Loss: 2.1811982011891606, Accuracy: 0.4384765625\n",
      "Epoch: 8400, Loss: 2.091739020471456, Accuracy: 0.455078125\n",
      "Epoch: 8500, Loss: 2.0880388768242204, Accuracy: 0.4453125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 8500, Momentum: False\n",
      "Val Loss: 2.164717854270533, Val Accuracy: 0.43546666666666667\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.1651439619316997, Accuracy: 0.4189453125\n",
      "Epoch: 8700, Loss: 2.133992149952612, Accuracy: 0.439453125\n",
      "Epoch: 8800, Loss: 2.1017832177637006, Accuracy: 0.447265625\n",
      "Epoch: 8900, Loss: 2.1171046021561906, Accuracy: 0.453125\n",
      "Epoch: 9000, Loss: 2.05628371312418, Accuracy: 0.4521484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 9000, Momentum: False\n",
      "Val Loss: 2.1431338748794655, Val Accuracy: 0.44076666666666664\n",
      "-----------\n",
      "Epoch: 9100, Loss: 2.0374112614085584, Accuracy: 0.4560546875\n",
      "Epoch: 9200, Loss: 2.011693398146959, Accuracy: 0.4619140625\n",
      "Epoch: 9300, Loss: 2.0774687394490363, Accuracy: 0.4541015625\n",
      "Epoch: 9400, Loss: 2.104461870196406, Accuracy: 0.453125\n",
      "Epoch: 9500, Loss: 2.0740892106220814, Accuracy: 0.4560546875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 9500, Momentum: False\n",
      "Val Loss: 2.133197618157906, Val Accuracy: 0.4389\n",
      "-----------\n",
      "Epoch: 9600, Loss: 2.029562589390588, Accuracy: 0.47265625\n",
      "Epoch: 9700, Loss: 2.0225151212316703, Accuracy: 0.4677734375\n",
      "Epoch: 9800, Loss: 2.041227703136218, Accuracy: 0.451171875\n",
      "Epoch: 9900, Loss: 2.0566537696120193, Accuracy: 0.4501953125\n",
      "Epoch: 10000, Loss: 2.0201473408581716, Accuracy: 0.4658203125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 10000, Momentum: False\n",
      "Val Loss: 2.1131622999879993, Val Accuracy: 0.4456333333333333\n",
      "-----------\n",
      "Epoch: 10100, Loss: 2.1203983394660293, Accuracy: 0.4560546875\n",
      "Epoch: 10200, Loss: 2.0720075466614607, Accuracy: 0.4609375\n",
      "Epoch: 10300, Loss: 2.048729370643252, Accuracy: 0.4599609375\n",
      "Epoch: 10400, Loss: 2.036349646930637, Accuracy: 0.4638671875\n",
      "Epoch: 10500, Loss: 2.055337002838904, Accuracy: 0.451171875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 10500, Momentum: False\n",
      "Val Loss: 2.096094374264927, Val Accuracy: 0.4494\n",
      "-----------\n",
      "Epoch: 10600, Loss: 2.0602104573314755, Accuracy: 0.4482421875\n",
      "Epoch: 10700, Loss: 1.9486253546625694, Accuracy: 0.4755859375\n",
      "Epoch: 10800, Loss: 2.043861495455744, Accuracy: 0.4453125\n",
      "Epoch: 10900, Loss: 2.0570587058584415, Accuracy: 0.41796875\n",
      "Epoch: 11000, Loss: 2.0262086503945884, Accuracy: 0.4501953125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 11000, Momentum: False\n",
      "Val Loss: 2.0771073584223756, Val Accuracy: 0.4536\n",
      "-----------\n",
      "Epoch: 11100, Loss: 2.0252704389243874, Accuracy: 0.458984375\n",
      "Epoch: 11200, Loss: 2.0047191178816846, Accuracy: 0.447265625\n",
      "Epoch: 11300, Loss: 2.087035797883356, Accuracy: 0.455078125\n",
      "Epoch: 11400, Loss: 1.9648914537944795, Accuracy: 0.4697265625\n",
      "Epoch: 11500, Loss: 2.035184773103415, Accuracy: 0.4521484375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 11500, Momentum: False\n",
      "Val Loss: 2.066235588319607, Val Accuracy: 0.45613333333333334\n",
      "-----------\n",
      "Epoch: 11600, Loss: 1.9898965380798432, Accuracy: 0.4599609375\n",
      "Epoch: 11700, Loss: 2.0820156107479777, Accuracy: 0.455078125\n",
      "Epoch: 11800, Loss: 1.9221082580746647, Accuracy: 0.48046875\n",
      "Epoch: 11900, Loss: 2.08208553084608, Accuracy: 0.451171875\n",
      "Epoch: 12000, Loss: 1.942218201676353, Accuracy: 0.5126953125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 12000, Momentum: False\n",
      "Val Loss: 2.052651402746047, Val Accuracy: 0.45943333333333336\n",
      "-----------\n",
      "Epoch: 12100, Loss: 1.956610807309806, Accuracy: 0.4794921875\n",
      "Epoch: 12200, Loss: 1.950607248922875, Accuracy: 0.4912109375\n",
      "Epoch: 12300, Loss: 1.9616786218791056, Accuracy: 0.4677734375\n",
      "Epoch: 12400, Loss: 1.9219601099748036, Accuracy: 0.4560546875\n",
      "Epoch: 12500, Loss: 1.934185523994345, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 12500, Momentum: False\n",
      "Val Loss: 2.046048408033185, Val Accuracy: 0.46073333333333333\n",
      "-----------\n",
      "Epoch: 12600, Loss: 1.8094101009659638, Accuracy: 0.509765625\n",
      "Epoch: 12700, Loss: 1.8906634565565963, Accuracy: 0.505859375\n",
      "Epoch: 12800, Loss: 1.9727076618581758, Accuracy: 0.4970703125\n",
      "Epoch: 12900, Loss: 1.9361063343302363, Accuracy: 0.4931640625\n",
      "Epoch: 13000, Loss: 1.915375084635297, Accuracy: 0.48828125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 13000, Momentum: False\n",
      "Val Loss: 2.0517028580053505, Val Accuracy: 0.4586\n",
      "-----------\n",
      "Epoch: 13100, Loss: 2.052575672696559, Accuracy: 0.44140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13200, Loss: 1.9830835206536128, Accuracy: 0.46875\n",
      "Epoch: 13300, Loss: 1.9512700576253397, Accuracy: 0.4853515625\n",
      "Epoch: 13400, Loss: 1.9496248871483577, Accuracy: 0.4814453125\n",
      "Epoch: 13500, Loss: 1.886761836053736, Accuracy: 0.48828125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 13500, Momentum: False\n",
      "Val Loss: 2.0298199244789257, Val Accuracy: 0.46386666666666665\n",
      "-----------\n",
      "Epoch: 13600, Loss: 1.9531538005549818, Accuracy: 0.490234375\n",
      "Epoch: 13700, Loss: 1.9700942502450207, Accuracy: 0.47265625\n",
      "Epoch: 13800, Loss: 1.9944495079522289, Accuracy: 0.4560546875\n",
      "Epoch: 13900, Loss: 1.9352084815830801, Accuracy: 0.4912109375\n",
      "Epoch: 14000, Loss: 1.8678096103427448, Accuracy: 0.5078125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 14000, Momentum: False\n",
      "Val Loss: 2.007154153038544, Val Accuracy: 0.47\n",
      "-----------\n",
      "Epoch: 14100, Loss: 1.9201026051837558, Accuracy: 0.4794921875\n",
      "Epoch: 14200, Loss: 1.8622292943482108, Accuracy: 0.5048828125\n",
      "Epoch: 14300, Loss: 1.9419845054286824, Accuracy: 0.4892578125\n",
      "Epoch: 14400, Loss: 1.9159070451755182, Accuracy: 0.4814453125\n",
      "Epoch: 14500, Loss: 1.9309994707369706, Accuracy: 0.474609375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 14500, Momentum: False\n",
      "Val Loss: 2.0056651697364405, Val Accuracy: 0.4679333333333333\n",
      "-----------\n",
      "Epoch: 14600, Loss: 1.8433824218590715, Accuracy: 0.501953125\n",
      "Epoch: 14700, Loss: 1.931508634344331, Accuracy: 0.4873046875\n",
      "Epoch: 14800, Loss: 1.8635823276880457, Accuracy: 0.4853515625\n",
      "Epoch: 14900, Loss: 1.9188751825430277, Accuracy: 0.4794921875\n",
      "Epoch: 15000, Loss: 2.0007993601620297, Accuracy: 0.4775390625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 15000, Momentum: False\n",
      "Val Loss: 2.0067078775505953, Val Accuracy: 0.4673333333333333\n",
      "-----------\n",
      "Epoch: 15100, Loss: 1.8813559943711038, Accuracy: 0.498046875\n",
      "Epoch: 15200, Loss: 1.8769258172790306, Accuracy: 0.5009765625\n",
      "Epoch: 15300, Loss: 1.9278741615258306, Accuracy: 0.4853515625\n",
      "Epoch: 15400, Loss: 1.9709367319848123, Accuracy: 0.4677734375\n",
      "Epoch: 15500, Loss: 1.914486454167411, Accuracy: 0.494140625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 15500, Momentum: False\n",
      "Val Loss: 1.9894277773842701, Val Accuracy: 0.47126666666666667\n",
      "-----------\n",
      "Epoch: 15600, Loss: 1.8737781261474706, Accuracy: 0.484375\n",
      "Epoch: 15700, Loss: 1.9052660459893431, Accuracy: 0.4892578125\n",
      "Epoch: 15800, Loss: 1.943800448750447, Accuracy: 0.4736328125\n",
      "Epoch: 15900, Loss: 1.9805380361179912, Accuracy: 0.4736328125\n",
      "Epoch: 16000, Loss: 1.8598518385777831, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 16000, Momentum: False\n",
      "Val Loss: 1.9880156929622361, Val Accuracy: 0.47153333333333336\n",
      "-----------\n",
      "Epoch: 16100, Loss: 1.9239618295450431, Accuracy: 0.4794921875\n",
      "Epoch: 16200, Loss: 1.9744885090614006, Accuracy: 0.4755859375\n",
      "Epoch: 16300, Loss: 1.8311678803843792, Accuracy: 0.513671875\n",
      "Epoch: 16400, Loss: 1.9236702508096923, Accuracy: 0.4892578125\n",
      "Epoch: 16500, Loss: 1.9634242548835559, Accuracy: 0.45703125\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 16500, Momentum: False\n",
      "Val Loss: 1.9645176272467857, Val Accuracy: 0.4775\n",
      "-----------\n",
      "Epoch: 16600, Loss: 1.842853030367822, Accuracy: 0.50390625\n",
      "Epoch: 16700, Loss: 1.8715069759546312, Accuracy: 0.498046875\n",
      "Epoch: 16800, Loss: 1.8491029620861077, Accuracy: 0.5068359375\n",
      "Epoch: 16900, Loss: 1.9088633915144038, Accuracy: 0.4775390625\n",
      "Epoch: 17000, Loss: 1.874983814710182, Accuracy: 0.4833984375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 17000, Momentum: False\n",
      "Val Loss: 1.9586861654009557, Val Accuracy: 0.47933333333333333\n",
      "-----------\n",
      "Epoch: 17100, Loss: 1.8898079542966133, Accuracy: 0.5009765625\n",
      "Epoch: 17200, Loss: 1.941295086306182, Accuracy: 0.4775390625\n",
      "Epoch: 17300, Loss: 1.8022733391335874, Accuracy: 0.5107421875\n",
      "Epoch: 17400, Loss: 1.7927591233935556, Accuracy: 0.50390625\n",
      "Epoch: 17500, Loss: 1.7636621688604373, Accuracy: 0.5302734375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 17500, Momentum: False\n",
      "Val Loss: 1.954117292225856, Val Accuracy: 0.47936666666666666\n",
      "-----------\n",
      "Epoch: 17600, Loss: 1.9262805673507428, Accuracy: 0.474609375\n",
      "Epoch: 17700, Loss: 1.859525750092188, Accuracy: 0.5166015625\n",
      "Epoch: 17800, Loss: 1.8348904341795003, Accuracy: 0.50390625\n",
      "Epoch: 17900, Loss: 1.8611430318862032, Accuracy: 0.505859375\n",
      "Epoch: 18000, Loss: 1.901547816273283, Accuracy: 0.4990234375\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 18000, Momentum: False\n",
      "Val Loss: 1.9503055816948212, Val Accuracy: 0.4806666666666667\n",
      "-----------\n",
      "Epoch: 18100, Loss: 1.8826146595646653, Accuracy: 0.4873046875\n",
      "Epoch: 18200, Loss: 1.8612547788152285, Accuracy: 0.4873046875\n",
      "Epoch: 18300, Loss: 1.8483167209211602, Accuracy: 0.494140625\n",
      "Epoch: 18400, Loss: 1.7967745795441405, Accuracy: 0.5029296875\n",
      "Epoch: 18500, Loss: 1.8872677009453582, Accuracy: 0.5009765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 18500, Momentum: False\n",
      "Val Loss: 1.9375769877106364, Val Accuracy: 0.48136666666666666\n",
      "-----------\n",
      "Epoch: 18600, Loss: 1.8482934592328906, Accuracy: 0.4990234375\n",
      "Epoch: 18700, Loss: 1.8162360649894893, Accuracy: 0.486328125\n",
      "Epoch: 18800, Loss: 1.8508093834303658, Accuracy: 0.486328125\n",
      "Epoch: 18900, Loss: 1.8024906510302379, Accuracy: 0.5078125\n",
      "Epoch: 19000, Loss: 1.8122680468880916, Accuracy: 0.509765625\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 19000, Momentum: False\n",
      "Val Loss: 1.9422279502422912, Val Accuracy: 0.4810333333333333\n",
      "-----------\n",
      "Epoch: 19100, Loss: 1.9076890985254789, Accuracy: 0.4951171875\n",
      "Epoch: 19200, Loss: 1.7978695727270337, Accuracy: 0.521484375\n",
      "Epoch: 19300, Loss: 1.8608873117998876, Accuracy: 0.4931640625\n",
      "Epoch: 19400, Loss: 1.8344262122337236, Accuracy: 0.498046875\n",
      "Epoch: 19500, Loss: 1.8585554695032793, Accuracy: 0.498046875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 19500, Momentum: False\n",
      "Val Loss: 1.935141122450864, Val Accuracy: 0.4825333333333333\n",
      "-----------\n",
      "Epoch: 19600, Loss: 1.8394261029032475, Accuracy: 0.5126953125\n",
      "Epoch: 19700, Loss: 1.9178084707439398, Accuracy: 0.5\n",
      "Epoch: 19800, Loss: 1.7427128801671912, Accuracy: 0.5107421875\n",
      "Epoch: 19900, Loss: 1.8551179892234408, Accuracy: 0.5029296875\n",
      "-----------\n",
      "Learning Rate: 0.05, Reg: 1e-05, Num Epoch: 19500, Momentum: False\n",
      "Test Loss: 1.9480853391058561, Test Accuracy: 0.4813216306397795\n",
      "-----------\n",
      "Epoch: 0, Loss: 15.806482400095863, Accuracy: 0.0126953125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 0, Momentum: True\n",
      "Val Loss: 12.188359653320315, Val Accuracy: 0.038566666666666666\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.651249700957125, Accuracy: 0.052734375\n",
      "Epoch: 200, Loss: 4.596189901743335, Accuracy: 0.052734375\n",
      "Epoch: 300, Loss: 4.434044517418103, Accuracy: 0.0703125\n",
      "Epoch: 400, Loss: 4.401425522682677, Accuracy: 0.0732421875\n",
      "Epoch: 500, Loss: 4.220002116560678, Accuracy: 0.076171875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 500, Momentum: True\n",
      "Val Loss: 4.243884215861662, Val Accuracy: 0.0803\n",
      "-----------\n",
      "Epoch: 600, Loss: 4.107166672745116, Accuracy: 0.0947265625\n",
      "Epoch: 700, Loss: 4.048722571299698, Accuracy: 0.091796875\n",
      "Epoch: 800, Loss: 3.9604867178415755, Accuracy: 0.1064453125\n",
      "Epoch: 900, Loss: 3.936154774367206, Accuracy: 0.1181640625\n",
      "Epoch: 1000, Loss: 3.945388167238319, Accuracy: 0.1025390625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 1000, Momentum: True\n",
      "Val Loss: 3.88545688085898, Val Accuracy: 0.11656666666666667\n",
      "-----------\n",
      "Epoch: 1100, Loss: 3.680482910547009, Accuracy: 0.138671875\n",
      "Epoch: 1200, Loss: 3.6896044352334574, Accuracy: 0.140625\n",
      "Epoch: 1300, Loss: 3.6602986638909742, Accuracy: 0.158203125\n",
      "Epoch: 1400, Loss: 3.687473515883035, Accuracy: 0.1240234375\n",
      "Epoch: 1500, Loss: 3.5703145750349394, Accuracy: 0.173828125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 1500, Momentum: True\n",
      "Val Loss: 3.6227579362792497, Val Accuracy: 0.14913333333333334\n",
      "-----------\n",
      "Epoch: 1600, Loss: 3.5994000853411894, Accuracy: 0.15625\n",
      "Epoch: 1700, Loss: 3.484711019578699, Accuracy: 0.14453125\n",
      "Epoch: 1800, Loss: 3.533987395665588, Accuracy: 0.1494140625\n",
      "Epoch: 1900, Loss: 3.387511304480391, Accuracy: 0.1884765625\n",
      "Epoch: 2000, Loss: 3.450319546180626, Accuracy: 0.18359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 2000, Momentum: True\n",
      "Val Loss: 3.4210859927593793, Val Accuracy: 0.17556666666666668\n",
      "-----------\n",
      "Epoch: 2100, Loss: 3.3568971688587865, Accuracy: 0.1767578125\n",
      "Epoch: 2200, Loss: 3.2712612950586304, Accuracy: 0.1865234375\n",
      "Epoch: 2300, Loss: 3.2247843641581833, Accuracy: 0.19921875\n",
      "Epoch: 2400, Loss: 3.3021668731701688, Accuracy: 0.18359375\n",
      "Epoch: 2500, Loss: 3.2665079449659027, Accuracy: 0.1982421875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 2500, Momentum: True\n",
      "Val Loss: 3.2602841736303163, Val Accuracy: 0.19916666666666666\n",
      "-----------\n",
      "Epoch: 2600, Loss: 3.178235286006882, Accuracy: 0.2060546875\n",
      "Epoch: 2700, Loss: 3.157471171603772, Accuracy: 0.2138671875\n",
      "Epoch: 2800, Loss: 3.222852710203668, Accuracy: 0.1962890625\n",
      "Epoch: 2900, Loss: 3.082900363924221, Accuracy: 0.2392578125\n",
      "Epoch: 3000, Loss: 3.0995097164969394, Accuracy: 0.2060546875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 3000, Momentum: True\n",
      "Val Loss: 3.128170172817307, Val Accuracy: 0.22153333333333333\n",
      "-----------\n",
      "Epoch: 3100, Loss: 3.064673843497452, Accuracy: 0.2109375\n",
      "Epoch: 3200, Loss: 3.064220995060991, Accuracy: 0.220703125\n",
      "Epoch: 3300, Loss: 2.941595996098754, Accuracy: 0.2548828125\n",
      "Epoch: 3400, Loss: 3.0596012856949164, Accuracy: 0.2626953125\n",
      "Epoch: 3500, Loss: 3.033139196605279, Accuracy: 0.2412109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 3500, Momentum: True\n",
      "Val Loss: 3.017768049447359, Val Accuracy: 0.2441\n",
      "-----------\n",
      "Epoch: 3600, Loss: 3.0910005071187285, Accuracy: 0.2177734375\n",
      "Epoch: 3700, Loss: 2.978759668444723, Accuracy: 0.2421875\n",
      "Epoch: 3800, Loss: 2.9349718735134664, Accuracy: 0.25\n",
      "Epoch: 3900, Loss: 2.912741412189928, Accuracy: 0.2685546875\n",
      "Epoch: 4000, Loss: 2.8186972377199155, Accuracy: 0.2744140625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 4000, Momentum: True\n",
      "Val Loss: 2.925505126989626, Val Accuracy: 0.25876666666666664\n",
      "-----------\n",
      "Epoch: 4100, Loss: 2.920918260074338, Accuracy: 0.271484375\n",
      "Epoch: 4200, Loss: 2.8815009729641297, Accuracy: 0.26171875\n",
      "Epoch: 4300, Loss: 2.808712234577655, Accuracy: 0.2724609375\n",
      "Epoch: 4400, Loss: 2.879574107559706, Accuracy: 0.25\n",
      "Epoch: 4500, Loss: 2.819220021249715, Accuracy: 0.287109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 4500, Momentum: True\n",
      "Val Loss: 2.847195346659539, Val Accuracy: 0.2727\n",
      "-----------\n",
      "Epoch: 4600, Loss: 2.90163155216843, Accuracy: 0.2783203125\n",
      "Epoch: 4700, Loss: 2.8440961598512087, Accuracy: 0.2724609375\n",
      "Epoch: 4800, Loss: 2.7364190826374815, Accuracy: 0.3125\n",
      "Epoch: 4900, Loss: 2.9048546866792333, Accuracy: 0.263671875\n",
      "Epoch: 5000, Loss: 2.7898137678794312, Accuracy: 0.2890625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 5000, Momentum: True\n",
      "Val Loss: 2.7787746954019883, Val Accuracy: 0.28823333333333334\n",
      "-----------\n",
      "Epoch: 5100, Loss: 2.831468643842055, Accuracy: 0.2880859375\n",
      "Epoch: 5200, Loss: 2.71000643873314, Accuracy: 0.3017578125\n",
      "Epoch: 5300, Loss: 2.7759038928988673, Accuracy: 0.2841796875\n",
      "Epoch: 5400, Loss: 2.782746430088287, Accuracy: 0.2978515625\n",
      "Epoch: 5500, Loss: 2.7760844975710075, Accuracy: 0.2783203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 5500, Momentum: True\n",
      "Val Loss: 2.719153973953603, Val Accuracy: 0.29996666666666666\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.731883746812925, Accuracy: 0.30078125\n",
      "Epoch: 5700, Loss: 2.5767770428533066, Accuracy: 0.3173828125\n",
      "Epoch: 5800, Loss: 2.6751519221572173, Accuracy: 0.3193359375\n",
      "Epoch: 5900, Loss: 2.6794135415678757, Accuracy: 0.328125\n",
      "Epoch: 6000, Loss: 2.726375664175411, Accuracy: 0.30078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 6000, Momentum: True\n",
      "Val Loss: 2.6654134079026184, Val Accuracy: 0.3144\n",
      "-----------\n",
      "Epoch: 6100, Loss: 2.6906176709545746, Accuracy: 0.3037109375\n",
      "Epoch: 6200, Loss: 2.6446023736116904, Accuracy: 0.3212890625\n",
      "Epoch: 6300, Loss: 2.7246909853083023, Accuracy: 0.296875\n",
      "Epoch: 6400, Loss: 2.6572317568438484, Accuracy: 0.306640625\n",
      "Epoch: 6500, Loss: 2.5502619168484806, Accuracy: 0.33984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 6500, Momentum: True\n",
      "Val Loss: 2.6176459025276926, Val Accuracy: 0.32313333333333333\n",
      "-----------\n",
      "Epoch: 6600, Loss: 2.647108272305842, Accuracy: 0.3056640625\n",
      "Epoch: 6700, Loss: 2.5545197314254784, Accuracy: 0.3310546875\n",
      "Epoch: 6800, Loss: 2.6406197129110787, Accuracy: 0.3095703125\n",
      "Epoch: 6900, Loss: 2.6563339021480097, Accuracy: 0.302734375\n",
      "Epoch: 7000, Loss: 2.6582041872865974, Accuracy: 0.310546875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 7000, Momentum: True\n",
      "Val Loss: 2.5754330025166, Val Accuracy: 0.33316666666666667\n",
      "-----------\n",
      "Epoch: 7100, Loss: 2.537133027711172, Accuracy: 0.345703125\n",
      "Epoch: 7200, Loss: 2.4869947002854293, Accuracy: 0.34375\n",
      "Epoch: 7300, Loss: 2.539234487847727, Accuracy: 0.333984375\n",
      "Epoch: 7400, Loss: 2.515095412724209, Accuracy: 0.337890625\n",
      "Epoch: 7500, Loss: 2.523588356341262, Accuracy: 0.341796875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 7500, Momentum: True\n",
      "Val Loss: 2.5373226921589773, Val Accuracy: 0.3444333333333333\n",
      "-----------\n",
      "Epoch: 7600, Loss: 2.4983480461333025, Accuracy: 0.3583984375\n",
      "Epoch: 7700, Loss: 2.4013016916371472, Accuracy: 0.3837890625\n",
      "Epoch: 7800, Loss: 2.396124216021511, Accuracy: 0.36328125\n",
      "Epoch: 7900, Loss: 2.483455159814009, Accuracy: 0.3544921875\n",
      "Epoch: 8000, Loss: 2.429959057593932, Accuracy: 0.373046875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 8000, Momentum: True\n",
      "Val Loss: 2.5054888065169516, Val Accuracy: 0.35073333333333334\n",
      "-----------\n",
      "Epoch: 8100, Loss: 2.395587220901672, Accuracy: 0.3779296875\n",
      "Epoch: 8200, Loss: 2.548972029272175, Accuracy: 0.34375\n",
      "Epoch: 8300, Loss: 2.4311378031686552, Accuracy: 0.3603515625\n",
      "Epoch: 8400, Loss: 2.544872284898827, Accuracy: 0.359375\n",
      "Epoch: 8500, Loss: 2.4510115917593662, Accuracy: 0.3525390625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 8500, Momentum: True\n",
      "Val Loss: 2.4720550031968864, Val Accuracy: 0.3606333333333333\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.4444929493598417, Accuracy: 0.375\n",
      "Epoch: 8700, Loss: 2.4100902364241765, Accuracy: 0.3662109375\n",
      "Epoch: 8800, Loss: 2.478107631024405, Accuracy: 0.35546875\n",
      "Epoch: 8900, Loss: 2.4936831755059403, Accuracy: 0.353515625\n",
      "Epoch: 9000, Loss: 2.3876414738729514, Accuracy: 0.3603515625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 9000, Momentum: True\n",
      "Val Loss: 2.4450501370747872, Val Accuracy: 0.36666666666666664\n",
      "-----------\n",
      "Epoch: 9100, Loss: 2.422746980719375, Accuracy: 0.361328125\n",
      "Epoch: 9200, Loss: 2.322897950834774, Accuracy: 0.38671875\n",
      "Epoch: 9300, Loss: 2.3701861373217454, Accuracy: 0.3818359375\n",
      "Epoch: 9400, Loss: 2.450800156473802, Accuracy: 0.3642578125\n",
      "Epoch: 9500, Loss: 2.446103429879253, Accuracy: 0.3720703125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 9500, Momentum: True\n",
      "Val Loss: 2.419034738258265, Val Accuracy: 0.37083333333333335\n",
      "-----------\n",
      "Epoch: 9600, Loss: 2.362528863683228, Accuracy: 0.37890625\n",
      "Epoch: 9700, Loss: 2.3823555280565807, Accuracy: 0.3701171875\n",
      "Epoch: 9800, Loss: 2.39387296729192, Accuracy: 0.35546875\n",
      "Epoch: 9900, Loss: 2.4390626516257257, Accuracy: 0.357421875\n",
      "Epoch: 10000, Loss: 2.3281868429179404, Accuracy: 0.396484375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 10000, Momentum: True\n",
      "Val Loss: 2.395368831566222, Val Accuracy: 0.37776666666666664\n",
      "-----------\n",
      "Epoch: 10100, Loss: 2.4196540235859705, Accuracy: 0.392578125\n",
      "Epoch: 10200, Loss: 2.3653931344088277, Accuracy: 0.3720703125\n",
      "Epoch: 10300, Loss: 2.3478551461014012, Accuracy: 0.40234375\n",
      "Epoch: 10400, Loss: 2.3436347104156035, Accuracy: 0.3837890625\n",
      "Epoch: 10500, Loss: 2.4069955604779345, Accuracy: 0.361328125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 10500, Momentum: True\n",
      "Val Loss: 2.373941185647415, Val Accuracy: 0.3838\n",
      "-----------\n",
      "Epoch: 10600, Loss: 2.3960597221235003, Accuracy: 0.3857421875\n",
      "Epoch: 10700, Loss: 2.2782964824901297, Accuracy: 0.4052734375\n",
      "Epoch: 10800, Loss: 2.3084545912792, Accuracy: 0.3955078125\n",
      "Epoch: 10900, Loss: 2.234518895173564, Accuracy: 0.41796875\n",
      "Epoch: 11000, Loss: 2.2655125716983227, Accuracy: 0.3955078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 11000, Momentum: True\n",
      "Val Loss: 2.353711712803755, Val Accuracy: 0.3873333333333333\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11100, Loss: 2.331870103288311, Accuracy: 0.384765625\n",
      "Epoch: 11200, Loss: 2.2657432567215086, Accuracy: 0.4130859375\n",
      "Epoch: 11300, Loss: 2.386382791747219, Accuracy: 0.3671875\n",
      "Epoch: 11400, Loss: 2.23736940100906, Accuracy: 0.4052734375\n",
      "Epoch: 11500, Loss: 2.3052323389324183, Accuracy: 0.4169921875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 11500, Momentum: True\n",
      "Val Loss: 2.3362818531015224, Val Accuracy: 0.3930666666666667\n",
      "-----------\n",
      "Epoch: 11600, Loss: 2.3392353328025854, Accuracy: 0.3798828125\n",
      "Epoch: 11700, Loss: 2.3555743314612414, Accuracy: 0.3759765625\n",
      "Epoch: 11800, Loss: 2.257440595264078, Accuracy: 0.3994140625\n",
      "Epoch: 11900, Loss: 2.262129504110932, Accuracy: 0.4033203125\n",
      "Epoch: 12000, Loss: 2.255028534474424, Accuracy: 0.416015625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 12000, Momentum: True\n",
      "Val Loss: 2.318887294155098, Val Accuracy: 0.39666666666666667\n",
      "-----------\n",
      "Epoch: 12100, Loss: 2.3506828464852902, Accuracy: 0.3759765625\n",
      "Epoch: 12200, Loss: 2.237856499146856, Accuracy: 0.3994140625\n",
      "Epoch: 12300, Loss: 2.3057631915924968, Accuracy: 0.40234375\n",
      "Epoch: 12400, Loss: 2.2873838243369953, Accuracy: 0.4091796875\n",
      "Epoch: 12500, Loss: 2.300288589304133, Accuracy: 0.384765625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 12500, Momentum: True\n",
      "Val Loss: 2.3026657594137854, Val Accuracy: 0.4023\n",
      "-----------\n",
      "Epoch: 12600, Loss: 2.1979950495681058, Accuracy: 0.421875\n",
      "Epoch: 12700, Loss: 2.3066039286553286, Accuracy: 0.404296875\n",
      "Epoch: 12800, Loss: 2.227169419202598, Accuracy: 0.4140625\n",
      "Epoch: 12900, Loss: 2.221587522000634, Accuracy: 0.42578125\n",
      "Epoch: 13000, Loss: 2.2474095150153985, Accuracy: 0.4033203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 13000, Momentum: True\n",
      "Val Loss: 2.289064137910019, Val Accuracy: 0.40476666666666666\n",
      "-----------\n",
      "Epoch: 13100, Loss: 2.267179669225662, Accuracy: 0.4072265625\n",
      "Epoch: 13200, Loss: 2.3592389165078393, Accuracy: 0.384765625\n",
      "Epoch: 13300, Loss: 2.287763427757336, Accuracy: 0.412109375\n",
      "Epoch: 13400, Loss: 2.23053943009727, Accuracy: 0.4130859375\n",
      "Epoch: 13500, Loss: 2.279152967446559, Accuracy: 0.4208984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 13500, Momentum: True\n",
      "Val Loss: 2.274268524022067, Val Accuracy: 0.4096666666666667\n",
      "-----------\n",
      "Epoch: 13600, Loss: 2.23815375161161, Accuracy: 0.41796875\n",
      "Epoch: 13700, Loss: 2.2578159985971995, Accuracy: 0.4072265625\n",
      "Epoch: 13800, Loss: 2.1691719958217996, Accuracy: 0.4365234375\n",
      "Epoch: 13900, Loss: 2.157899493713022, Accuracy: 0.4482421875\n",
      "Epoch: 14000, Loss: 2.1908845578368554, Accuracy: 0.4345703125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 14000, Momentum: True\n",
      "Val Loss: 2.2618073210252225, Val Accuracy: 0.4121666666666667\n",
      "-----------\n",
      "Epoch: 14100, Loss: 2.2014404697899583, Accuracy: 0.42578125\n",
      "Epoch: 14200, Loss: 2.2809355516925542, Accuracy: 0.412109375\n",
      "Epoch: 14300, Loss: 2.258557763214082, Accuracy: 0.404296875\n",
      "Epoch: 14400, Loss: 2.2958282373195495, Accuracy: 0.421875\n",
      "Epoch: 14500, Loss: 2.162323148473554, Accuracy: 0.4423828125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 14500, Momentum: True\n",
      "Val Loss: 2.2507994849335633, Val Accuracy: 0.4147666666666667\n",
      "-----------\n",
      "Epoch: 14600, Loss: 2.278741953695132, Accuracy: 0.3974609375\n",
      "Epoch: 14700, Loss: 2.16791163266428, Accuracy: 0.443359375\n",
      "Epoch: 14800, Loss: 2.2469172107034083, Accuracy: 0.419921875\n",
      "Epoch: 14900, Loss: 2.1968529572842783, Accuracy: 0.42578125\n",
      "Epoch: 15000, Loss: 2.1395399314612753, Accuracy: 0.4423828125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 15000, Momentum: True\n",
      "Val Loss: 2.2380080778214846, Val Accuracy: 0.4194333333333333\n",
      "-----------\n",
      "Epoch: 15100, Loss: 2.2247135515625156, Accuracy: 0.42578125\n",
      "Epoch: 15200, Loss: 2.2531763847236377, Accuracy: 0.416015625\n",
      "Epoch: 15300, Loss: 2.185870339330066, Accuracy: 0.4267578125\n",
      "Epoch: 15400, Loss: 2.2503262688801513, Accuracy: 0.4111328125\n",
      "Epoch: 15500, Loss: 2.1618418762442246, Accuracy: 0.4326171875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 15500, Momentum: True\n",
      "Val Loss: 2.227536414757134, Val Accuracy: 0.4227\n",
      "-----------\n",
      "Epoch: 15600, Loss: 2.2176545422440643, Accuracy: 0.4189453125\n",
      "Epoch: 15700, Loss: 2.15439201159979, Accuracy: 0.4599609375\n",
      "Epoch: 15800, Loss: 2.247035495947606, Accuracy: 0.41796875\n",
      "Epoch: 15900, Loss: 2.3042414056000737, Accuracy: 0.3896484375\n",
      "Epoch: 16000, Loss: 2.1816570596584683, Accuracy: 0.4326171875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 16000, Momentum: True\n",
      "Val Loss: 2.2187441809729136, Val Accuracy: 0.4250333333333333\n",
      "-----------\n",
      "Epoch: 16100, Loss: 2.2005985541268323, Accuracy: 0.4228515625\n",
      "Epoch: 16200, Loss: 2.182482654680247, Accuracy: 0.4453125\n",
      "Epoch: 16300, Loss: 2.1564364820181603, Accuracy: 0.4580078125\n",
      "Epoch: 16400, Loss: 2.249229726505634, Accuracy: 0.4189453125\n",
      "Epoch: 16500, Loss: 2.1550317077516645, Accuracy: 0.43359375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 16500, Momentum: True\n",
      "Val Loss: 2.2096203333086195, Val Accuracy: 0.42683333333333334\n",
      "-----------\n",
      "Epoch: 16600, Loss: 2.235433999516433, Accuracy: 0.4140625\n",
      "Epoch: 16700, Loss: 2.1701799410211535, Accuracy: 0.423828125\n",
      "Epoch: 16800, Loss: 2.2377173898305256, Accuracy: 0.404296875\n",
      "Epoch: 16900, Loss: 2.1674704567254928, Accuracy: 0.4365234375\n",
      "Epoch: 17000, Loss: 2.1331029057219544, Accuracy: 0.4482421875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 17000, Momentum: True\n",
      "Val Loss: 2.2008394826390103, Val Accuracy: 0.42846666666666666\n",
      "-----------\n",
      "Epoch: 17100, Loss: 2.198393032242401, Accuracy: 0.4208984375\n",
      "Epoch: 17200, Loss: 2.1546832979653807, Accuracy: 0.4521484375\n",
      "Epoch: 17300, Loss: 2.144152892981457, Accuracy: 0.4609375\n",
      "Epoch: 17400, Loss: 2.153583981086719, Accuracy: 0.4267578125\n",
      "Epoch: 17500, Loss: 2.1401485045070405, Accuracy: 0.4541015625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 17500, Momentum: True\n",
      "Val Loss: 2.192339217884041, Val Accuracy: 0.43146666666666667\n",
      "-----------\n",
      "Epoch: 17600, Loss: 2.182570112107941, Accuracy: 0.431640625\n",
      "Epoch: 17700, Loss: 2.213062074179032, Accuracy: 0.4130859375\n",
      "Epoch: 17800, Loss: 2.2555277641500338, Accuracy: 0.3876953125\n",
      "Epoch: 17900, Loss: 2.1853279778708616, Accuracy: 0.44140625\n",
      "Epoch: 18000, Loss: 2.213077707629595, Accuracy: 0.4296875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 18000, Momentum: True\n",
      "Val Loss: 2.1845358368180015, Val Accuracy: 0.43496666666666667\n",
      "-----------\n",
      "Epoch: 18100, Loss: 2.1260169284276174, Accuracy: 0.4482421875\n",
      "Epoch: 18200, Loss: 2.1353369155090247, Accuracy: 0.4345703125\n",
      "Epoch: 18300, Loss: 2.2113065282448843, Accuracy: 0.421875\n",
      "Epoch: 18400, Loss: 2.1721549469099255, Accuracy: 0.455078125\n",
      "Epoch: 18500, Loss: 2.125077727669624, Accuracy: 0.4404296875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 18500, Momentum: True\n",
      "Val Loss: 2.176416259029595, Val Accuracy: 0.4367333333333333\n",
      "-----------\n",
      "Epoch: 18600, Loss: 2.0713806726607262, Accuracy: 0.4521484375\n",
      "Epoch: 18700, Loss: 2.145426920695456, Accuracy: 0.443359375\n",
      "Epoch: 18800, Loss: 2.1696989688644206, Accuracy: 0.443359375\n",
      "Epoch: 18900, Loss: 2.1931804612682173, Accuracy: 0.4140625\n",
      "Epoch: 19000, Loss: 2.116383341003341, Accuracy: 0.4619140625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 19000, Momentum: True\n",
      "Val Loss: 2.1689503595395685, Val Accuracy: 0.4391333333333333\n",
      "-----------\n",
      "Epoch: 19100, Loss: 2.2441759237405354, Accuracy: 0.4140625\n",
      "Epoch: 19200, Loss: 2.1029978217572745, Accuracy: 0.453125\n",
      "Epoch: 19300, Loss: 2.1212367872895843, Accuracy: 0.458984375\n",
      "Epoch: 19400, Loss: 2.156947766724578, Accuracy: 0.4521484375\n",
      "Epoch: 19500, Loss: 2.142037782844709, Accuracy: 0.4365234375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 19500, Momentum: True\n",
      "Val Loss: 2.1627461676221365, Val Accuracy: 0.4407333333333333\n",
      "-----------\n",
      "Epoch: 19600, Loss: 2.1351560714490283, Accuracy: 0.458984375\n",
      "Epoch: 19700, Loss: 2.1562246827319593, Accuracy: 0.4521484375\n",
      "Epoch: 19800, Loss: 2.1526239268662613, Accuracy: 0.4345703125\n",
      "Epoch: 19900, Loss: 2.2265276724544862, Accuracy: 0.4169921875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 19500, Momentum: True\n",
      "Test Loss: 2.1844172789328486, Test Accuracy: 0.4342448861163499\n",
      "-----------\n",
      "Epoch: 0, Loss: 15.170803095023647, Accuracy: 0.0166015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 0, Momentum: False\n",
      "Val Loss: 13.976322071549712, Val Accuracy: 0.0309\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.775928209457421, Accuracy: 0.056640625\n",
      "Epoch: 200, Loss: 4.793221780040134, Accuracy: 0.060546875\n",
      "Epoch: 300, Loss: 4.660565111651379, Accuracy: 0.0556640625\n",
      "Epoch: 400, Loss: 4.603516506544952, Accuracy: 0.0556640625\n",
      "Epoch: 500, Loss: 4.484762981818598, Accuracy: 0.072265625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 500, Momentum: False\n",
      "Val Loss: 4.543597747480943, Val Accuracy: 0.06193333333333333\n",
      "-----------\n",
      "Epoch: 600, Loss: 4.429456060788013, Accuracy: 0.064453125\n",
      "Epoch: 700, Loss: 4.465335276568047, Accuracy: 0.0634765625\n",
      "Epoch: 800, Loss: 4.408227949001459, Accuracy: 0.0703125\n",
      "Epoch: 900, Loss: 4.32730802649721, Accuracy: 0.0693359375\n",
      "Epoch: 1000, Loss: 4.282490328936968, Accuracy: 0.0751953125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 1000, Momentum: False\n",
      "Val Loss: 4.299376142340069, Val Accuracy: 0.0761\n",
      "-----------\n",
      "Epoch: 1100, Loss: 4.241329295297491, Accuracy: 0.078125\n",
      "Epoch: 1200, Loss: 4.292077564744533, Accuracy: 0.0771484375\n",
      "Epoch: 1300, Loss: 4.161428029988623, Accuracy: 0.0869140625\n",
      "Epoch: 1400, Loss: 4.125288946048832, Accuracy: 0.0947265625\n",
      "Epoch: 1500, Loss: 4.144201684672568, Accuracy: 0.08984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 1500, Momentum: False\n",
      "Val Loss: 4.095558071149687, Val Accuracy: 0.09473333333333334\n",
      "-----------\n",
      "Epoch: 1600, Loss: 3.9723270535341597, Accuracy: 0.099609375\n",
      "Epoch: 1700, Loss: 4.02248329436275, Accuracy: 0.0986328125\n",
      "Epoch: 1800, Loss: 3.932612021064458, Accuracy: 0.12109375\n",
      "Epoch: 1900, Loss: 3.869380361678939, Accuracy: 0.09765625\n",
      "Epoch: 2000, Loss: 3.8261957104870277, Accuracy: 0.1083984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 2000, Momentum: False\n",
      "Val Loss: 3.9229883029605093, Val Accuracy: 0.1101\n",
      "-----------\n",
      "Epoch: 2100, Loss: 3.8850951701249605, Accuracy: 0.12109375\n",
      "Epoch: 2200, Loss: 3.889688345325479, Accuracy: 0.0927734375\n",
      "Epoch: 2300, Loss: 3.800902918233718, Accuracy: 0.107421875\n",
      "Epoch: 2400, Loss: 3.8621187013479004, Accuracy: 0.1083984375\n",
      "Epoch: 2500, Loss: 3.852971024883575, Accuracy: 0.12109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 2500, Momentum: False\n",
      "Val Loss: 3.776059065208093, Val Accuracy: 0.12876666666666667\n",
      "-----------\n",
      "Epoch: 2600, Loss: 3.7018883172980326, Accuracy: 0.1435546875\n",
      "Epoch: 2700, Loss: 3.6420981565061648, Accuracy: 0.1533203125\n",
      "Epoch: 2800, Loss: 3.657109233849945, Accuracy: 0.1435546875\n",
      "Epoch: 2900, Loss: 3.5693936136732454, Accuracy: 0.1435546875\n",
      "Epoch: 3000, Loss: 3.642111209674388, Accuracy: 0.138671875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 3000, Momentum: False\n",
      "Val Loss: 3.6487791752035856, Val Accuracy: 0.14426666666666665\n",
      "-----------\n",
      "Epoch: 3100, Loss: 3.6455834947186583, Accuracy: 0.1474609375\n",
      "Epoch: 3200, Loss: 3.5194704803567856, Accuracy: 0.1474609375\n",
      "Epoch: 3300, Loss: 3.5661988900118646, Accuracy: 0.1533203125\n",
      "Epoch: 3400, Loss: 3.4391490219393352, Accuracy: 0.16796875\n",
      "Epoch: 3500, Loss: 3.587076791496624, Accuracy: 0.1591796875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 3500, Momentum: False\n",
      "Val Loss: 3.537154317382002, Val Accuracy: 0.159\n",
      "-----------\n",
      "Epoch: 3600, Loss: 3.5092841778424284, Accuracy: 0.1572265625\n",
      "Epoch: 3700, Loss: 3.5702788043509504, Accuracy: 0.140625\n",
      "Epoch: 3800, Loss: 3.4922977767439116, Accuracy: 0.1650390625\n",
      "Epoch: 3900, Loss: 3.4443103215015505, Accuracy: 0.1748046875\n",
      "Epoch: 4000, Loss: 3.4302851066814486, Accuracy: 0.1611328125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 4000, Momentum: False\n",
      "Val Loss: 3.439711494183543, Val Accuracy: 0.17273333333333332\n",
      "-----------\n",
      "Epoch: 4100, Loss: 3.3589831566806367, Accuracy: 0.1796875\n",
      "Epoch: 4200, Loss: 3.391526237396778, Accuracy: 0.17578125\n",
      "Epoch: 4300, Loss: 3.350885280313917, Accuracy: 0.18359375\n",
      "Epoch: 4400, Loss: 3.3391844687113297, Accuracy: 0.1865234375\n",
      "Epoch: 4500, Loss: 3.3455588019030538, Accuracy: 0.203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 4500, Momentum: False\n",
      "Val Loss: 3.3545996064591717, Val Accuracy: 0.18566666666666667\n",
      "-----------\n",
      "Epoch: 4600, Loss: 3.287138945679791, Accuracy: 0.2001953125\n",
      "Epoch: 4700, Loss: 3.3102615569418825, Accuracy: 0.1845703125\n",
      "Epoch: 4800, Loss: 3.3027666044058774, Accuracy: 0.185546875\n",
      "Epoch: 4900, Loss: 3.4352259012514565, Accuracy: 0.1806640625\n",
      "Epoch: 5000, Loss: 3.332619786109979, Accuracy: 0.189453125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 5000, Momentum: False\n",
      "Val Loss: 3.275806826623816, Val Accuracy: 0.19723333333333334\n",
      "-----------\n",
      "Epoch: 5100, Loss: 3.2556182673955196, Accuracy: 0.2080078125\n",
      "Epoch: 5200, Loss: 3.217606750909373, Accuracy: 0.1962890625\n",
      "Epoch: 5300, Loss: 3.2107722234659732, Accuracy: 0.1953125\n",
      "Epoch: 5400, Loss: 3.16506001607513, Accuracy: 0.208984375\n",
      "Epoch: 5500, Loss: 3.1206093721252364, Accuracy: 0.2080078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 5500, Momentum: False\n",
      "Val Loss: 3.2052307959386273, Val Accuracy: 0.20876666666666666\n",
      "-----------\n",
      "Epoch: 5600, Loss: 3.172128092797654, Accuracy: 0.21484375\n",
      "Epoch: 5700, Loss: 3.064132463904346, Accuracy: 0.2294921875\n",
      "Epoch: 5800, Loss: 3.150143007804912, Accuracy: 0.20703125\n",
      "Epoch: 5900, Loss: 3.1891934349191495, Accuracy: 0.203125\n",
      "Epoch: 6000, Loss: 3.0626775852564876, Accuracy: 0.224609375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 6000, Momentum: False\n",
      "Val Loss: 3.142223147855374, Val Accuracy: 0.2198\n",
      "-----------\n",
      "Epoch: 6100, Loss: 3.1061770045804904, Accuracy: 0.2412109375\n",
      "Epoch: 6200, Loss: 3.212496562485463, Accuracy: 0.1953125\n",
      "Epoch: 6300, Loss: 3.05803139575461, Accuracy: 0.2490234375\n",
      "Epoch: 6400, Loss: 3.1181627588427743, Accuracy: 0.2177734375\n",
      "Epoch: 6500, Loss: 3.0713983869629695, Accuracy: 0.234375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 6500, Momentum: False\n",
      "Val Loss: 3.0847403998573144, Val Accuracy: 0.22906666666666667\n",
      "-----------\n",
      "Epoch: 6600, Loss: 2.959370290127174, Accuracy: 0.2578125\n",
      "Epoch: 6700, Loss: 2.936860101139458, Accuracy: 0.25\n",
      "Epoch: 6800, Loss: 3.0757689120718847, Accuracy: 0.2197265625\n",
      "Epoch: 6900, Loss: 3.0982237307437837, Accuracy: 0.2509765625\n",
      "Epoch: 7000, Loss: 3.0228346143487936, Accuracy: 0.2412109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 7000, Momentum: False\n",
      "Val Loss: 3.032880678133779, Val Accuracy: 0.23806666666666668\n",
      "-----------\n",
      "Epoch: 7100, Loss: 3.0098892551844036, Accuracy: 0.2490234375\n",
      "Epoch: 7200, Loss: 2.9483865755280236, Accuracy: 0.2587890625\n",
      "Epoch: 7300, Loss: 3.013979520537991, Accuracy: 0.2255859375\n",
      "Epoch: 7400, Loss: 2.9770306727076763, Accuracy: 0.251953125\n",
      "Epoch: 7500, Loss: 2.922381451045161, Accuracy: 0.255859375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 7500, Momentum: False\n",
      "Val Loss: 2.9829111627004994, Val Accuracy: 0.24776666666666666\n",
      "-----------\n",
      "Epoch: 7600, Loss: 2.896680854138121, Accuracy: 0.25\n",
      "Epoch: 7700, Loss: 2.872420438928968, Accuracy: 0.259765625\n",
      "Epoch: 7800, Loss: 2.9585415353926505, Accuracy: 0.2490234375\n",
      "Epoch: 7900, Loss: 2.9190102491885344, Accuracy: 0.2607421875\n",
      "Epoch: 8000, Loss: 3.0160758526528304, Accuracy: 0.23046875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 8000, Momentum: False\n",
      "Val Loss: 2.9405088761187987, Val Accuracy: 0.2564\n",
      "-----------\n",
      "Epoch: 8100, Loss: 2.969069871687819, Accuracy: 0.2333984375\n",
      "Epoch: 8200, Loss: 2.888087385909465, Accuracy: 0.2529296875\n",
      "Epoch: 8300, Loss: 2.8663230869626126, Accuracy: 0.2763671875\n",
      "Epoch: 8400, Loss: 2.996391015844269, Accuracy: 0.2421875\n",
      "Epoch: 8500, Loss: 2.9395289707327357, Accuracy: 0.2666015625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 8500, Momentum: False\n",
      "Val Loss: 2.89748646570331, Val Accuracy: 0.2628\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.896626141661941, Accuracy: 0.2490234375\n",
      "Epoch: 8700, Loss: 2.78750895215363, Accuracy: 0.2646484375\n",
      "Epoch: 8800, Loss: 2.7697823620820397, Accuracy: 0.2958984375\n",
      "Epoch: 8900, Loss: 2.814219448434338, Accuracy: 0.283203125\n",
      "Epoch: 9000, Loss: 2.885131149718942, Accuracy: 0.255859375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 9000, Momentum: False\n",
      "Val Loss: 2.858233530654647, Val Accuracy: 0.2710666666666667\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9100, Loss: 2.9078285640908392, Accuracy: 0.2626953125\n",
      "Epoch: 9200, Loss: 2.947198753908207, Accuracy: 0.2587890625\n",
      "Epoch: 9300, Loss: 2.6869693007659836, Accuracy: 0.298828125\n",
      "Epoch: 9400, Loss: 2.709306586817373, Accuracy: 0.2900390625\n",
      "Epoch: 9500, Loss: 2.7821332111257564, Accuracy: 0.271484375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 9500, Momentum: False\n",
      "Val Loss: 2.8237196180454327, Val Accuracy: 0.2772\n",
      "-----------\n",
      "Epoch: 9600, Loss: 2.772026939753364, Accuracy: 0.2763671875\n",
      "Epoch: 9700, Loss: 2.7636222131769106, Accuracy: 0.279296875\n",
      "Epoch: 9800, Loss: 2.7686045261431267, Accuracy: 0.2998046875\n",
      "Epoch: 9900, Loss: 2.653160724662465, Accuracy: 0.310546875\n",
      "Epoch: 10000, Loss: 2.760955686609538, Accuracy: 0.3017578125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 10000, Momentum: False\n",
      "Val Loss: 2.788714158253375, Val Accuracy: 0.2851666666666667\n",
      "-----------\n",
      "Epoch: 10100, Loss: 2.7270049880214793, Accuracy: 0.2890625\n",
      "Epoch: 10200, Loss: 2.7084888954225628, Accuracy: 0.291015625\n",
      "Epoch: 10300, Loss: 2.7606885130419014, Accuracy: 0.2919921875\n",
      "Epoch: 10400, Loss: 2.7559853989305862, Accuracy: 0.287109375\n",
      "Epoch: 10500, Loss: 2.719366599941484, Accuracy: 0.30078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 10500, Momentum: False\n",
      "Val Loss: 2.7577884414564258, Val Accuracy: 0.2917666666666667\n",
      "-----------\n",
      "Epoch: 10600, Loss: 2.649124198673683, Accuracy: 0.31640625\n",
      "Epoch: 10700, Loss: 2.8037715042584206, Accuracy: 0.271484375\n",
      "Epoch: 10800, Loss: 2.764169367914147, Accuracy: 0.2763671875\n",
      "Epoch: 10900, Loss: 2.651843864851173, Accuracy: 0.3154296875\n",
      "Epoch: 11000, Loss: 2.6403199830115454, Accuracy: 0.2939453125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 11000, Momentum: False\n",
      "Val Loss: 2.7278353925992285, Val Accuracy: 0.29846666666666666\n",
      "-----------\n",
      "Epoch: 11100, Loss: 2.7341000034157985, Accuracy: 0.275390625\n",
      "Epoch: 11200, Loss: 2.731388301596911, Accuracy: 0.2998046875\n",
      "Epoch: 11300, Loss: 2.690730647333686, Accuracy: 0.3037109375\n",
      "Epoch: 11400, Loss: 2.673589602505137, Accuracy: 0.3134765625\n",
      "Epoch: 11500, Loss: 2.636961048089183, Accuracy: 0.3017578125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 11500, Momentum: False\n",
      "Val Loss: 2.7015566115195706, Val Accuracy: 0.3038666666666667\n",
      "-----------\n",
      "Epoch: 11600, Loss: 2.6678451316596927, Accuracy: 0.2998046875\n",
      "Epoch: 11700, Loss: 2.6405875670243373, Accuracy: 0.3017578125\n",
      "Epoch: 11800, Loss: 2.723850511843145, Accuracy: 0.3095703125\n",
      "Epoch: 11900, Loss: 2.649214343815329, Accuracy: 0.3251953125\n",
      "Epoch: 12000, Loss: 2.6101201426508034, Accuracy: 0.3408203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 12000, Momentum: False\n",
      "Val Loss: 2.6756295682192732, Val Accuracy: 0.30973333333333336\n",
      "-----------\n",
      "Epoch: 12100, Loss: 2.6708639138150474, Accuracy: 0.296875\n",
      "Epoch: 12200, Loss: 2.6530896094433563, Accuracy: 0.3115234375\n",
      "Epoch: 12300, Loss: 2.6867777805439164, Accuracy: 0.2958984375\n",
      "Epoch: 12400, Loss: 2.5554697064135308, Accuracy: 0.3466796875\n",
      "Epoch: 12500, Loss: 2.6228033836747873, Accuracy: 0.3193359375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 12500, Momentum: False\n",
      "Val Loss: 2.650011717306337, Val Accuracy: 0.31456666666666666\n",
      "-----------\n",
      "Epoch: 12600, Loss: 2.604617108520539, Accuracy: 0.314453125\n",
      "Epoch: 12700, Loss: 2.542041580306605, Accuracy: 0.345703125\n",
      "Epoch: 12800, Loss: 2.571664192880692, Accuracy: 0.3427734375\n",
      "Epoch: 12900, Loss: 2.604365488482678, Accuracy: 0.337890625\n",
      "Epoch: 13000, Loss: 2.518341351881661, Accuracy: 0.3427734375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 13000, Momentum: False\n",
      "Val Loss: 2.6282801702372076, Val Accuracy: 0.3203\n",
      "-----------\n",
      "Epoch: 13100, Loss: 2.5878903082224234, Accuracy: 0.3310546875\n",
      "Epoch: 13200, Loss: 2.562762196460116, Accuracy: 0.3154296875\n",
      "Epoch: 13300, Loss: 2.5449179416227192, Accuracy: 0.3359375\n",
      "Epoch: 13400, Loss: 2.6440069614819355, Accuracy: 0.3212890625\n",
      "Epoch: 13500, Loss: 2.525580165884419, Accuracy: 0.3466796875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 13500, Momentum: False\n",
      "Val Loss: 2.6059815596413918, Val Accuracy: 0.3254\n",
      "-----------\n",
      "Epoch: 13600, Loss: 2.5958751373717313, Accuracy: 0.3232421875\n",
      "Epoch: 13700, Loss: 2.6475374125181297, Accuracy: 0.3271484375\n",
      "Epoch: 13800, Loss: 2.5655853758022076, Accuracy: 0.3349609375\n",
      "Epoch: 13900, Loss: 2.5886258009303855, Accuracy: 0.3154296875\n",
      "Epoch: 14000, Loss: 2.5300404645734775, Accuracy: 0.337890625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 14000, Momentum: False\n",
      "Val Loss: 2.5851945920606743, Val Accuracy: 0.3315666666666667\n",
      "-----------\n",
      "Epoch: 14100, Loss: 2.496866908589851, Accuracy: 0.36328125\n",
      "Epoch: 14200, Loss: 2.6804610105398403, Accuracy: 0.314453125\n",
      "Epoch: 14300, Loss: 2.5150483508952575, Accuracy: 0.33984375\n",
      "Epoch: 14400, Loss: 2.5004972846860447, Accuracy: 0.3525390625\n",
      "Epoch: 14500, Loss: 2.516652148109446, Accuracy: 0.34375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 14500, Momentum: False\n",
      "Val Loss: 2.564575744906605, Val Accuracy: 0.33586666666666665\n",
      "-----------\n",
      "Epoch: 14600, Loss: 2.4360008690870845, Accuracy: 0.3642578125\n",
      "Epoch: 14700, Loss: 2.6080533801272097, Accuracy: 0.3330078125\n",
      "Epoch: 14800, Loss: 2.5287469299066294, Accuracy: 0.3623046875\n",
      "Epoch: 14900, Loss: 2.5067933953493857, Accuracy: 0.3466796875\n",
      "Epoch: 15000, Loss: 2.523803784153736, Accuracy: 0.34375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 15000, Momentum: False\n",
      "Val Loss: 2.546789564375161, Val Accuracy: 0.34073333333333333\n",
      "-----------\n",
      "Epoch: 15100, Loss: 2.5313264659712162, Accuracy: 0.359375\n",
      "Epoch: 15200, Loss: 2.467556075029546, Accuracy: 0.3525390625\n",
      "Epoch: 15300, Loss: 2.530083150471009, Accuracy: 0.345703125\n",
      "Epoch: 15400, Loss: 2.484135261331273, Accuracy: 0.33984375\n",
      "Epoch: 15500, Loss: 2.5169654304164393, Accuracy: 0.337890625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 15500, Momentum: False\n",
      "Val Loss: 2.5292103679597107, Val Accuracy: 0.34346666666666664\n",
      "-----------\n",
      "Epoch: 15600, Loss: 2.5322384604415245, Accuracy: 0.337890625\n",
      "Epoch: 15700, Loss: 2.465947150689295, Accuracy: 0.359375\n",
      "Epoch: 15800, Loss: 2.5403285453400115, Accuracy: 0.333984375\n",
      "Epoch: 15900, Loss: 2.502715336025778, Accuracy: 0.33984375\n",
      "Epoch: 16000, Loss: 2.531141443400097, Accuracy: 0.3505859375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 16000, Momentum: False\n",
      "Val Loss: 2.5119049997359393, Val Accuracy: 0.34836666666666666\n",
      "-----------\n",
      "Epoch: 16100, Loss: 2.4554995305837757, Accuracy: 0.3525390625\n",
      "Epoch: 16200, Loss: 2.4827051771763164, Accuracy: 0.3671875\n",
      "Epoch: 16300, Loss: 2.4070939183901663, Accuracy: 0.3671875\n",
      "Epoch: 16400, Loss: 2.5301666990718994, Accuracy: 0.3388671875\n",
      "Epoch: 16500, Loss: 2.462043186775876, Accuracy: 0.34765625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 16500, Momentum: False\n",
      "Val Loss: 2.4959265098582457, Val Accuracy: 0.3526666666666667\n",
      "-----------\n",
      "Epoch: 16600, Loss: 2.4393058858024483, Accuracy: 0.3720703125\n",
      "Epoch: 16700, Loss: 2.5512585083675927, Accuracy: 0.3291015625\n",
      "Epoch: 16800, Loss: 2.4239749532871264, Accuracy: 0.375\n",
      "Epoch: 16900, Loss: 2.4190938621149862, Accuracy: 0.3603515625\n",
      "Epoch: 17000, Loss: 2.528319666260018, Accuracy: 0.3408203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 17000, Momentum: False\n",
      "Val Loss: 2.480717715629945, Val Accuracy: 0.35663333333333336\n",
      "-----------\n",
      "Epoch: 17100, Loss: 2.471391801317851, Accuracy: 0.34375\n",
      "Epoch: 17200, Loss: 2.450274550929978, Accuracy: 0.375\n",
      "Epoch: 17300, Loss: 2.451798237670241, Accuracy: 0.359375\n",
      "Epoch: 17400, Loss: 2.4273145432748082, Accuracy: 0.3486328125\n",
      "Epoch: 17500, Loss: 2.442191893276087, Accuracy: 0.3583984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 17500, Momentum: False\n",
      "Val Loss: 2.46712203617432, Val Accuracy: 0.3602666666666667\n",
      "-----------\n",
      "Epoch: 17600, Loss: 2.439476708572931, Accuracy: 0.3740234375\n",
      "Epoch: 17700, Loss: 2.388804189812224, Accuracy: 0.3896484375\n",
      "Epoch: 17800, Loss: 2.45070029495502, Accuracy: 0.3642578125\n",
      "Epoch: 17900, Loss: 2.4529040216876723, Accuracy: 0.3662109375\n",
      "Epoch: 18000, Loss: 2.353504751582813, Accuracy: 0.3798828125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 18000, Momentum: False\n",
      "Val Loss: 2.4524521911787405, Val Accuracy: 0.3629\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18100, Loss: 2.4669490622415737, Accuracy: 0.3466796875\n",
      "Epoch: 18200, Loss: 2.414294261811297, Accuracy: 0.3818359375\n",
      "Epoch: 18300, Loss: 2.5064193411668034, Accuracy: 0.3544921875\n",
      "Epoch: 18400, Loss: 2.357728511804419, Accuracy: 0.388671875\n",
      "Epoch: 18500, Loss: 2.4338574552754335, Accuracy: 0.3740234375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 18500, Momentum: False\n",
      "Val Loss: 2.440091454838856, Val Accuracy: 0.36606666666666665\n",
      "-----------\n",
      "Epoch: 18600, Loss: 2.3458267967783, Accuracy: 0.39453125\n",
      "Epoch: 18700, Loss: 2.381073740954256, Accuracy: 0.373046875\n",
      "Epoch: 18800, Loss: 2.390890641837612, Accuracy: 0.3857421875\n",
      "Epoch: 18900, Loss: 2.418138633348368, Accuracy: 0.353515625\n",
      "Epoch: 19000, Loss: 2.436152812807228, Accuracy: 0.3603515625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 19000, Momentum: False\n",
      "Val Loss: 2.427902283362169, Val Accuracy: 0.3682666666666667\n",
      "-----------\n",
      "Epoch: 19100, Loss: 2.331099807647396, Accuracy: 0.384765625\n",
      "Epoch: 19200, Loss: 2.3744337551770034, Accuracy: 0.376953125\n",
      "Epoch: 19300, Loss: 2.4220815610910718, Accuracy: 0.3828125\n",
      "Epoch: 19400, Loss: 2.419987148921031, Accuracy: 0.36328125\n",
      "Epoch: 19500, Loss: 2.355624713534551, Accuracy: 0.37109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 19500, Momentum: False\n",
      "Val Loss: 2.414737643716726, Val Accuracy: 0.37216666666666665\n",
      "-----------\n",
      "Epoch: 19600, Loss: 2.3144196067435296, Accuracy: 0.37890625\n",
      "Epoch: 19700, Loss: 2.3637247102767116, Accuracy: 0.3759765625\n",
      "Epoch: 19800, Loss: 2.438873328653232, Accuracy: 0.3544921875\n",
      "Epoch: 19900, Loss: 2.335039381525397, Accuracy: 0.4091796875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 0.001, Num Epoch: 19500, Momentum: False\n",
      "Test Loss: 2.419774419753663, Test Accuracy: 0.3734585811693022\n",
      "-----------\n",
      "Epoch: 0, Loss: 12.886845078177853, Accuracy: 0.037109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 0, Momentum: True\n",
      "Val Loss: 11.018912454229676, Val Accuracy: 0.03213333333333333\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.648935297656682, Accuracy: 0.0537109375\n",
      "Epoch: 200, Loss: 4.508242656805905, Accuracy: 0.05859375\n",
      "Epoch: 300, Loss: 4.306648810469651, Accuracy: 0.068359375\n",
      "Epoch: 400, Loss: 4.2892548976589655, Accuracy: 0.08203125\n",
      "Epoch: 500, Loss: 4.276289437840271, Accuracy: 0.0771484375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 500, Momentum: True\n",
      "Val Loss: 4.2856546121386, Val Accuracy: 0.07693333333333334\n",
      "-----------\n",
      "Epoch: 600, Loss: 4.202544249813039, Accuracy: 0.0849609375\n",
      "Epoch: 700, Loss: 4.159613508241037, Accuracy: 0.080078125\n",
      "Epoch: 800, Loss: 3.9459020229490935, Accuracy: 0.0986328125\n",
      "Epoch: 900, Loss: 4.0105490562501345, Accuracy: 0.09375\n",
      "Epoch: 1000, Loss: 3.9375816152187997, Accuracy: 0.111328125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 1000, Momentum: True\n",
      "Val Loss: 3.9403541472356935, Val Accuracy: 0.1123\n",
      "-----------\n",
      "Epoch: 1100, Loss: 3.912983058470775, Accuracy: 0.1123046875\n",
      "Epoch: 1200, Loss: 3.865170238994372, Accuracy: 0.1083984375\n",
      "Epoch: 1300, Loss: 3.716095776492174, Accuracy: 0.1455078125\n",
      "Epoch: 1400, Loss: 3.80844257529696, Accuracy: 0.1328125\n",
      "Epoch: 1500, Loss: 3.581196506510686, Accuracy: 0.154296875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 1500, Momentum: True\n",
      "Val Loss: 3.6925711733501148, Val Accuracy: 0.14743333333333333\n",
      "-----------\n",
      "Epoch: 1600, Loss: 3.5705394303069435, Accuracy: 0.150390625\n",
      "Epoch: 1700, Loss: 3.6110925298232437, Accuracy: 0.15625\n",
      "Epoch: 1800, Loss: 3.6483160655083218, Accuracy: 0.146484375\n",
      "Epoch: 1900, Loss: 3.578799138643972, Accuracy: 0.1591796875\n",
      "Epoch: 2000, Loss: 3.5343767791304694, Accuracy: 0.1796875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 2000, Momentum: True\n",
      "Val Loss: 3.5014547468535113, Val Accuracy: 0.17513333333333334\n",
      "-----------\n",
      "Epoch: 2100, Loss: 3.5256560149843605, Accuracy: 0.1669921875\n",
      "Epoch: 2200, Loss: 3.3996855421706713, Accuracy: 0.193359375\n",
      "Epoch: 2300, Loss: 3.3753735000663907, Accuracy: 0.2021484375\n",
      "Epoch: 2400, Loss: 3.472098088455414, Accuracy: 0.16796875\n",
      "Epoch: 2500, Loss: 3.2495113197869347, Accuracy: 0.2177734375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 2500, Momentum: True\n",
      "Val Loss: 3.3467366111586214, Val Accuracy: 0.1992\n",
      "-----------\n",
      "Epoch: 2600, Loss: 3.30442972946671, Accuracy: 0.203125\n",
      "Epoch: 2700, Loss: 3.224604067876737, Accuracy: 0.220703125\n",
      "Epoch: 2800, Loss: 3.270569120314819, Accuracy: 0.2099609375\n",
      "Epoch: 2900, Loss: 3.2039229569288397, Accuracy: 0.2265625\n",
      "Epoch: 3000, Loss: 3.163009551439469, Accuracy: 0.2236328125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 3000, Momentum: True\n",
      "Val Loss: 3.223015162566265, Val Accuracy: 0.2203\n",
      "-----------\n",
      "Epoch: 3100, Loss: 3.2011870162273777, Accuracy: 0.2353515625\n",
      "Epoch: 3200, Loss: 3.1254565704351607, Accuracy: 0.240234375\n",
      "Epoch: 3300, Loss: 3.173090271041171, Accuracy: 0.21875\n",
      "Epoch: 3400, Loss: 3.158401938468992, Accuracy: 0.2392578125\n",
      "Epoch: 3500, Loss: 3.00148264597894, Accuracy: 0.2529296875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 3500, Momentum: True\n",
      "Val Loss: 3.1183602252880336, Val Accuracy: 0.23913333333333334\n",
      "-----------\n",
      "Epoch: 3600, Loss: 3.039924019845314, Accuracy: 0.259765625\n",
      "Epoch: 3700, Loss: 3.02215154193585, Accuracy: 0.2412109375\n",
      "Epoch: 3800, Loss: 3.22953738530573, Accuracy: 0.23828125\n",
      "Epoch: 3900, Loss: 3.0525309155239504, Accuracy: 0.244140625\n",
      "Epoch: 4000, Loss: 3.0150905548826206, Accuracy: 0.2626953125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 4000, Momentum: True\n",
      "Val Loss: 3.0269152790271594, Val Accuracy: 0.2545\n",
      "-----------\n",
      "Epoch: 4100, Loss: 3.093443950269555, Accuracy: 0.248046875\n",
      "Epoch: 4200, Loss: 2.968615332869354, Accuracy: 0.265625\n",
      "Epoch: 4300, Loss: 2.8584187331159963, Accuracy: 0.2783203125\n",
      "Epoch: 4400, Loss: 2.9447085389466814, Accuracy: 0.2646484375\n",
      "Epoch: 4500, Loss: 2.8957311961561962, Accuracy: 0.2666015625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 4500, Momentum: True\n",
      "Val Loss: 2.948846810846539, Val Accuracy: 0.26893333333333336\n",
      "-----------\n",
      "Epoch: 4600, Loss: 3.0255322086524554, Accuracy: 0.2568359375\n",
      "Epoch: 4700, Loss: 2.8091188487160803, Accuracy: 0.291015625\n",
      "Epoch: 4800, Loss: 3.024960606400712, Accuracy: 0.26171875\n",
      "Epoch: 4900, Loss: 2.927758434999728, Accuracy: 0.2724609375\n",
      "Epoch: 5000, Loss: 2.736669327284757, Accuracy: 0.314453125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 5000, Momentum: True\n",
      "Val Loss: 2.8784283527583803, Val Accuracy: 0.2834\n",
      "-----------\n",
      "Epoch: 5100, Loss: 2.8293144990692554, Accuracy: 0.302734375\n",
      "Epoch: 5200, Loss: 2.9315743536945065, Accuracy: 0.271484375\n",
      "Epoch: 5300, Loss: 2.8546470119281038, Accuracy: 0.287109375\n",
      "Epoch: 5400, Loss: 2.824357369291155, Accuracy: 0.2802734375\n",
      "Epoch: 5500, Loss: 2.7793660473258144, Accuracy: 0.302734375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 5500, Momentum: True\n",
      "Val Loss: 2.8211118612867434, Val Accuracy: 0.29413333333333336\n",
      "-----------\n",
      "Epoch: 5600, Loss: 2.8513714122322806, Accuracy: 0.2998046875\n",
      "Epoch: 5700, Loss: 2.7453151242499754, Accuracy: 0.302734375\n",
      "Epoch: 5800, Loss: 2.7060415326566285, Accuracy: 0.31640625\n",
      "Epoch: 5900, Loss: 2.788367956332804, Accuracy: 0.2939453125\n",
      "Epoch: 6000, Loss: 2.7237548732494856, Accuracy: 0.30078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 6000, Momentum: True\n",
      "Val Loss: 2.7668192509909066, Val Accuracy: 0.30533333333333335\n",
      "-----------\n",
      "Epoch: 6100, Loss: 2.767936914759823, Accuracy: 0.306640625\n",
      "Epoch: 6200, Loss: 2.675567063251918, Accuracy: 0.3076171875\n",
      "Epoch: 6300, Loss: 2.7866154167634978, Accuracy: 0.2900390625\n",
      "Epoch: 6400, Loss: 2.6332221191506724, Accuracy: 0.3369140625\n",
      "Epoch: 6500, Loss: 2.7409676779556653, Accuracy: 0.2900390625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 6500, Momentum: True\n",
      "Val Loss: 2.7186953501969113, Val Accuracy: 0.3149\n",
      "-----------\n",
      "Epoch: 6600, Loss: 2.6285860555301817, Accuracy: 0.330078125\n",
      "Epoch: 6700, Loss: 2.7876075914238188, Accuracy: 0.3173828125\n",
      "Epoch: 6800, Loss: 2.7417550732841356, Accuracy: 0.3056640625\n",
      "Epoch: 6900, Loss: 2.68686710800172, Accuracy: 0.314453125\n",
      "Epoch: 7000, Loss: 2.68486582889804, Accuracy: 0.314453125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 7000, Momentum: True\n",
      "Val Loss: 2.6711042304672947, Val Accuracy: 0.3229666666666667\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7100, Loss: 2.6871925081385246, Accuracy: 0.3271484375\n",
      "Epoch: 7200, Loss: 2.6768216408615455, Accuracy: 0.3310546875\n",
      "Epoch: 7300, Loss: 2.6860472646347118, Accuracy: 0.3271484375\n",
      "Epoch: 7400, Loss: 2.6749181346161066, Accuracy: 0.330078125\n",
      "Epoch: 7500, Loss: 2.606685068415315, Accuracy: 0.345703125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 7500, Momentum: True\n",
      "Val Loss: 2.6313864078762577, Val Accuracy: 0.3323\n",
      "-----------\n",
      "Epoch: 7600, Loss: 2.6026760601185766, Accuracy: 0.3359375\n",
      "Epoch: 7700, Loss: 2.5340987264356616, Accuracy: 0.345703125\n",
      "Epoch: 7800, Loss: 2.5899029761921066, Accuracy: 0.330078125\n",
      "Epoch: 7900, Loss: 2.701003981356572, Accuracy: 0.330078125\n",
      "Epoch: 8000, Loss: 2.562125026110517, Accuracy: 0.3466796875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 8000, Momentum: True\n",
      "Val Loss: 2.596084235811636, Val Accuracy: 0.3396666666666667\n",
      "-----------\n",
      "Epoch: 8100, Loss: 2.596453861551042, Accuracy: 0.3203125\n",
      "Epoch: 8200, Loss: 2.4147903065168133, Accuracy: 0.3876953125\n",
      "Epoch: 8300, Loss: 2.5271767934652427, Accuracy: 0.341796875\n",
      "Epoch: 8400, Loss: 2.447047499773488, Accuracy: 0.3671875\n",
      "Epoch: 8500, Loss: 2.4930535989284115, Accuracy: 0.35546875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 8500, Momentum: True\n",
      "Val Loss: 2.563414735145119, Val Accuracy: 0.34726666666666667\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.5881451920779615, Accuracy: 0.3330078125\n",
      "Epoch: 8700, Loss: 2.5452778032772185, Accuracy: 0.3466796875\n",
      "Epoch: 8800, Loss: 2.490245654445181, Accuracy: 0.369140625\n",
      "Epoch: 8900, Loss: 2.4785876401840357, Accuracy: 0.388671875\n",
      "Epoch: 9000, Loss: 2.530911772755278, Accuracy: 0.359375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 9000, Momentum: True\n",
      "Val Loss: 2.530856416222533, Val Accuracy: 0.3533\n",
      "-----------\n",
      "Epoch: 9100, Loss: 2.4878658772636575, Accuracy: 0.34375\n",
      "Epoch: 9200, Loss: 2.4836260162565607, Accuracy: 0.3681640625\n",
      "Epoch: 9300, Loss: 2.5502202325777454, Accuracy: 0.3564453125\n",
      "Epoch: 9400, Loss: 2.5341946584776913, Accuracy: 0.34765625\n",
      "Epoch: 9500, Loss: 2.435643579960559, Accuracy: 0.3583984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 9500, Momentum: True\n",
      "Val Loss: 2.501674359362621, Val Accuracy: 0.3595\n",
      "-----------\n",
      "Epoch: 9600, Loss: 2.484826957298922, Accuracy: 0.375\n",
      "Epoch: 9700, Loss: 2.4518382979097106, Accuracy: 0.3583984375\n",
      "Epoch: 9800, Loss: 2.3856570693379338, Accuracy: 0.3740234375\n",
      "Epoch: 9900, Loss: 2.5385640717878606, Accuracy: 0.349609375\n",
      "Epoch: 10000, Loss: 2.478697544674947, Accuracy: 0.357421875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 10000, Momentum: True\n",
      "Val Loss: 2.4734212786441727, Val Accuracy: 0.3675\n",
      "-----------\n",
      "Epoch: 10100, Loss: 2.4512213749476666, Accuracy: 0.373046875\n",
      "Epoch: 10200, Loss: 2.5182982259950606, Accuracy: 0.357421875\n",
      "Epoch: 10300, Loss: 2.345201934199757, Accuracy: 0.3994140625\n",
      "Epoch: 10400, Loss: 2.3249186892167466, Accuracy: 0.4130859375\n",
      "Epoch: 10500, Loss: 2.5045252058718406, Accuracy: 0.36328125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 10500, Momentum: True\n",
      "Val Loss: 2.448644513043515, Val Accuracy: 0.37196666666666667\n",
      "-----------\n",
      "Epoch: 10600, Loss: 2.421583096066785, Accuracy: 0.3779296875\n",
      "Epoch: 10700, Loss: 2.5167090562195353, Accuracy: 0.3642578125\n",
      "Epoch: 10800, Loss: 2.3646401793376723, Accuracy: 0.3876953125\n",
      "Epoch: 10900, Loss: 2.3951475308487273, Accuracy: 0.369140625\n",
      "Epoch: 11000, Loss: 2.481398606949176, Accuracy: 0.3564453125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 11000, Momentum: True\n",
      "Val Loss: 2.425440708113692, Val Accuracy: 0.3767333333333333\n",
      "-----------\n",
      "Epoch: 11100, Loss: 2.4202266268778283, Accuracy: 0.3642578125\n",
      "Epoch: 11200, Loss: 2.2658231348895876, Accuracy: 0.40625\n",
      "Epoch: 11300, Loss: 2.428732721554532, Accuracy: 0.37890625\n",
      "Epoch: 11400, Loss: 2.39720307690159, Accuracy: 0.37890625\n",
      "Epoch: 11500, Loss: 2.3679885081268788, Accuracy: 0.3818359375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 11500, Momentum: True\n",
      "Val Loss: 2.4043762321989184, Val Accuracy: 0.38293333333333335\n",
      "-----------\n",
      "Epoch: 11600, Loss: 2.3900658383507896, Accuracy: 0.396484375\n",
      "Epoch: 11700, Loss: 2.302449777435845, Accuracy: 0.4052734375\n",
      "Epoch: 11800, Loss: 2.292204715887361, Accuracy: 0.3974609375\n",
      "Epoch: 11900, Loss: 2.407161559116533, Accuracy: 0.3876953125\n",
      "Epoch: 12000, Loss: 2.3319458431526594, Accuracy: 0.388671875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 12000, Momentum: True\n",
      "Val Loss: 2.3836671899113067, Val Accuracy: 0.3865\n",
      "-----------\n",
      "Epoch: 12100, Loss: 2.424598793213278, Accuracy: 0.365234375\n",
      "Epoch: 12200, Loss: 2.3792253997808883, Accuracy: 0.3896484375\n",
      "Epoch: 12300, Loss: 2.357274701083859, Accuracy: 0.37890625\n",
      "Epoch: 12400, Loss: 2.3254290079846456, Accuracy: 0.4033203125\n",
      "Epoch: 12500, Loss: 2.2598891924067166, Accuracy: 0.4306640625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 12500, Momentum: True\n",
      "Val Loss: 2.3659589416983504, Val Accuracy: 0.39116666666666666\n",
      "-----------\n",
      "Epoch: 12600, Loss: 2.3451064083265445, Accuracy: 0.404296875\n",
      "Epoch: 12700, Loss: 2.266406245481074, Accuracy: 0.4013671875\n",
      "Epoch: 12800, Loss: 2.3063408893749484, Accuracy: 0.3779296875\n",
      "Epoch: 12900, Loss: 2.366948710597795, Accuracy: 0.41015625\n",
      "Epoch: 13000, Loss: 2.268809533088713, Accuracy: 0.42578125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 13000, Momentum: True\n",
      "Val Loss: 2.34726586883252, Val Accuracy: 0.39553333333333335\n",
      "-----------\n",
      "Epoch: 13100, Loss: 2.257021878129297, Accuracy: 0.3974609375\n",
      "Epoch: 13200, Loss: 2.2696108871857668, Accuracy: 0.4091796875\n",
      "Epoch: 13300, Loss: 2.2683705761899358, Accuracy: 0.3984375\n",
      "Epoch: 13400, Loss: 2.2910788038965046, Accuracy: 0.412109375\n",
      "Epoch: 13500, Loss: 2.3549820511557673, Accuracy: 0.392578125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 13500, Momentum: True\n",
      "Val Loss: 2.3302774854116612, Val Accuracy: 0.3985666666666667\n",
      "-----------\n",
      "Epoch: 13600, Loss: 2.279144778152375, Accuracy: 0.408203125\n",
      "Epoch: 13700, Loss: 2.272836329233564, Accuracy: 0.4208984375\n",
      "Epoch: 13800, Loss: 2.23395742673837, Accuracy: 0.41015625\n",
      "Epoch: 13900, Loss: 2.214652012561241, Accuracy: 0.431640625\n",
      "Epoch: 14000, Loss: 2.2463822175165413, Accuracy: 0.4111328125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 14000, Momentum: True\n",
      "Val Loss: 2.3117112488215605, Val Accuracy: 0.4039333333333333\n",
      "-----------\n",
      "Epoch: 14100, Loss: 2.2614737861104777, Accuracy: 0.396484375\n",
      "Epoch: 14200, Loss: 2.247064514420881, Accuracy: 0.4150390625\n",
      "Epoch: 14300, Loss: 2.245922652681295, Accuracy: 0.41796875\n",
      "Epoch: 14400, Loss: 2.323360181863424, Accuracy: 0.3857421875\n",
      "Epoch: 14500, Loss: 2.246957362319815, Accuracy: 0.4208984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 14500, Momentum: True\n",
      "Val Loss: 2.2977056452779125, Val Accuracy: 0.40663333333333335\n",
      "-----------\n",
      "Epoch: 14600, Loss: 2.328924391330929, Accuracy: 0.408203125\n",
      "Epoch: 14700, Loss: 2.194562330482855, Accuracy: 0.4306640625\n",
      "Epoch: 14800, Loss: 2.266282320768993, Accuracy: 0.400390625\n",
      "Epoch: 14900, Loss: 2.303631383734057, Accuracy: 0.392578125\n",
      "Epoch: 15000, Loss: 2.243509196909266, Accuracy: 0.412109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 15000, Momentum: True\n",
      "Val Loss: 2.2823256315810876, Val Accuracy: 0.4103\n",
      "-----------\n",
      "Epoch: 15100, Loss: 2.156571170405832, Accuracy: 0.431640625\n",
      "Epoch: 15200, Loss: 2.241594843209363, Accuracy: 0.4130859375\n",
      "Epoch: 15300, Loss: 2.2182325312075166, Accuracy: 0.416015625\n",
      "Epoch: 15400, Loss: 2.2215417775577118, Accuracy: 0.4306640625\n",
      "Epoch: 15500, Loss: 2.2040522979288877, Accuracy: 0.4345703125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 15500, Momentum: True\n",
      "Val Loss: 2.2684887591281284, Val Accuracy: 0.4128\n",
      "-----------\n",
      "Epoch: 15600, Loss: 2.141738966428056, Accuracy: 0.447265625\n",
      "Epoch: 15700, Loss: 2.1542893085022268, Accuracy: 0.4326171875\n",
      "Epoch: 15800, Loss: 2.18315081900512, Accuracy: 0.4228515625\n",
      "Epoch: 15900, Loss: 2.240139383642223, Accuracy: 0.4423828125\n",
      "Epoch: 16000, Loss: 2.1833508895335987, Accuracy: 0.416015625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 16000, Momentum: True\n",
      "Val Loss: 2.2553144681946407, Val Accuracy: 0.4169333333333333\n",
      "-----------\n",
      "Epoch: 16100, Loss: 2.2057066434341817, Accuracy: 0.431640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16200, Loss: 2.2844289839003915, Accuracy: 0.4072265625\n",
      "Epoch: 16300, Loss: 2.167636575977213, Accuracy: 0.4453125\n",
      "Epoch: 16400, Loss: 2.2000113803088395, Accuracy: 0.435546875\n",
      "Epoch: 16500, Loss: 2.2370671843057797, Accuracy: 0.42578125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 16500, Momentum: True\n",
      "Val Loss: 2.2433933989027914, Val Accuracy: 0.41873333333333335\n",
      "-----------\n",
      "Epoch: 16600, Loss: 2.2048387544380206, Accuracy: 0.427734375\n",
      "Epoch: 16700, Loss: 2.1993706374769726, Accuracy: 0.4248046875\n",
      "Epoch: 16800, Loss: 2.205839182138199, Accuracy: 0.4248046875\n",
      "Epoch: 16900, Loss: 2.112659051701354, Accuracy: 0.4296875\n",
      "Epoch: 17000, Loss: 2.1745782361533, Accuracy: 0.4267578125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 17000, Momentum: True\n",
      "Val Loss: 2.2311986012941354, Val Accuracy: 0.4224\n",
      "-----------\n",
      "Epoch: 17100, Loss: 2.2059105864223896, Accuracy: 0.421875\n",
      "Epoch: 17200, Loss: 2.169782375918561, Accuracy: 0.4423828125\n",
      "Epoch: 17300, Loss: 2.2303076696481585, Accuracy: 0.4150390625\n",
      "Epoch: 17400, Loss: 2.200053886172819, Accuracy: 0.423828125\n",
      "Epoch: 17500, Loss: 2.1519273770116847, Accuracy: 0.4423828125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 17500, Momentum: True\n",
      "Val Loss: 2.2213676914385596, Val Accuracy: 0.4245333333333333\n",
      "-----------\n",
      "Epoch: 17600, Loss: 2.140869317826536, Accuracy: 0.44921875\n",
      "Epoch: 17700, Loss: 2.1570041920125442, Accuracy: 0.4365234375\n",
      "Epoch: 17800, Loss: 2.1448435083746347, Accuracy: 0.4541015625\n",
      "Epoch: 17900, Loss: 2.11783671758998, Accuracy: 0.4541015625\n",
      "Epoch: 18000, Loss: 2.1609216684234034, Accuracy: 0.4365234375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 18000, Momentum: True\n",
      "Val Loss: 2.2081841390226207, Val Accuracy: 0.42683333333333334\n",
      "-----------\n",
      "Epoch: 18100, Loss: 2.1462742929088803, Accuracy: 0.4326171875\n",
      "Epoch: 18200, Loss: 2.2262816102154064, Accuracy: 0.4248046875\n",
      "Epoch: 18300, Loss: 2.1477072960889956, Accuracy: 0.44140625\n",
      "Epoch: 18400, Loss: 2.2282533217091007, Accuracy: 0.423828125\n",
      "Epoch: 18500, Loss: 2.1364676211753446, Accuracy: 0.453125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 18500, Momentum: True\n",
      "Val Loss: 2.1967389705077243, Val Accuracy: 0.429\n",
      "-----------\n",
      "Epoch: 18600, Loss: 2.1151662776291174, Accuracy: 0.453125\n",
      "Epoch: 18700, Loss: 2.088842473769412, Accuracy: 0.46875\n",
      "Epoch: 18800, Loss: 2.16833845323094, Accuracy: 0.451171875\n",
      "Epoch: 18900, Loss: 2.1711394179126615, Accuracy: 0.4443359375\n",
      "Epoch: 19000, Loss: 2.1429044145759626, Accuracy: 0.4462890625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 19000, Momentum: True\n",
      "Val Loss: 2.1867474787013195, Val Accuracy: 0.43023333333333336\n",
      "-----------\n",
      "Epoch: 19100, Loss: 2.11735463417806, Accuracy: 0.4345703125\n",
      "Epoch: 19200, Loss: 2.188704671620613, Accuracy: 0.423828125\n",
      "Epoch: 19300, Loss: 2.151054344577644, Accuracy: 0.4443359375\n",
      "Epoch: 19400, Loss: 2.0606548273795173, Accuracy: 0.466796875\n",
      "Epoch: 19500, Loss: 2.0743281092203794, Accuracy: 0.4560546875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 19500, Momentum: True\n",
      "Val Loss: 2.1787268357918927, Val Accuracy: 0.4338666666666667\n",
      "-----------\n",
      "Epoch: 19600, Loss: 2.0697493383266536, Accuracy: 0.443359375\n",
      "Epoch: 19700, Loss: 2.0286237689080635, Accuracy: 0.470703125\n",
      "Epoch: 19800, Loss: 2.072983308405386, Accuracy: 0.4453125\n",
      "Epoch: 19900, Loss: 2.1928467785350225, Accuracy: 0.4296875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 19500, Momentum: True\n",
      "Test Loss: 2.198111122903952, Test Accuracy: 0.42583055273465836\n",
      "-----------\n",
      "Epoch: 0, Loss: 14.32356684983041, Accuracy: 0.0283203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 0, Momentum: False\n",
      "Val Loss: 13.002039406313822, Val Accuracy: 0.03473333333333333\n",
      "-----------\n",
      "Epoch: 100, Loss: 4.870545220238833, Accuracy: 0.037109375\n",
      "Epoch: 200, Loss: 4.7712499801203405, Accuracy: 0.048828125\n",
      "Epoch: 300, Loss: 4.587686864479755, Accuracy: 0.041015625\n",
      "Epoch: 400, Loss: 4.635114944645444, Accuracy: 0.05859375\n",
      "Epoch: 500, Loss: 4.545558958298768, Accuracy: 0.0634765625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 500, Momentum: False\n",
      "Val Loss: 4.574292315208164, Val Accuracy: 0.0585\n",
      "-----------\n",
      "Epoch: 600, Loss: 4.48572317168415, Accuracy: 0.0625\n",
      "Epoch: 700, Loss: 4.4594377036742685, Accuracy: 0.05859375\n",
      "Epoch: 800, Loss: 4.439015312562882, Accuracy: 0.0751953125\n",
      "Epoch: 900, Loss: 4.385589160479528, Accuracy: 0.0703125\n",
      "Epoch: 1000, Loss: 4.215762479099806, Accuracy: 0.076171875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 1000, Momentum: False\n",
      "Val Loss: 4.343510043768637, Val Accuracy: 0.0733\n",
      "-----------\n",
      "Epoch: 1100, Loss: 4.2636768357410375, Accuracy: 0.078125\n",
      "Epoch: 1200, Loss: 4.161950362413036, Accuracy: 0.080078125\n",
      "Epoch: 1300, Loss: 4.1424548965369254, Accuracy: 0.076171875\n",
      "Epoch: 1400, Loss: 4.163935498703491, Accuracy: 0.09375\n",
      "Epoch: 1500, Loss: 4.241984570569784, Accuracy: 0.08984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 1500, Momentum: False\n",
      "Val Loss: 4.154773485507833, Val Accuracy: 0.0883\n",
      "-----------\n",
      "Epoch: 1600, Loss: 4.182979432390401, Accuracy: 0.0966796875\n",
      "Epoch: 1700, Loss: 4.127731923681449, Accuracy: 0.0927734375\n",
      "Epoch: 1800, Loss: 3.978214756984963, Accuracy: 0.119140625\n",
      "Epoch: 1900, Loss: 3.9883047621956584, Accuracy: 0.099609375\n",
      "Epoch: 2000, Loss: 3.990977135672616, Accuracy: 0.0869140625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 2000, Momentum: False\n",
      "Val Loss: 3.988428680800878, Val Accuracy: 0.10646666666666667\n",
      "-----------\n",
      "Epoch: 2100, Loss: 4.00173743011578, Accuracy: 0.1064453125\n",
      "Epoch: 2200, Loss: 3.958143486462653, Accuracy: 0.109375\n",
      "Epoch: 2300, Loss: 3.8665657672912817, Accuracy: 0.1201171875\n",
      "Epoch: 2400, Loss: 3.8732044572601065, Accuracy: 0.109375\n",
      "Epoch: 2500, Loss: 3.8718789176941253, Accuracy: 0.1240234375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 2500, Momentum: False\n",
      "Val Loss: 3.8466330021571764, Val Accuracy: 0.1247\n",
      "-----------\n",
      "Epoch: 2600, Loss: 3.7839086005953133, Accuracy: 0.1220703125\n",
      "Epoch: 2700, Loss: 3.6918505978278153, Accuracy: 0.1484375\n",
      "Epoch: 2800, Loss: 3.7685528599413063, Accuracy: 0.1376953125\n",
      "Epoch: 2900, Loss: 3.790655127713355, Accuracy: 0.11328125\n",
      "Epoch: 3000, Loss: 3.758959610939719, Accuracy: 0.134765625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 3000, Momentum: False\n",
      "Val Loss: 3.727043163982907, Val Accuracy: 0.1392\n",
      "-----------\n",
      "Epoch: 3100, Loss: 3.5927751634957317, Accuracy: 0.146484375\n",
      "Epoch: 3200, Loss: 3.658498143560066, Accuracy: 0.1552734375\n",
      "Epoch: 3300, Loss: 3.5278054775884216, Accuracy: 0.166015625\n",
      "Epoch: 3400, Loss: 3.6793141916313776, Accuracy: 0.142578125\n",
      "Epoch: 3500, Loss: 3.6494075642653523, Accuracy: 0.1533203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 3500, Momentum: False\n",
      "Val Loss: 3.619429223798043, Val Accuracy: 0.1545\n",
      "-----------\n",
      "Epoch: 3600, Loss: 3.5920217250264788, Accuracy: 0.1611328125\n",
      "Epoch: 3700, Loss: 3.520304159070696, Accuracy: 0.1640625\n",
      "Epoch: 3800, Loss: 3.5466154033774093, Accuracy: 0.173828125\n",
      "Epoch: 3900, Loss: 3.537749315043021, Accuracy: 0.1552734375\n",
      "Epoch: 4000, Loss: 3.429833836872098, Accuracy: 0.169921875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 4000, Momentum: False\n",
      "Val Loss: 3.5263229670317813, Val Accuracy: 0.16986666666666667\n",
      "-----------\n",
      "Epoch: 4100, Loss: 3.404303478483181, Accuracy: 0.1806640625\n",
      "Epoch: 4200, Loss: 3.44996827334563, Accuracy: 0.1845703125\n",
      "Epoch: 4300, Loss: 3.477975753663471, Accuracy: 0.19921875\n",
      "Epoch: 4400, Loss: 3.5434500876376958, Accuracy: 0.158203125\n",
      "Epoch: 4500, Loss: 3.485061484051082, Accuracy: 0.1748046875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 4500, Momentum: False\n",
      "Val Loss: 3.443045741571903, Val Accuracy: 0.1829\n",
      "-----------\n",
      "Epoch: 4600, Loss: 3.4895991067180816, Accuracy: 0.1767578125\n",
      "Epoch: 4700, Loss: 3.3577083167572574, Accuracy: 0.185546875\n",
      "Epoch: 4800, Loss: 3.4924369590565916, Accuracy: 0.1904296875\n",
      "Epoch: 4900, Loss: 3.393079494711153, Accuracy: 0.1826171875\n",
      "Epoch: 5000, Loss: 3.3945475839828063, Accuracy: 0.1953125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 5000, Momentum: False\n",
      "Val Loss: 3.3676711471688505, Val Accuracy: 0.19623333333333334\n",
      "-----------\n",
      "Epoch: 5100, Loss: 3.331859454616847, Accuracy: 0.201171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5200, Loss: 3.238936082155206, Accuracy: 0.2119140625\n",
      "Epoch: 5300, Loss: 3.4338071941988244, Accuracy: 0.173828125\n",
      "Epoch: 5400, Loss: 3.3830420713494265, Accuracy: 0.20703125\n",
      "Epoch: 5500, Loss: 3.3110235911744987, Accuracy: 0.2080078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 5500, Momentum: False\n",
      "Val Loss: 3.298408030644516, Val Accuracy: 0.2051\n",
      "-----------\n",
      "Epoch: 5600, Loss: 3.3905371151410635, Accuracy: 0.197265625\n",
      "Epoch: 5700, Loss: 3.1559478660107816, Accuracy: 0.2236328125\n",
      "Epoch: 5800, Loss: 3.264150443172391, Accuracy: 0.193359375\n",
      "Epoch: 5900, Loss: 3.2392211047733093, Accuracy: 0.2001953125\n",
      "Epoch: 6000, Loss: 3.2137120076710413, Accuracy: 0.2255859375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 6000, Momentum: False\n",
      "Val Loss: 3.237165969301831, Val Accuracy: 0.21663333333333334\n",
      "-----------\n",
      "Epoch: 6100, Loss: 3.163981390783172, Accuracy: 0.2333984375\n",
      "Epoch: 6200, Loss: 3.1637506782634404, Accuracy: 0.22265625\n",
      "Epoch: 6300, Loss: 3.1858523622388537, Accuracy: 0.2080078125\n",
      "Epoch: 6400, Loss: 3.242233402745003, Accuracy: 0.2216796875\n",
      "Epoch: 6500, Loss: 3.1893486109278215, Accuracy: 0.21875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 6500, Momentum: False\n",
      "Val Loss: 3.181338274438679, Val Accuracy: 0.2256\n",
      "-----------\n",
      "Epoch: 6600, Loss: 3.1395220770667134, Accuracy: 0.23046875\n",
      "Epoch: 6700, Loss: 3.1880184742370057, Accuracy: 0.212890625\n",
      "Epoch: 6800, Loss: 3.1185818592630774, Accuracy: 0.228515625\n",
      "Epoch: 6900, Loss: 3.072166640314383, Accuracy: 0.2412109375\n",
      "Epoch: 7000, Loss: 3.0212213012713134, Accuracy: 0.25\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 7000, Momentum: False\n",
      "Val Loss: 3.130780751665409, Val Accuracy: 0.23686666666666667\n",
      "-----------\n",
      "Epoch: 7100, Loss: 3.0910190485972207, Accuracy: 0.2548828125\n",
      "Epoch: 7200, Loss: 3.039738521265177, Accuracy: 0.2412109375\n",
      "Epoch: 7300, Loss: 2.9175494491880736, Accuracy: 0.271484375\n",
      "Epoch: 7400, Loss: 3.024481649230144, Accuracy: 0.2421875\n",
      "Epoch: 7500, Loss: 3.1669248004436166, Accuracy: 0.2177734375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 7500, Momentum: False\n",
      "Val Loss: 3.0830439861127443, Val Accuracy: 0.2462\n",
      "-----------\n",
      "Epoch: 7600, Loss: 3.163397026440566, Accuracy: 0.2080078125\n",
      "Epoch: 7700, Loss: 3.0607693109772534, Accuracy: 0.259765625\n",
      "Epoch: 7800, Loss: 3.074984607987577, Accuracy: 0.2392578125\n",
      "Epoch: 7900, Loss: 3.0494651113041957, Accuracy: 0.2509765625\n",
      "Epoch: 8000, Loss: 3.0230035426822566, Accuracy: 0.2548828125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 8000, Momentum: False\n",
      "Val Loss: 3.039296487734884, Val Accuracy: 0.25433333333333336\n",
      "-----------\n",
      "Epoch: 8100, Loss: 3.0193855775624225, Accuracy: 0.2509765625\n",
      "Epoch: 8200, Loss: 3.035678298759555, Accuracy: 0.265625\n",
      "Epoch: 8300, Loss: 2.965376457904354, Accuracy: 0.263671875\n",
      "Epoch: 8400, Loss: 3.012650259548569, Accuracy: 0.26171875\n",
      "Epoch: 8500, Loss: 2.9928892802000955, Accuracy: 0.265625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 8500, Momentum: False\n",
      "Val Loss: 2.9960869186340684, Val Accuracy: 0.2619666666666667\n",
      "-----------\n",
      "Epoch: 8600, Loss: 2.968419888841152, Accuracy: 0.2529296875\n",
      "Epoch: 8700, Loss: 2.963910287528795, Accuracy: 0.2626953125\n",
      "Epoch: 8800, Loss: 2.8703640148803267, Accuracy: 0.2763671875\n",
      "Epoch: 8900, Loss: 2.9690353516911694, Accuracy: 0.2626953125\n",
      "Epoch: 9000, Loss: 2.986333945007895, Accuracy: 0.2783203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 9000, Momentum: False\n",
      "Val Loss: 2.9579018723868606, Val Accuracy: 0.2682\n",
      "-----------\n",
      "Epoch: 9100, Loss: 3.079783460942494, Accuracy: 0.2431640625\n",
      "Epoch: 9200, Loss: 3.0276872916446584, Accuracy: 0.2646484375\n",
      "Epoch: 9300, Loss: 2.953060734078294, Accuracy: 0.2587890625\n",
      "Epoch: 9400, Loss: 2.9171633620192376, Accuracy: 0.2734375\n",
      "Epoch: 9500, Loss: 2.9328827820960734, Accuracy: 0.2958984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 9500, Momentum: False\n",
      "Val Loss: 2.922150242861046, Val Accuracy: 0.27713333333333334\n",
      "-----------\n",
      "Epoch: 9600, Loss: 2.9133207308610785, Accuracy: 0.294921875\n",
      "Epoch: 9700, Loss: 2.8620232092905473, Accuracy: 0.26953125\n",
      "Epoch: 9800, Loss: 2.8100310536396815, Accuracy: 0.2939453125\n",
      "Epoch: 9900, Loss: 2.8040845442817433, Accuracy: 0.275390625\n",
      "Epoch: 10000, Loss: 2.938660739338739, Accuracy: 0.2822265625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 10000, Momentum: False\n",
      "Val Loss: 2.8886170857516946, Val Accuracy: 0.2835\n",
      "-----------\n",
      "Epoch: 10100, Loss: 2.84444969594289, Accuracy: 0.30078125\n",
      "Epoch: 10200, Loss: 2.778265468898594, Accuracy: 0.3154296875\n",
      "Epoch: 10300, Loss: 2.9083257561751696, Accuracy: 0.25\n",
      "Epoch: 10400, Loss: 2.7940945359194993, Accuracy: 0.287109375\n",
      "Epoch: 10500, Loss: 2.826040191647111, Accuracy: 0.3076171875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 10500, Momentum: False\n",
      "Val Loss: 2.8563925229917513, Val Accuracy: 0.2910333333333333\n",
      "-----------\n",
      "Epoch: 10600, Loss: 2.754983615630607, Accuracy: 0.30078125\n",
      "Epoch: 10700, Loss: 2.8108469207590794, Accuracy: 0.287109375\n",
      "Epoch: 10800, Loss: 2.886125277858573, Accuracy: 0.3095703125\n",
      "Epoch: 10900, Loss: 2.873241215412003, Accuracy: 0.28515625\n",
      "Epoch: 11000, Loss: 2.8240714063406975, Accuracy: 0.3056640625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 11000, Momentum: False\n",
      "Val Loss: 2.8262521315438582, Val Accuracy: 0.29563333333333336\n",
      "-----------\n",
      "Epoch: 11100, Loss: 2.7536395022533675, Accuracy: 0.3125\n",
      "Epoch: 11200, Loss: 2.82217748742901, Accuracy: 0.291015625\n",
      "Epoch: 11300, Loss: 2.842756996518874, Accuracy: 0.2890625\n",
      "Epoch: 11400, Loss: 2.792562293524185, Accuracy: 0.2900390625\n",
      "Epoch: 11500, Loss: 2.6335397108469283, Accuracy: 0.3427734375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 11500, Momentum: False\n",
      "Val Loss: 2.7989498535044928, Val Accuracy: 0.3014\n",
      "-----------\n",
      "Epoch: 11600, Loss: 2.7188497111294128, Accuracy: 0.30859375\n",
      "Epoch: 11700, Loss: 2.7975252477871106, Accuracy: 0.298828125\n",
      "Epoch: 11800, Loss: 2.7404741981121177, Accuracy: 0.326171875\n",
      "Epoch: 11900, Loss: 2.765707009041826, Accuracy: 0.3076171875\n",
      "Epoch: 12000, Loss: 2.704786917717523, Accuracy: 0.2890625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 12000, Momentum: False\n",
      "Val Loss: 2.7709029622077237, Val Accuracy: 0.3090333333333333\n",
      "-----------\n",
      "Epoch: 12100, Loss: 2.7942445222046715, Accuracy: 0.2880859375\n",
      "Epoch: 12200, Loss: 2.7824647055537963, Accuracy: 0.2958984375\n",
      "Epoch: 12300, Loss: 2.711888096421788, Accuracy: 0.306640625\n",
      "Epoch: 12400, Loss: 2.735973803608477, Accuracy: 0.306640625\n",
      "Epoch: 12500, Loss: 2.637237849291905, Accuracy: 0.3232421875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 12500, Momentum: False\n",
      "Val Loss: 2.746152448192413, Val Accuracy: 0.3126333333333333\n",
      "-----------\n",
      "Epoch: 12600, Loss: 2.6783535851028746, Accuracy: 0.337890625\n",
      "Epoch: 12700, Loss: 2.7266046757698668, Accuracy: 0.3193359375\n",
      "Epoch: 12800, Loss: 2.708303143833307, Accuracy: 0.3212890625\n",
      "Epoch: 12900, Loss: 2.652759009325476, Accuracy: 0.3095703125\n",
      "Epoch: 13000, Loss: 2.7222957844985194, Accuracy: 0.3203125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 13000, Momentum: False\n",
      "Val Loss: 2.721794993963364, Val Accuracy: 0.3179\n",
      "-----------\n",
      "Epoch: 13100, Loss: 2.699352671292578, Accuracy: 0.3359375\n",
      "Epoch: 13200, Loss: 2.6028444164616884, Accuracy: 0.33984375\n",
      "Epoch: 13300, Loss: 2.6666802611756317, Accuracy: 0.326171875\n",
      "Epoch: 13400, Loss: 2.6845300944106416, Accuracy: 0.326171875\n",
      "Epoch: 13500, Loss: 2.683582146179293, Accuracy: 0.330078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 13500, Momentum: False\n",
      "Val Loss: 2.6988822313354137, Val Accuracy: 0.3228666666666667\n",
      "-----------\n",
      "Epoch: 13600, Loss: 2.78353311610679, Accuracy: 0.296875\n",
      "Epoch: 13700, Loss: 2.6669671723548953, Accuracy: 0.3369140625\n",
      "Epoch: 13800, Loss: 2.666575511194203, Accuracy: 0.3447265625\n",
      "Epoch: 13900, Loss: 2.740196097063751, Accuracy: 0.3271484375\n",
      "Epoch: 14000, Loss: 2.648492914003871, Accuracy: 0.3271484375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 14000, Momentum: False\n",
      "Val Loss: 2.676401071449925, Val Accuracy: 0.3275666666666667\n",
      "-----------\n",
      "Epoch: 14100, Loss: 2.604580899970463, Accuracy: 0.3388671875\n",
      "Epoch: 14200, Loss: 2.682882515150992, Accuracy: 0.31640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14300, Loss: 2.554076883948785, Accuracy: 0.3505859375\n",
      "Epoch: 14400, Loss: 2.643257867324585, Accuracy: 0.3291015625\n",
      "Epoch: 14500, Loss: 2.4944621943673244, Accuracy: 0.3525390625\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 14500, Momentum: False\n",
      "Val Loss: 2.656379912362569, Val Accuracy: 0.33193333333333336\n",
      "-----------\n",
      "Epoch: 14600, Loss: 2.6384025078667395, Accuracy: 0.3359375\n",
      "Epoch: 14700, Loss: 2.675901497722111, Accuracy: 0.330078125\n",
      "Epoch: 14800, Loss: 2.511530522299492, Accuracy: 0.365234375\n",
      "Epoch: 14900, Loss: 2.5939397992919617, Accuracy: 0.34765625\n",
      "Epoch: 15000, Loss: 2.5731438322757305, Accuracy: 0.345703125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 15000, Momentum: False\n",
      "Val Loss: 2.636828579272211, Val Accuracy: 0.3352333333333333\n",
      "-----------\n",
      "Epoch: 15100, Loss: 2.616666004994751, Accuracy: 0.33203125\n",
      "Epoch: 15200, Loss: 2.556148863328634, Accuracy: 0.36328125\n",
      "Epoch: 15300, Loss: 2.52156600845985, Accuracy: 0.353515625\n",
      "Epoch: 15400, Loss: 2.576658673192507, Accuracy: 0.3603515625\n",
      "Epoch: 15500, Loss: 2.4856828728536664, Accuracy: 0.357421875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 15500, Momentum: False\n",
      "Val Loss: 2.617617983467474, Val Accuracy: 0.3384\n",
      "-----------\n",
      "Epoch: 15600, Loss: 2.5992840272393947, Accuracy: 0.341796875\n",
      "Epoch: 15700, Loss: 2.5636677009243156, Accuracy: 0.337890625\n",
      "Epoch: 15800, Loss: 2.679023438897203, Accuracy: 0.3349609375\n",
      "Epoch: 15900, Loss: 2.611090652703573, Accuracy: 0.333984375\n",
      "Epoch: 16000, Loss: 2.4677821315386868, Accuracy: 0.35546875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 16000, Momentum: False\n",
      "Val Loss: 2.599085496082535, Val Accuracy: 0.34236666666666665\n",
      "-----------\n",
      "Epoch: 16100, Loss: 2.5824406820210752, Accuracy: 0.3447265625\n",
      "Epoch: 16200, Loss: 2.5760398538403004, Accuracy: 0.3515625\n",
      "Epoch: 16300, Loss: 2.5992677537296798, Accuracy: 0.349609375\n",
      "Epoch: 16400, Loss: 2.5493972116431207, Accuracy: 0.361328125\n",
      "Epoch: 16500, Loss: 2.600978282690573, Accuracy: 0.3330078125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 16500, Momentum: False\n",
      "Val Loss: 2.5822366043986538, Val Accuracy: 0.3463333333333333\n",
      "-----------\n",
      "Epoch: 16600, Loss: 2.571815343897497, Accuracy: 0.35546875\n",
      "Epoch: 16700, Loss: 2.6283004538207817, Accuracy: 0.30859375\n",
      "Epoch: 16800, Loss: 2.5466967252460764, Accuracy: 0.3505859375\n",
      "Epoch: 16900, Loss: 2.596893132368331, Accuracy: 0.3369140625\n",
      "Epoch: 17000, Loss: 2.5187524593010755, Accuracy: 0.33984375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 17000, Momentum: False\n",
      "Val Loss: 2.5668205412915377, Val Accuracy: 0.3496666666666667\n",
      "-----------\n",
      "Epoch: 17100, Loss: 2.523130158150498, Accuracy: 0.365234375\n",
      "Epoch: 17200, Loss: 2.5995107836525055, Accuracy: 0.34375\n",
      "Epoch: 17300, Loss: 2.5999627182625416, Accuracy: 0.3408203125\n",
      "Epoch: 17400, Loss: 2.520399773529954, Accuracy: 0.365234375\n",
      "Epoch: 17500, Loss: 2.4903809122302527, Accuracy: 0.3623046875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 17500, Momentum: False\n",
      "Val Loss: 2.5490972111316057, Val Accuracy: 0.3531\n",
      "-----------\n",
      "Epoch: 17600, Loss: 2.6684394880269657, Accuracy: 0.330078125\n",
      "Epoch: 17700, Loss: 2.5206027848953, Accuracy: 0.3447265625\n",
      "Epoch: 17800, Loss: 2.4595433548097776, Accuracy: 0.3720703125\n",
      "Epoch: 17900, Loss: 2.463280908073216, Accuracy: 0.3623046875\n",
      "Epoch: 18000, Loss: 2.487195641422164, Accuracy: 0.365234375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 18000, Momentum: False\n",
      "Val Loss: 2.5339327593577914, Val Accuracy: 0.35633333333333334\n",
      "-----------\n",
      "Epoch: 18100, Loss: 2.473899634780787, Accuracy: 0.359375\n",
      "Epoch: 18200, Loss: 2.411368922192257, Accuracy: 0.404296875\n",
      "Epoch: 18300, Loss: 2.564828615318361, Accuracy: 0.3408203125\n",
      "Epoch: 18400, Loss: 2.5549189227121443, Accuracy: 0.3603515625\n",
      "Epoch: 18500, Loss: 2.442966134346098, Accuracy: 0.3662109375\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 18500, Momentum: False\n",
      "Val Loss: 2.518357605269688, Val Accuracy: 0.3594\n",
      "-----------\n",
      "Epoch: 18600, Loss: 2.4457401534014602, Accuracy: 0.37890625\n",
      "Epoch: 18700, Loss: 2.4865639335056917, Accuracy: 0.380859375\n",
      "Epoch: 18800, Loss: 2.4824951725450193, Accuracy: 0.3681640625\n",
      "Epoch: 18900, Loss: 2.4487641558505615, Accuracy: 0.384765625\n",
      "Epoch: 19000, Loss: 2.454904555111632, Accuracy: 0.361328125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 19000, Momentum: False\n",
      "Val Loss: 2.505793401904703, Val Accuracy: 0.3631\n",
      "-----------\n",
      "Epoch: 19100, Loss: 2.4935811221062236, Accuracy: 0.3583984375\n",
      "Epoch: 19200, Loss: 2.4777928502373463, Accuracy: 0.3662109375\n",
      "Epoch: 19300, Loss: 2.4248789734840175, Accuracy: 0.4033203125\n",
      "Epoch: 19400, Loss: 2.4425092791657486, Accuracy: 0.3798828125\n",
      "Epoch: 19500, Loss: 2.494590050594786, Accuracy: 0.3544921875\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 19500, Momentum: False\n",
      "Val Loss: 2.4914350552112476, Val Accuracy: 0.36646666666666666\n",
      "-----------\n",
      "Epoch: 19600, Loss: 2.4126546615240145, Accuracy: 0.37890625\n",
      "Epoch: 19700, Loss: 2.413875768914896, Accuracy: 0.3779296875\n",
      "Epoch: 19800, Loss: 2.43836099621372, Accuracy: 0.3681640625\n",
      "Epoch: 19900, Loss: 2.4216741951358203, Accuracy: 0.3642578125\n",
      "-----------\n",
      "Learning Rate: 0.01, Reg: 1e-05, Num Epoch: 19500, Momentum: False\n",
      "Test Loss: 2.506363615441279, Test Accuracy: 0.36145364862904394\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Options\n",
    "\n",
    "#My Hyperparameters are:\n",
    "\n",
    "# 0  : lr = 1e-1, reg = 1e-3, momentum = True\n",
    "# 1  : lr = 1e-1, reg = 1e-3, momentum = False\n",
    "# 2  : lr = 1e-1, reg = 1e-5, momentum = True\n",
    "# 3  : lr = 1e-1, reg = 1e-5, momentum = False\n",
    "# 4  : lr = 5e-2, reg = 1e-3, momentum = True\n",
    "# 5  : lr = 5e-2, reg = 1e-3, momentum = False\n",
    "# 6  : lr = 5e-2, reg = 1e-5, momentum = True\n",
    "# 7  : lr = 5e-2, reg = 1e-5, momentum = False\n",
    "# 8  : lr = 1e-2, reg = 1e-3, momentum = True\n",
    "# 9  : lr = 1e-2, reg = 1e-3, momentum = False\n",
    "# 10 : lr = 1e-2, reg = 1e-5, momentum = True\n",
    "# 11 : lr = 1e-2, reg = 1e-5, momentum = False\n",
    "\n",
    "#Number of epoches 20000\n",
    "\n",
    "n_epochs = 20000\n",
    "print_every = 100\n",
    "test_every = 500\n",
    "\n",
    "lrs = [1e-1, 5e-2, 1e-2]\n",
    "rss = [1e-3, 1e-5]\n",
    "momentum = [True, False]\n",
    "\n",
    "\n",
    "grid_search = []\n",
    "train_accss = []\n",
    "val_accss = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_models = []\n",
    "best_test = -1\n",
    "\n",
    "\n",
    "for lr in lrs:\n",
    "    for rs in rss:\n",
    "        for m in momentum:            \n",
    "            grid_search.append((lr, rs, m))\n",
    "\n",
    "\n",
    "for config in grid_search:   # Try for every config\n",
    "    \n",
    "    model = layer.Model() # Create a model instance\n",
    " \n",
    "    layers = [layer.AffineLayer(2500,512), layer.ReLU(), \n",
    "              layer.AffineLayer(512,32), layer.Softmax()]\n",
    "\n",
    "    model(layers) # Load layers to model object\n",
    "        \n",
    "    lr, rs, momentum = config\n",
    "          \n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    best_val = -1\n",
    "    \n",
    "    if(momentum):  #Check config for Which optimizer to use\n",
    "        optimizer = layer.SGDWithMomentum(model, lr=lr, regularization_str=rs)\n",
    "    else:\n",
    "        optimizer = layer.VanillaSDGOptimizer(model, lr=lr, regularization_str=rs)\n",
    "    \n",
    "    for epoch in range(n_epochs):   #train all config parameters\n",
    "\n",
    "        samples = np.random.choice(x_train.shape[0], size=m_batch)  #mini batch size samples are selected\n",
    "\n",
    "        x = x_train[samples,:]\n",
    "        y = y_train[samples]\n",
    "        \n",
    "        softmax_out = model.forward(x)                  #forward of all layers are executed and final layer gives probs mtrx.\n",
    "        predictions = np.argmax(softmax_out, axis=1)    #Highest prob will be our predicted result\n",
    "        train_acc = np.mean(predictions == y)           #Compare with correct class avg them, get accuracy\n",
    "        loss = layer.loss(softmax_out, y)               #Calculate loss\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss, train_acc))\n",
    "\n",
    "        model.backward(y)                               #Calculate derivatives\n",
    "        optimizer.optimize()                            #Update weights and biases\n",
    "        \n",
    "        if epoch % test_every == 0:\n",
    "            softmax_out = model.forward(x_val)             #execute model for the validation data but no update\n",
    "            predictions = np.argmax(softmax_out, axis=1)\n",
    "            loss = layer.loss(softmax_out, y_val)\n",
    "            val_acc = np.mean(predictions == y_val)\n",
    "            \n",
    "            if val_acc > best_val: \n",
    "                best_val = val_acc\n",
    "                best_model = model\n",
    "                best_config = (epoch, lr, rs, momentum)\n",
    "\n",
    "            for i in range(test_every):            \n",
    "                val_loss.append(loss)\n",
    "                val_accs.append(val_acc)\n",
    "                \n",
    "            print(\"-----------\")\n",
    "            print(\"Learning Rate: {}, Reg: {}, Num Epoch: {}, Momentum: {}\".format(lr, rs, epoch, momentum))\n",
    "            print(\"Val Loss: {}, Val Accuracy: {}\".format(loss, val_acc))   \n",
    "            print(\"-----------\")\n",
    "        \n",
    "    train_accss.append(train_accs)              #Log accuracies and losses\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    val_losses.append(val_loss)\n",
    "    val_accss.append(val_accs)\n",
    "    \n",
    "    best_models.append(best_model)\n",
    "    \n",
    "    \n",
    "    softmax_out = best_model.forward(x_test)                # Test the trained model with test data \n",
    "    predictions = np.argmax(softmax_out, axis=1)\n",
    "    loss = layer.loss(softmax_out, y_test)\n",
    "    test_acc = np.mean(predictions == y_test)\n",
    "\n",
    "    print(\"-----------\")\n",
    "    print(\"Learning Rate: {}, Reg: {}, Num Epoch: {}, Momentum: {}\".format(lr, rs, best_config[0], momentum))\n",
    "    print(\"Test Loss: {}, Test Accuracy: {}\".format(loss, test_acc))      \n",
    "    print(\"-----------\")\n",
    "    \n",
    "    if test_acc > best_test: \n",
    "        best_test = test_acc\n",
    "        best_of_all_models = best_model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Plot the training and validation losses versus number of iterations, as you vary the regularization parameter lambda with different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0  : lr = 1e-1, reg = 1e-3, momentum = True\n",
    "# 1  : lr = 1e-1, reg = 1e-3, momentum = False\n",
    "# 2  : lr = 1e-1, reg = 1e-5, momentum = True\n",
    "# 3  : lr = 1e-1, reg = 1e-5, momentum = False\n",
    "# 4  : lr = 5e-2, reg = 1e-3, momentum = True\n",
    "# 5  : lr = 5e-2, reg = 1e-3, momentum = False\n",
    "# 6  : lr = 5e-2, reg = 1e-5, momentum = True\n",
    "# 7  : lr = 5e-2, reg = 1e-5, momentum = False\n",
    "# 8  : lr = 1e-2, reg = 1e-3, momentum = True\n",
    "# 9  : lr = 1e-2, reg = 1e-3, momentum = False\n",
    "# 10 : lr = 1e-2, reg = 1e-5, momentum = True\n",
    "# 11 : lr = 1e-2, reg = 1e-5, momentum = False\n",
    "\n",
    "#Rss : 1e-3, 1e-5\n",
    "\n",
    "plt.plot(train_losses[0])\n",
    "plt.plot(train_losses[2])\n",
    "plt.title('training loss curve')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1e-3', '1e-5'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(val_losses[0])\n",
    "plt.plot(val_losses[2])\n",
    "plt.title('Validation loss curve')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1e-3', '1e-5'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Plot the training and validation losses as you vary the Learning Parameter alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lrs : 1e-1, 5e-2, 1e-2\n",
    "\n",
    "plt.plot(train_losses[0])\n",
    "plt.plot(train_losses[4])\n",
    "plt.plot(train_losses[8])\n",
    "plt.title('training loss curve')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1e-1', '5e-2', '1e-2'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(val_losses[0])\n",
    "plt.plot(val_losses[4])\n",
    "plt.plot(val_losses[8])\n",
    "plt.title('Validation loss curve')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1e-1', '5e-2', '1e-2'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use two different optimizers: Mini-batch SGD and Mini-batch SGD with Momentum, and plot training and validation losses versus Iteration numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Momentum : SGDWithMomentum, VanillaSDGOptimizer\n",
    "\n",
    "plt.plot(train_losses[0])\n",
    "plt.plot(train_losses[1])\n",
    "plt.title('training loss curve')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['SGDWithMomentum', 'VanillaSDGOptimizer'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(val_losses[0])\n",
    "plt.plot(val_losses[1])\n",
    "plt.title('Validation loss curve')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['SGDWithMomentum', 'VanillaSDGOptimizer'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Finally, fix your model and hyperparameters according to your observations above. Plot accuracy of your classification for training and validation sets, and print your test accuracy. Remember that the test accuracy shoud be at least 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zU9f3A8dc7l0ECCXuvsPcOSxRB0B9DcFHFPaoURx2ttai12lJb664T0eKqGxVREQQFQdlLBGQbJIwQAiQhkHmf3x/fby53ucvlArlckns/Hw/07rvunQt839/PFmMMSimlwldEqANQSikVWpoIlFIqzGkiUEqpMKeJQCmlwpwmAqWUCnOaCJRSKsxpIlBhRUTeEJF/BHhssoiMDnZMSoWaJgKllApzmgiUqoZEJDLUMaiaQxOBqnLsKpk/icgmEckWkf+KSFMR+UpEskRkkYjUdzt+oohsEZHjIrJERLq57esnIuvt8z4AapX4rAtFZKN97nIR6R1gjONFZIOIZIrIPhF5pMT+s+3rHbf332BvjxWRp0Rkr4hkiMj39rYRIpLi43sYbb9+RERmi8j/RCQTuEFEBonICvszDorICyIS7XZ+DxFZKCJHRSRVRB4QkWYiclJEGrodN0BE0kQkKpCfXdU8mghUVXUZcD7QGZgAfAU8ADTC+nt7J4CIdAbeA+4GGgPzgM9FJNq+Kc4B3gYaAB/Z18U+tz8wC/gd0BB4BZgrIjEBxJcNXAfUA8YDt4rIxfZ129jxPm/H1BfYaJ/3JDAAOMuO6T7AGeB3chEw2/7Md4BC4B77OxkKjAJus2OIBxYB84EWQEfgG2PMIWAJcLnbda8B3jfG5AcYh6phNBGoqup5Y0yqMWY/sAxYZYzZYIzJBT4F+tnHXQF8aYxZaN/IngRisW60Q4Ao4FljTL4xZjawxu0zbgFeMcasMsYUGmPeBHLt8/wyxiwxxvxkjHEaYzZhJaNz7d1XA4uMMe/Zn5tujNkoIhHATcBdxpj99mcut3+mQKwwxsyxP/OUMWadMWalMabAGJOMlciKYrgQOGSMecoYk2OMyTLGrLL3vYl180dEHMCVWMlShSlNBKqqSnV7fcrH+zr26xbA3qIdxhgnsA9oae/bbzxnVtzr9rot8Ee7auW4iBwHWtvn+SUig0VksV2lkgFMxXoyx77Gbh+nNcKqmvK1LxD7SsTQWUS+EJFDdnXRPwOIAeAzoLuItMcqdWUYY1afZkyqBtBEoKq7A1g3dABERLBugvuBg0BLe1uRNm6v9wGPGmPquf2JM8a8F8DnvgvMBVobY+oCM4Ciz9kHdPBxzhEgp5R92UCc28/hwKpWcldyquCXgW1AJ2NMAlbVWVkxYIzJAT7EKrlci5YGwp4mAlXdfQiMF5FRdmPnH7Gqd5YDK4AC4E4RiRSRS4FBbue+Cky1n+5FRGrbjcDxAXxuPHDUGJMjIoOAq9z2vQOMFpHL7c9tKCJ97dLKLOBpEWkhIg4RGWq3SewAatmfHwX8BSirrSIeyAROiEhX4Fa3fV8AzUTkbhGJEZF4ERnstv8t4AZgIvC/AH5eVYNpIlDVmjFmO1Z99/NYT9wTgAnGmDxjTB5wKdYN7xhWe8InbueuxWoneMHev8s+NhC3AX8XkSzgr1gJqei6vwLjsJLSUayG4j727nuBn7DaKo4C/wYijDEZ9jVfwyrNZAMevYh8uBcrAWVhJbUP3GLIwqr2mQAcAnYCI932/4DVSL3ebl9QYUx0YRqlwpOIfAu8a4x5LdSxqNDSRKBUGBKRgcBCrDaOrFDHo0JLq4aUCjMi8ibWGIO7NQko0BKBUkqFPS0RKKVUmKt2E1c1atTIJCYmhjoMpZSqVtatW3fEGFNybApQDRNBYmIia9euDXUYSilVrYjI3tL2adWQUkqFOU0ESikV5jQRKKVUmKt2bQS+5Ofnk5KSQk5OTqhDqTFq1apFq1atiIrStUqUqulqRCJISUkhPj6exMREPCeaVKfDGEN6ejopKSm0a9cu1OEopYKsRlQN5eTk0LBhQ00CFUREaNiwoZawlAoTNSIRAJoEKph+n0qFjxqTCJRSqjIt3ZHGvqMng3LtY9l5QbluaTQRVIDjx4/z0ksvlfu8cePGcfz48SBEpJQKtutmreacxxdz7hOLyTiV7/fY3WknmL/5UEDXXb7rCP2mL+Sbn1PLPriCaCKoAKUlgsLCQr/nzZs3j3r16gUrLKWqvPQTuRzOqt5tUXvTT7JyT7rfY0Y99R1T/7cuoOtt2Gc9HK5JPnbGsQVKE0EFmDZtGrt376Zv374MHDiQkSNHctVVV9GrVy8ALr74YgYMGECPHj2YOXOm67zExESOHDlCcnIy3bp145ZbbqFHjx5ccMEFnDp1KlQ/jlKVZsA/FjHo0W/8HnMoIydoVTB707N5/pud+JqF+aufDvLttuA/lc/ffIjEaV+6ShVFzXPGXqL6aHYeS3ekcTAjePeEoHYfFZExwH8AB/CaMeYxH8eMAJ4FooAjxphzz+Qz//b5FrYeyDyTS3jp3iKBhyf0KHX/Y489xubNm9m4cSNLlixh/PjxbN682dX1ctasWTRo0IBTp04xcOBALrvsMho2bOhxjZ07d/Lee+/x6quvcvnll/Pxxx9zzTXXVOjPoVRV9fWWQ1zQo5nHtmteW0VyejYpx6wbYPJj4wGre/OSHWmM6Nz4jDs1XD9rNcnpJ7l8YGuaJtTy2HfrO+tdrz/83VAGtWtQ6nVOdzb/73ak8cLinQDsSTtBvzb1EVyZAIDzn/6OdLvNoOg7qGhBKxGIiAN4ERgLdAeuFJHuJY6pB7wETDTG9AB+E6x4KtOgQYM8+t8/99xz9OnThyFDhrBv3z527tzpdU67du3o27cvAAMGDCA5ObmywlU1RE5+oc8n26pgxe50UjNLrwKa8vY6jpZoIP1+1xFXEnD3wZp93Pj6GmavK31J55z8Qk7mFfjc9/aKZN5d9SsAJ/Os6ltjYN3eoyRO+5J1e496nXP5KytK/ayybErx3Q64dEca189azeb91oPrV5sPUeg0biUCS3olNBwHs0QwCNhljNkDICLvAxcBW92OuQr4xF7sG2PM4TP9UH9P7pWldu3artdLlixh0aJFrFixgri4OEaMGOGzf35MTIzrtcPh0KqhMLJ422E6NqlD6wZxp32N9BO5DPjHIu4b04XbRnSswOgsxhhueWsdVw9pw8guTXwe859FOxGBO0d18tp35asraVA7mvUPnV/qZ7yydDf3j+1WZiz7j1v/Ng5m+E4smTn59H7kawA+ue0s+rep77H/oc+2AHBxvxaubSKwdMcRwPr/gLbeT/8/H8ykW/OEUqIqPQFPfOEHj/eFTkPmqXyvxDhz6R7iYyJ5auEO64rGlJpEKlow2whaAvvc3qfY29x1BuqLyBIRWSci1/m6kIhMEZG1IrI2LS0tSOGevvj4eLKyfK/4l5GRQf369YmLi2Pbtm2sXLmykqNTVd2Nb6xh1NPfeW3/Nf0kn23cH9A1UjNzAZi78UCFxuZu0c+p3Pj6Gq/t+4+f4uN1KTyzaAdPL9xB+olcTuR6P42XfOL3J6/AWeq+mUv3+D236Gkf4H8r95Jf6OSzjfv5bkcah9ySx6o9Rz1u30VP4st3HyFx2pde1x37n2VcOXMlj8/f5vNz8wudHDju/wFu9roU/v75FvpNX+gqjbgrSgIAb6/c65VEgiWYJQJflXcl02YkMAAYBcQCK0RkpTFmh8dJxswEZgIkJSVVubJvw4YNGTZsGD179iQ2NpamTZu69o0ZM4YZM2bQu3dvunTpwpAhQ0IYqaoKfk0/Sf3aUcTXKp7HydeNb/zzy8jKKeCivsXPT/uPn6J2tIN6cdGubS98u5Mnv97h2p9xMp+6ccXXHv74Yq4/K5ELezfHESE0qlNc+qwIl89Y4XpKB6sBOD4mkmcn9+X7XUc8bszu/FVj3Tf7R69tP6VksDvtBLk+vqvN+zPYfiiLywa0YvUvxVU7n6zfz6m8Qr7y0XXzyIlc0rKsBPr4/O20sUtk/nrrrNiTzoo96Uwa0Mpj+67DJ/j9exvILzRc2q8ln2zYz6DEBsREeT5r3/tR8c/lK1m6y8n3/jmNMUEZ7BnMRJACtHZ73woo+biSgtVAnA1ki8hSoA+wg2rm3Xff9bk9JiaGr776yue+onaARo0asXnzZtf2e++9t8LjU2dm64FMWjWIJcHt5v3bN9Zw/FQ+H996VsDXOZyVw/AnFtOpSR0W/sF/v4isHO8bxbDHviW+ViQ/PfJ/rm1FSaDonBFPLmbDXy9wbfv16Emmf7GV6V9YtbJFDY7HsvNIO5FL56bx7EjNIjbKwZvLkxnWsRFHs/O4rMTNrkjitC957NJeTB7Uhpz8Qo8k4Iojt4Dfvum9gNS6vUe57OUVzLx2AKO7NfXan1/o5IkF25njo2Qz4YXvPd4/vdAqgdwzujPPLLK+g4l9W3id5ysJAPxp9ibX64/Xl97e4Mt5T3mW4Nx/B59ssEpxq5O92xrcLdle/prwj9fv90pCFSGYiWAN0ElE2gH7gclYbQLuPgNeEJFIIBoYDDwTxJiUAiDjVD47UrMYmNjA9WRa2pPW1gOZjHtuGX1a1eWzO852bf9mW/E/5FV70unWIsEjUYD1BDfyySXUrx3NJ7ee5eoqufPwiXLH/P1Oqw67KEEkH8nmjeXJXscdO+l/cFORftMXWtd5bDwXPLPUtf21738B8EgEJR/en1m0g8mD2vDApz8FHD/gauCd8vY6dj061mPf11tSeeU7/9U+vhQlAYAB0xeS6SOBVkWnM05gy4GM6pUIjDEFInIHsACr++gsY8wWEZlq759hjPlZROYDmwAnVhfTzaVfVanTs3HfcQQ4nJXL+d2b8ts31rB27zG2TR9Dz4cX0LlpPPPuOsfjnEKnIa/AybjnlgHwY0qGz2tn5uRzxcyVnNWhIe/eYlX9GWO496NNrifN5PSTtLt/nte57tUjJ/MKiIv2/U9yZ2oW1/x3let9QaGTEU8u8fsz/2fRToZ1bOi1feuBTNo1qu3jDE+7Dp8g5dhJ+retT50ScRW1SWze7/s7Kc17q4ubDTs+6FlS/uVIdrmu5Ut1SQKn65SPdoWKENRxBMaYecC8EttmlHj/BPBEMONQ4S3jVD4Xv1jc6LbsvpFssceaFDoNBU7D1oPeY0/+Mmcz7632Xb/trqiB8Ge3a2Scyi+zuuHpr7eTEFtcguj+1wUs/dNI2jSM86o/L9nQ+sTX2/1eu9BpeGbRDp5Z5L2vKLEV+dvnW3xeY7RbA/aYEn38AT7/8QA7UstfslGnL6uMdoXTpSOLVY3X529fe7zPLSj06qsNVlXL0ew81whPX0lg+hdbvfqnF/VEcb+Wr3rzkp77dhdf/nTQY9vq5KNc/soK+v59oWtbTn4hU972nJ6grCqUAf9Y6He/u9d/SC7zmPlbvOvZf//ehoA/Q1WMRVuDM9K5RixMo1T5uMZu8pTbk7V7VUtpIzj/+/0vFDoNj0wsHq8yy76RHj+ZT5e/fMXS+0Yy/rnvfZ5f0oZfPfuJu/cqKdL1ofkBXcvd8QDbCVT14qvHVEXQEoGqFn45ku3RB9wfYwwr96RjjGH9r94NchEC2XZda2lPw0/7qXrJzMn3mMZk6Y7isS25BU6mvOXdW0apqkwTQQjUqVMHgAMHDjBp0iSfx4wYMYK1a/3fUJ599llOniyejKs6TWu9O+0EidO+5LsdZQ8QLOp5M+Rf3pOTFTqN1/v3Vu9j8syVvLJ0D5e+tNzrnED6YT/37a5S9y3ZnuZVz+6utEZlpaoqTQQh1KJFC2bPnn3a55dMBNVhWuuc/ELyC518/qPVT/ztFXvJyfffE6K0uugf9x2nwwPzWGDXX3+0dh8dHpjn6tJYWo+WeSXq5curPCNklaoONBFUgD//+c8e6xE88sgj/O1vf2PUqFH079+fXr168dlnn3mdl5ycTM+ePQE4deoUkydPpnfv3lxxxRUecw3deuutJCUl0aNHDx5++GHAmsjuwIEDjBw5kpEjRwLF01oDPP300/Ts2ZOePXvy7LPPuj4v1NNdd31oPpe9vJxnF1kT7y36ObXMOvAvNvm+cReNIP2d3ZDqPkAISp/95YkF/nvcKBVual5j8VfT4FD5BrmUqVkvGOs1g7bL5MmTufvuu7ntttsA+PDDD5k/fz733HMPCQkJHDlyhCFDhjBx4sRSqyVefvll4uLi2LRpE5s2baJ///6ufY8++igNGjSgsLCQUaNGsWnTJu68806efvppFi9eTKNGjTyutW7dOl5//XVWrVqFMYbBgwdz7rnnUr9+fXbu3MnM19/iuRdf5vprrqqU6a5z8gt5Y3kyN59tzci66QyqTv7w4UYSakVxx3kdycwpbhD9yxzv3/mXpSQQpZSnmpcIQqBfv34cPnyYAwcOkJaWRv369WnevDn33HMPS5cuJSIigv3795OamkqzZt79sQGWLl3KnXfeCUDv3r3p3bu3a9+HH37IzJkzKSgo4ODBg2zdutVjf0nff/89l1xyiWsW1EsvvZRly5YxceJE2rVrR91Wndh5+ESlTXf98pLd/OebnRQUlt3j4cbXV7N4u9VucOWg1kw9t4PH/k/WW8P3S46o/d/Ksvv7K6V8q3mJwM+TezBNmjSJ2bNnc+jQISZPnsw777xDWloa69atIyoqisTERJ/TT7vzVVr45ZdfePLJJ1mzZg3169fnhhtuKPM6/ibzCsV019n2IBj3+Vh82XX4hCsJgDUK1X0kqlIqOLSNoIJMnjyZ999/n9mzZzNp0iQyMjJo0qQJUVFRLF68mL179/o9f/jw4bzzzjsAbN68mU2brPruzMxMateuTd26dUlNTfWYwK606a+HDx/OnDlzOHnyJNnZ2Xz66aecc845XseVVOg07Dt6MqAn9083pPDhWt836b3p2Ww5YFX/5BYUuuau8Se3oNBjJKtSqvLUvBJBiPTo0YOsrCxatmxJ8+bNufrqq5kwYQJJSUn07duXrl27+j3/1ltv5cYbb6R379707duXQYMGAdCnTx/69etHjx49aN++PcOGDXOdM2XKFMaOHUvz5s1ZvHixa3v//v254YYbXNe4+eab6devX5nVQEez8zh2Mg9HhFDgNOTmF5KamcPWg5mM7NIEYwyZOQXUjY3ing+sgU+XJ7Vm/a/HqBMTSeem8QCc+8QSAN69ZTBXvbqqtI/zcHWAxymlKp5U1aXtSpOUlGRK9q//+eef6dat7JWNlKVo1aPerTy7mqZl5XIw4xSN6sRw5EQuqb/u4Za5xQ2uUQ4hv9Cw8J7hnG/PVvnqdUncYg+g6tkyge7NE/hwbfmm9FVKBebaIW2ZfnHP0zpXRNYZY5J87dMSQRjLzi2gdoz3X4EjJ3J9Hp9faD00nO82ZfEtbqNoN+/PdK2/qpSqeH+d0L3sg06DthGEsd1pJyhwOtmUcpxdh0+QH0DbgFIqdKIcwbll15gSQbCWcKvpUjOsp/+TeQUes2oaYzB+FuRWStUcNaJEUKtWLdLT0/12m1SQeSqf1EzPrqclp1QGKwkUnMxk73GdwVKpcFAjSgStWrUiJSWFtLSyJzALVwVOJ4cyfNf9l2Qw7D2ez/Oryr+UnlKq/BrViebICc85rB4Y15V/zttWKZ9fIxJBVFQU7dq1C3UYle5Ydh7RkRF8vD6F5bvSmXHtAAAe+2obM77bzcQ+LVibfJRv7x1xWnPaK1VdTezTgrn2xIaBGNerGfN+8r3IfbBMGd6emUv38M9LetEkPoabS0xf7l7Bcd+YLozq2jRosdSIqqGa4Fh2Hoczy55v//UffmH444t5/pud9Ju+kHOfWMJfP9visYLUjO92AzD3xwMcyMjh/QCWW1SqqujePOGMr/Hclf3KdfxLVw+gR4vT/9xHL/Hu0vnadcU9NZ++vI/r9ehuTQBIaluf5MfGc9XgNozu3pTkx8Yz/+5zuGmY9VDrXtF924iOdGkWf9rxlaVGlAhqgn7TraUFS1sZq8jfPt8KwFMLreka3Lt6bj2QSduGcV7nPGKfo1RlSuAEZ0dsprQuHAVEsNTZm1PUAuDt3w7i4c+28MjEHlz+ygq/144mn1ZiVQUPad+QB8Z1ZeILxetSs/0r/tFhK2vsGWrdtZHDtI04DEDvVnXp0LgOzPmSu0+kciwyH0eEUOg0GLfI3W/KJbe3rB/HuamNkEhrpH2qqU/jJk0ZnbmPGxzWetCX5u3jJ8dmWsoRLolpwNK4NM7dsQD2uD2Lp26m68FNPOA0/DnG4Fgi3Bhjf/J0+7izfg+jHvL73ZyOGjGgrCZInPYlUHYiKDquND1bJmhf/jATgZO2koqU0ssrHwf7TBMo9ZYMe/45jqteW8nKPd43ztM1LfJdpkZ+4feYQiP84LSepod3buzavnl/Bj+dSOBvzpuoXzuGm89pz6N2ffldozoyZtuDdEn3XqioPFJMI5om1CIqwvpesnLyyczJJyYygryC4jUyBEioFUlmTgGCIcoRQUKtSBz21ykiCIYjJ3KpY7KpJWV0sqhVDxzRvvdFRHKiyyUs2JLK2J7N+d+qvRQ6DbcWTb6YeDZ0Ov+0fl4dUFYDOJ2GfGfZ/fw1CYSf+yI/YGrk536PWeXsysLCAXaqEAyC0/6/ASLWHmDMyWQ6OrLtbULbRnUYYjaRfSyVJgkxHM60Sp8N60STfiIPh1gJKAbfN744ckgxjbgh7z4A3rhxEDe8vhqAf1/Wm347X0BOHKLOPntVvdziebN65qyjZyRcyWLIB76F39aydxY9+LcaCIOnus75+WAmLy/ZTZP4GP5ycT9o3JURT/mev+ra0QO58pweREUX3wLrGENkvpN7P/qRL386yOOTenOfvcbFUxP78Ed7PenSHtZq5xVy2zvrmD6mJS3rxgKw8/AJCp2Grs3i6fP3heQTydZHLvN5visO4LILrdcXDjvFvqMnoX1Dv+ecKU0E1cT457/n54N6k6+6DA9HvkUbsaoc3J/OPV/jcztAimnMTtPS68r15ATXN9jKvuO+e321lcMUJrTmniMXee0TnPwn+iUGR2xjcISfHijz4AaAKLdt9rIReREOTtXuT3qWNVNt2/oxHM+22rN2OFsR26Q93Vs35CN7apG+revRsUkdsguc/GNDPXaZViQ/Np6UYyfZZawG3AFJQyFpKACXFpWGb3a7weZmwdpZUFD8Mz+9cDvGwF2jOxMZIdB1PDTt4drfsG0Oc7/9hovbtYBuVhvBkn91AjxL0qXdyEWE2GiH631ctINOTeqw8/AJIh1lj1GKjXYw68ZBHts6JTZwvc6gTpnXKKlFvVha1Ist93nlFdREICJjgP8ADuA1Y8xjJfaPAD4Diqan/MQY8/dgxlRdHMrIoUHtaKIjrbpBTQKh14BMBkT4nko7jhxujFxAimnEUVPcqFdaPXNRSujcLIHth7LoF1H6GskAZMIuOpNprDUmYqMcRERAdm4hGY4GJJ11NXPnFK918c0fz0WA+VsO8XbUb3ns843ERArrHhxFn799DRjaNYxjzm1DrUiMsSI0hn/O28qcDfuZNrYzl/ZtSXR8c6IjIrjCvpluu3EMV7j1Qru+TVuSJvZgp9lMZk4B10/u6xrcOX9d8Q24Zb1Y7hndmUv6eSa77/40gtgoh8c2YuJh2F0em56f/yXGwJ3Dx4KPEbZNEmox945hrskPT5f7QMrZU8/ixSW7GNerOV9vSWX/8dOftn1Yx4b8sCv9jGILlqAlAhFxAC8C5wMpwBoRmWuMKdlyucwYc2Gw4qiO8gqcDPnXNwxoW5/UzBxSjlXucpLVWX/ZwbSo93BQejVaimnMQeO7qJ1LJLMLh2N8dKi7P/IdxjtW+/38Vle/hLPhOQx/YrHf4964cSAjuli9Ry6Z9iUOCqmD5+/5d+e047aRHQHIKnTwm0e/B6wGzg9/N5RjJ/MY+q9vaRobw6oho2GOddOdfnFPqwEUq7dJTn4hD32+nQIikNh6ZGIlk+tH9UFqe65uB9CpQx6HN5ykVZuOULeB1/6SDNbT9KOX9PJ7nIhw1+hOXtvbNqxd5mcEquREikWaJsSQmpnLyC6Nfe53NyixAfN+OkRiw9rUjYvigXHWhJYvXt2/jDP9e+26gV4DOquKYJYIBgG7jDF7AETkfeAiQLuw+LHtUCZfb0kFYN1eHdDly7CIn2jCcZ/7xjpWM0B2uBogS+oZ8Qs9JNnnvqJGvrsiPy31s9c5O/HX/Bs9tp3TqRHLdh4hhyi+6XQBbfxMdfLYpb0Y1K4B7Rt7VhMU4iCDOjz1mz60qh/LlgOZ3HBWItgNmfHAivvPo1GdGNd8M2KXKkr297hmcBuP99GOCHq1rMvtI60GxwV3D+emN9a4ElFJkwa0Ykj7hrRu4N0Dzf16dWIiWbHH/xPua9cl0apBxVZtnM5EMnNuH8Yn6/czZXj7Mo+9/qxERnVrWurPf7piox0kNqq4pFeRgpkIWgLuK5ekAIN9HDdURH4EDgD3GmO2lDxARKYAUwDatGlTcneNMubZZaEOIeTqk0nPiGSf+2qTw4zoZ/2ev9PZkuvy7/faHiHg9NNJLgInYyNWEyulj8Be4+zCXuO53OgLE0dw8odf6NmiLthJYOX9o1i6M43zuzXlw7X7+NdX23h4QncmD/L++3th7+Z8Ya+vPKpbE+rFRTPYR+Ng87qeN9SifFPyRyo551ZEhPD57892ve/SLJ4fpp1X6s8oIn5vgkXXO34yj5veWOP35jq6e/AGQZVH87qx3G6XrspS1s9fEwUzEfhK3CX/zq4H2hpjTojIOGAO4FV2NMbMBGaC1X20ogOtTDn5hRzNzuOsx77l8Um9uTypdUADycLJP6JmlVkFc2feHWw0HXzuO2Lqcu8Fnb2WxrxiYGu/S186ieBL55CAYnzrpkFcN8uKsV2j2vz9Is8SSLO6tbg8qTUAN5/TntYN4hjb0/d61c9N7sfDE3qw9WAm9eJK6VboQ9H93i400L15AlsrsS2pXlw0n9w2rOwDK5hOLlnxgpkIUoDWbu9bYT31uxhjMt1ezxORl0SkkTHmSBDjCuNCTjsAAB+ISURBVKmuD82npd0L4L7Zm/jfyr20qBv8XgGVra/solOE7wVqWsthxkSswVnKwPY2cpgNzo5Mz7/G5/4cotlq2uLrWePqwW146MLu1Ipy8PoPyaRnF8/fYgy0bhDLvqOnaFA7mqPZeVzQvSnXDm3Ltf/1n3iWTzuPFvViScvKJTUzh54t6/o93p0jQhjXq3mp+yMihMbxMZwbX3b9tbvGdWK4bUQHV+Pru7cM5pcj2eW6RnlM7NOCJdsPB+36KnSCmQjWAJ1EpB2wH5gMXOV+gIg0A1KNMUZEBmFNeVE1m9UrkHvPg00pGWxKyQhhNMHxavSTNBb/T6ffFfbmJDFe238xzfik8BzWm87l/lz3BsuPpg7lPLd+5MbAsvt8V4l8fc9wFv2cSq+Wdbn2v6t5/YaBdGkWz1mPfUvzurVcXfgax8fQON475lAQEe4bU7wEar24aPq1CbxEUV7lnbZBVR9BSwTGmAIRuQNYgNV9dJYxZouITLX3zwAmAbeKSAFwCphsqttQ5zA1IWI506NeJ6KU0awJcpJXC8bxesEYn/uziCOLwOphY6MczL51KJe8uJw8e/Gc7s0TmDqiA3e+t6HU89o3rkPyY+P5/McD/P69DdSNiyr12M5N413dDov6mR8oo6vg1/cM56camMSrKsG7bllVjKCOIzDGzAPmldg2w+31C8ALwYyhKtmbHrxie2XrF7GLWPJ4p3CUz/0FOHir8AIO4N09sbzWPTSauGjPv6qjuzdlYp8WLNuRxkfr/K+RPL5Xc9JP5PpsqPUnvpb1mRf29l2t4548VPC9dPUAZi7d7WoTURVH5xqqRGXNE1TZ+ssOznX86HNfDAUMjdhS6hNYa0kjh2iG5T7vte93w9vzytI9XtsnD2zN+2tKb6wtadUDo/hx33Eu6GE1si7fdYS3V+5lVDcrCURHRlBQ6ORkfiG9H/kaKHuupvLKOJVPnZhIHHr3UdWczjVUBZzI9V4JLNTui/qAIRE/4zS+b3IRYljr7EyW8W7MPmbiS+2rf/+4brz+Q7KrGqfIo5f0YkSXJlzQvSmn8gvp8fACj/1f3zOcN5cn884qa9rsxnViXEkA4KyOjTiro2cJI9IRQUKQ1nEFqBtbenWSUjWFJoIgST+Ry7KdR4iLdpBb4OT3fuqyg8VBIYMithFDns/9zUnn68IBTMn/o9/rJLWtz9oAB7dNGtAKgMHtG7Bsp9X565ohbejQuA6OCGGM3YWydkwk943pwuPzt7vO7dw0nkcv6cWetGxW7ElHewkqVTk0EQTJ1P+tY01yaEcGj45YzyvRz/g9ZmlB71L3FVXltGkQ55UIBibWZ03yMe4f25V/fVU8mdmTv7EW4Hjq8j4MetSaJnhQu4ZM7NPC6/pTh3dgcLuGXPbyco/tr12fxP7jp7S/uFKVRBNBBXl7RTJDOzSkYxOr8fBgRugHidWTEwD8Nu+PHDG++71vM6U3oF7Qoynvr9lHn9b1+GTDfo99b940iKPZebSqH+dKBKO6Fk9Z0CS+FtcNbctbK/ZSO7rEhGK2iAhhQNv6rH5wFDGO4mNqx0SWuxH22Sv6ntEKU0qFM00EFeShz7YQHRnBjn+MBagS1Rq17Cqh9c5OHKP0m+Sf/q8LzRJqueZbL3Je16asuP88nAYenls880frBrHERUe6evLERjk4lV/IjcM8142+f2w3OjWN57yuvue0KdIkvpbf/YG4uJ/39M1KqcBoIqhAeQVlLxxTXtHk01V+LXX1qX9F/ZcE8d0tNZ6TgDUS15cm8TEczspl0oBWNC2RCKZfbDUEN68bS6HTMK5XM245pz3HT+V7rSn7/pQhvLRkF0M7eM6PExvt4NohbQP7QZVSIaOJoIIt332Eszo0Yt/Ripk6+o7IT7kzco7fY46aOnxT6HuK3GTTjFPUYsm9Ixjx5BIAujSN58Wr+1PgdPLBmn00sUfKvn7DQN5akczi7WkMcltQwxEhvHT1gFI/v0/rerxyrc9eaUqpakATQQW76tVVLLtvZIVdrwFZZJg47sq/3ef+AiJZ7exKHv67ObpPf9uxaR06NrGmQX54QvEKTyO7NmFkGdU4SqmaRxNBBSg5KO+cx/0vSlIeURSSTS2WOE9/npc/nG/N2fP8lf2sbqzVawyhUirIgjcSJ4xMeOH7oF07UgooML573fjz8a1DGdTOqt4ZaFfzFJUChnQI7kLYSqnqRUsEFWDz/uDNAR9NAfmn8WsSEdeTf1EPpm7NE1j9wKgqM3umUqpq0ERwhrJy8s/ofMHJbxzfURffPX86yv7TSwQUL8Lt3pO1ScKZd9VUStUsmgjOwI/7jnPRiz+c0TU6yX4ej3rV7zHzCwd6vO/aLJ5th7J4/LLe3PfxJsBacHt18lEArh3Slt6t6hEdadX8ReiEaUopPzQRnIEzTQJQPOjr1ry7+M7Zx+cxp9zGATwyoTs3uA3cmtCnBY8v2MblSa0Z+59ltGkQ5xoD8NRv+vLG8mQGtKl/xnEqpWouTQQhFoU1K+kJYjmJ/2qbr+46h24lBnPFRjt4eEIP16pn9WsXJ41mdWsxbWxXlFLKH+01dJoqalrpKCkE8NkO8I+LfU/z7EvLerE8eklPXr229IFfSinli5YITtNNb6ypkOsUlQjyfXQRLW/vnqsH63QOSqny00Rwmlb/cjTgY293zOFCx0qf++pgVekUUJwI2jeuzZ60bK85farCRHZKqZpHE0ElGONYTSPJYL2zk8/9G+jOdtOa6Rf1YNuhLB6Z2IMoe9Wt5MfG83/PLGV7ahbVbFVRpVQ1oYmgEkTiZL2zE7/L/4PP/V9MPZttLX2vF6CUUsGmiaCcjDGs3BN4tRBAJIUU+GmX7xlgEtCqIaVUMGivoXJ6Z9WvXPmq7/r+0jgopBDPxuCbz25XytFKKVW5gpoIRGSMiGwXkV0iMs3PcQNFpFBEJgUznjPxwZpfSZz2JX+Zs7nc50ZSSD7lnzhOKaUqQ9CqhkTEAbwInA+kAGtEZK4xZquP4/4NLAhWLBXh1WW/nPa5DnFS6PROBB/fepZrURillAqVYLYRDAJ2GWP2AIjI+8BFwNYSx/0e+BgYSBWVk1/IrsMnSt1flxNc7ljiGhNQUgInvdoIRGBA28Cmfujdqi7bU7OIr+V/8RmllDodwUwELYF9bu9TgMHuB4hIS+AS4Dz8JAIRmQJMAWjTpk2FB1qWLQcy/O4f41jDg1Hv+j1mj2kBQK+Wdflpf4Y1TXSApl/ck+uGJtKyXmzA5yilVKCCmQh83elK9oR/FvizMabQ343RGDMTmAmQlJRU6b3py1p/uKgkMDTneY7guwdQ0RQSt4/swO/f28BvBrQK+PNrRTno1Uq7lyqlgiOYiSAFaO32vhVwoMQxScD7dhJoBIwTkQJjjP/V2ivZ3R9s9Ls/AicAuUR5zRn0/pQhTJ65kvO6NuHvF/WgVf04dj7aPGixKqVUeQUzEawBOolIO2A/MBm4yv0AY4yrD6WIvAF8UdWSwJ600tsGijjsRFBYoh1g2X0jad0gjuev7Mfwzo2pG6t1/EqpqidoicAYUyAid2D1BnIAs4wxW0Rkqr1/RrA+uyK9umxPmcdE2DVexq02bHS3JrRuEAdYawYopVRVFdSRxcaYecC8Ett8JgBjzA3BjOV07T+eU+YxET5KBDcN0wFjSqnqQUcWl2HpjrQyjykqETjdSgSRDv1qlVLVg96tKkBRG4HT7escmKjLQyqlqgdNBH48+OlPAR0nrhJB8ddZnnECSikVSgElAhH5WETGi0jYJI7s3ALeWfVrQMf6aiNQSqnqItA718tYXT93ishjIlLjV0TPLXAGfKxDrGMfnhD4GsNKKVVVBJQIjDGLjDFXA/2BZGChiCwXkRtFpEZ2jg9k/EARq2pIuF57CimlqqGAu4+KSEPgGuBaYAPwDnA2cD0wIhjBhdKkGSvc3hnmRP+V9lJyYLQlIbIQjK7xo5SqngK6e4nIJ0BX4G1ggjHmoL3rAxFZG6zgqgoHTvpG7Ga9syMbSqw7PKxjQxKaJUDjLiGKTimlzkygj7EvGGO+9bXDGJNUgfFUCYczPQeRFfUKWlzYl+cLL/XY9+G5Q6Fdg0qLTSmlKlqgjcXdRKRe0RsRqS8itwUpppD740c/erwv6ghqfEyo2rZhXCVEpJRSwRNoIrjFGHO86I0x5hhwS3BCCr1lO4/43F4yEXx861k0Tajlsa1b8wQSNTkopaqRQKuGIkREjDEGXMtLRgcvrKpFXJPKeerYpI7XsV/ddU4lRKSUUhUn0ESwAPhQRGZg3Q+nAvODFlUVI64UUFwiuLhvC51WWilVIwSaCP4M/A64Fetu+DXwWrCCqqrcq4bO794shJEopVTFCSgRGGOcWKOLXw5uOKGXmZPvtc1X1VB8LR03oJSqGQIdR9AJ+BfQHXC1jhpj2gcprpB58dtdXtvEbeGZQe0acO2QtpzTqVFlh6aUUkERaK+h17FKAwXASOAtrMFlNcqTC7bzylLvFcmKu49CTGQEE/q00NlFlVI1RqCJINYY8w0gxpi9xphHgPOCF1ZovLDYuzQAniUCpZSqaQKt6M6xp6Deaa9DvB9oErywqhZNBEqpmizQEsHdQBxwJzAAa/K564MVVFXjXjWkVUJKqZqmzBKBPXjscmPMn4ATwI1Bj6qKcR9HMKaHdhtVStUsZSYCY0yhiAxwH1lcEzmd/n40a9+fx3YjalDryglIKaUqSaBtBBuAz0TkIyC7aKMx5pOgRBUCf/hwY6n7iiqDoiMdoFVDSqkaJtA2ggZAOlZPoQn2nwvLOklExojIdhHZJSLTfOy/SEQ2ichGEVkrImeXJ/iKNGej70VnAN67ebD9SpOAUqrmCXRkcbnbBey2hReB84EUYI2IzDXGbHU77BtgrjHGiEhv4EOsBXCqlPaN7dlEtTSglKqBAh1Z/Drek29ijLnJz2mDgF3GmD32Nd4HLgJcicAY474wcG1fn1EVFBebNBEopWqeQNsIvnB7XQu4BCi9LsXSEtjn9j4FGFzyIBG5BGv6iibA+ADjqVQRYucnLREopWqgQKuGPnZ/LyLvAYvKOM3XXdNXqeJT4FMRGQ5MB0Z7XUhkCjAFoE2bNoGEXC5ldYYKtCFFKaWqo9O9x3UCyrojpwDufS1b4acUYYxZCnQQEa/Z3IwxM40xScaYpMaNG59OvH59uHaf3/0RRSlNSwRKqRoo0DaCLDyf5g9hrVHgzxqgk4i0w5qSYjJwVYnrdgR2243F/bFWPUsPMPYK89BnW3xu/+z2YaxJPgo+FqZRSqmaItCqofjyXtgYU2DPS7QAcACzjDFbRGSqvX8GcBlwnYjkA6eAK0IxaC2vwOlze5/W9ejTuh5kHarkiJRSqvIEWiK4BPjWGJNhv68HjDDGzPF3njFmHjCvxLYZbq//Dfy7vEFXOqONxUqpmivQNoKHi5IAgDHmOPBwcEKqirRqSClVcwWaCHwdFz5rNWqJQClVgwWaCNaKyNMi0kFE2ovIM8C6YAYWahf3beH2TksESqmaK9BE8HsgD/gAaxqIU8DtwQqqytESgVKqBgu011A24DVpXPjQEoFSquYKqEQgIgvtnkJF7+uLyILghVXFaIlAKVWDBdrg28juKQSAMeaYiNSINYt3Hc4CoKfs4TLHMtf2Dqm1YZ49ijk3y96qiUApVfMEmgicItLGGPMrgIgkUkVnCi2v0U8vBeBaxyJ+4/iOTKwpp6MzImCTo/jAOk2hcZWbIVsppc5YoIngQeB7EfnOfj8cexK4miICJwdoyNm5zwGw4aHziasdHeKolFIq+AJtLJ4vIklYN/+NwGdYPYdqjJLV//U1CSilwkSgU0zcDNyFNYPoRmAIsAJr6UqllFLVWKDjCO4CBgJ7jTEjgX5AWtCiqiRLth92vZaa0eShlFLlFmgiyDHG5ACISIwxZhvQJXhhVY7kI9mhDkEppUIu0MbiFHscwRxgoYgco+ylKqu87LxCj/fGaPdQpVT4CbSx+BL75SMishioC8wPWlSVJDu3wO2dVg0ppcJTuWcQNcZ8V/ZR1cPmA5ke7zUVKKXCUdiuy15Q6GTpjuL2bq0UUkqFq7BNBAu2pIY6BKWUqhLCNhE4fSyNbLRcoJQKQ2GbCEqOJNZxBEqpcBW2icDXGAItESilwlHYJoK3V+71eK8lAqVUuArbRBDhY5EZTQVKqXAUtongYEaOx3utFFJKhaugJgIRGSMi20Vkl4h4rXksIleLyCb7z3IR6RPMeJRSSnkLWiIQEQfwIjAW6A5cKSLdSxz2C3CuMaY3MB2YGax4AqGNxUqpcBTMEsEgYJcxZo8xJg94H7jI/QBjzHJjzDH77Uqs9Q5CQhuLlVLhKpiJoCWwz+19ir2tNL8FvvK1Q0SmiMhaEVmblnbmyyD8lJLhc3tMlMPndqWUqsmCmQh81bP4fOwWkZFYieDPvvYbY2YaY5KMMUmNGzc+48CS073HEAiG5nVjz/jaSilV3ZR79tFySAFau71vhY81DESkN/AaMNYYkx7EeMrkq0upUkrVdMEsEawBOolIOxGJBiYDc90PEJE2wCfAtcaYHUGMxYPe75VSqljQSgTGmAIRuQNYADiAWcaYLSIy1d4/A/gr0BB4Say7c4ExJilYMRXH5r1Nc4NSKlwFs2oIY8w8YF6JbTPcXt8M3BzMGMpFhP9en4RTOxAppcJIUBNBVfXJ+hQfW627/6huTSs3GKWUCrGwnGJi+e7S2qS1gkgpFX7CMhHkFji9tumAMqVUuArLRFAq7U6klApDmgiUUirMaSKwaVlAKRWuNBF40HSglAo/mghs2lislApXmgjcaWOxUioMhX0iiNB7v1IqzIV9IiiqEBK3/yqlVDgJ+0Sgt36lVLgL+0RQRDDaRqCUCkthnwi0r5BSKtyFfSIQ1/81JSilwlPYJwJPWjWklAo/YZcIDmflhDoEpZSqUsIvEWTmeryPjXIAEBkhWiBQSoWlsEsEJZ1nr0jWuWmdEEeilFKhEVaJ4Nr/ruLC5793vX/tuiTXyGJHhKBFAqVUOAqrRLBs5xGP96O7N2Vcr+YAJNQKy+WblVIqvBKBL//XoxnJj42ndrQj1KEopVRIhH0i8KAji5VSYSioiUBExojIdhHZJSLTfOzvKiIrRCRXRO4NZixKKaV8C1rFuIg4gBeB84EUYI2IzDXGbHU77ChwJ3BxsOIImDFoY7FSKhwFs0QwCNhljNljjMkD3gcucj/AGHPYGLMGyA9iHEoppfwIZiJoCexze59ibys3EZkiImtFZG1aWtppBZOaWdaIYp19VCkVnoKZCHzdVU9rZjdjzExjTJIxJqlx48anFcwzC3ec1nlKKVXTBTMRpACt3d63Ag4E8fP80od9pZTyLZiJYA3QSUTaiUg0MBmYG8TPK0MZmUAbi5VSYSpovYaMMQUicgewAHAAs4wxW0Rkqr1/hog0A9YCCYBTRO4GuhtjMis6Hi0RKKWUb0GdV8EYMw+YV2LbDLfXh7CqjKoAbSxWSoWnsBlZHKH3eKWU8ilsEoFoG4FSSvkUNokgK8dzzFrXZvEhikQppaqWsEkEJaegblU/NkSRKKVU1RI2iSA9O8/j/c3ntC9xhDYWK6XCU9gkgpIitfVYKaWAME4EXg//2lislApTYZsI+rWuH+oQlFKqSgjbRBDhq2pI2wiUUmEobBJB2ff405oYVSmlqr2wSQQR+rSvlFI+hU0icJSVCLSxWCkVpsInEWh3UaWU8imos49WJXUcBdTJzyjekJXqeUBhnjYWK6XCUtgkgj8m7mFy8kPFG57ycVC74ZUWj1JKVRVhkwiadxnMgztvAqBb8wSuGdzG+6A2Qys5KqWUCr2wSQQn67ThncLRAFyQ0JRrBiaFOCKllKoawqax2H2UQLvGtUMWh1JKVTVhUyIo8uC4btwwLDHUYSilVJURNiWCIsM7NybKEXY/tlJKlUrviEopFebCJhEYnUpIKaV8CptEUETHjCmllKegJgIRGSMi20Vkl4hM87FfROQ5e/8mEekfzHiUUkp5C1oiEBEH8CIwFugOXCki3UscNhboZP+ZArwcrHiUUkr5FswSwSBglzFmjzEmD3gfuKjEMRcBbxnLSqCeiDQPRjDN6tZifK/m1IkJux6zSinlVzDvii2BfW7vU4DBARzTEjjofpCITMEqMdCmjY+pIQIwoG19BrTV5SmVUqqkYJYIfDXLluy7E8gxGGNmGmOSjDFJjRs3rpDglFJKWYKZCFKA1m7vWwEHTuMYpZRSQRTMRLAG6CQi7UQkGpgMzC1xzFzgOrv30BAgwxhzsOSFlFJKBU/Q2giMMQUicgewAHAAs4wxW0Rkqr1/BjAPGAfsAk4CNwYrHqWUUr4FtQuNMWYe1s3efdsMt9cGuD2YMSillPIv7EYWK6WU8qSJQCmlwpwmAqWUCnNiqtm0nCKSBuw9zdMbAUcqMJyKUlXjgqobm8ZVPhpX+dTEuNoaY3wOxKp2ieBMiMhaY0yVW6y4qsYFVTc2jat8NK7yCbe4tGpIKaXCnCYCpZQKc+GWCGaGOoBSVNW4oOrGpnGVj8ZVPmEVV1i1ESillPIWbiUCpZRSJWgiUEqpMBc2iaCs9ZMr+LNai8hiEflZRLaIyF329kdEZL+IbLT/jHM75347tu0i8n9u2weIyE/2vudExNcaDuWNL9m+5kYRWWtvayAiC0Vkp/3/+m7HBz02Eeni9r1sFJFMEbk7FN+ZiMwSkcMistltW4V9PyISIyIf2NtXiUjiGcT1hIhss9f8/lRE6tnbE0XklNv3NsPtnMqIq8J+bxUc1wduMSWLyMYQfF+l3R9C93fMGFPj/2DNfrobaA9EAz8C3YP4ec2B/vbreGAH1rrNjwD3+ji+ux1TDNDOjtVh71sNDMVaxOcrYGwFxJcMNCqx7XFgmv16GvDvUMTm9vs6BLQNxXcGDAf6A5uD8f0AtwEz7NeTgQ/OIK4LgEj79b/d4kp0P67EdSojrgr7vVVkXCX2PwX8NQTfV2n3h5D9HQuXEkEg6ydXGGPMQWPMevt1FvAz1hKcpbkIeN8Yk2uM+QVrWu5BYq3fnGCMWWGs3+hbwMVBCvsi4E379ZtunxOK2EYBu40x/kaQBy0uY8xS4KiPz6uo78f9WrOBUYGUWnzFZYz52hhTYL9dibW4U6kqKy4/Qvp9FbHPvxx4z981ghRXafeHkP0dC5dEUNrayEFnF8n6AavsTXfYxfhZbkW/0uJrab8uuf1MGeBrEVkn1nrQAE2NvSiQ/f8mIYoNrCcY93+gVeE7q8jvx3WOfRPPABpWQIw3YT0VFmknIhtE5DsROcftsysrror6vQXj+zoHSDXG7HTbVunfV4n7Q8j+joVLIghobeQK/1CROsDHwN3GmEzgZaAD0Bc4iFU09RdfsOIeZozpD4wFbheR4X6OrdTYxFrNbiLwkb2pqnxnpTmdOCo8RhF5ECgA3rE3HQTaGGP6AX8A3hWRhEqMqyJ/b8H4nV6J58NGpX9fPu4PpR5ayudUWGzhkggqfW1kEYnC+iW/Y4z5BMAYk2qMKTTGOIFXsaqs/MWXgmdRv0LiNsYcsP9/GPjUjiPVLmoWFYcPhyI2rOS03hiTasdYJb4zKvb7cZ0jIpFAXQKvWvEiItcDFwJX21UE2NUI6fbrdVj1yp0rK64K/r1V9PcVCVwKfOAWb6V+X77uD4Tw71i4JIJA1k+uMHZd3H+Bn40xT7ttb+522CVAUW+GucBku6W/HdAJWG0XD7NEZIh9zeuAz84wttoiEl/0GquxcbMdw/X2Yde7fU6lxWbzeFKrCt+Z2+dV1Pfjfq1JwLdFN/DyEpExwJ+BicaYk27bG4uIw37d3o5rTyXGVZG/twqLyzYa2GaMcVWrVOb3Vdr9gVD+HfPXklyT/mCtjbwDK9M/GOTPOhurGLYJ2Gj/GQe8Dfxkb58LNHc750E7tu249XIBkrD+Ee0GXsAeDX4GsbXH6oHwI7Cl6LvAqj/8Bthp/79BCGKLA9KBum7bKv07w0pEB4F8rCer31bk9wPUwqr62oXV66P9GcS1C6suuOjvWVFPkcvs3++PwHpgQiXHVWG/t4qMy97+BjC1xLGV+X2Vdn8I2d8xnWJCKaXCXLhUDSmllCqFJgKllApzmgiUUirMaSJQSqkwp4lAKaXCnCYCpSqRiIwQkS9CHYdS7jQRKKVUmNNEoJQPInKNiKwWa276V0TEISInROQpEVkvIt+ISGP72L4islKK1wSob2/vKCKLRORH+5wO9uXriMhssdYReMceFapUyGgiUKoEEekGXIE1OV9foBC4GqiNNQ9Sf+A74GH7lLeAPxtjemONpi3a/g7wojGmD3AW1ihXsGabvBtrnvn2wLCg/1BK+REZ6gCUqoJGAQOANfbDeizWBGBOiicq+x/wiYjUBeoZY76zt78JfGTP59TSGPMpgDEmB8C+3mpjz3Mj1gpZicD3wf+xlPJNE4FS3gR40xhzv8dGkYdKHOdvfhZ/1T25bq8L0X+HKsS0akgpb98Ak0SkCbjWkm2L9e9lkn3MVcD3xpgM4JjbQibXAt8Za375FBG52L5GjIjEVepPoVSA9ElEqRKMMVtF5C9Yq7hFYM1eeTuQDfQQkXVYKz5dYZ9yPTDDvtHvAW60t18LvCIif7ev8ZtK/DGUCpjOPqpUgETkhDGmTqjjUKqiadWQUkqFOS0RKKVUmNMSgVJKhTlNBEopFeY0ESilVJjTRKCUUmFOE4FSSoW5/we4jgfRwITJ1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I picked reg = 1e-5\n",
    "# lr = 1e-1\n",
    "# optimizer = SGD With Momentum. [2] indexed log\n",
    "\n",
    "# 0  : lr = 1e-1, reg = 1e-3, momentum = True\n",
    "# 1  : lr = 1e-1, reg = 1e-3, momentum = False\n",
    "#################################################\n",
    "## 2  : lr = 1e-1, reg = 1e-5, momentum = True ##\n",
    "#################################################\n",
    "# 3  : lr = 1e-1, reg = 1e-5, momentum = False\n",
    "# 4  : lr = 5e-2, reg = 1e-3, momentum = True\n",
    "# 5  : lr = 5e-2, reg = 1e-3, momentum = False\n",
    "# 6  : lr = 5e-2, reg = 1e-5, momentum = True\n",
    "# 7  : lr = 5e-2, reg = 1e-5, momentum = False\n",
    "# 8  : lr = 1e-2, reg = 1e-3, momentum = True\n",
    "# 9  : lr = 1e-2, reg = 1e-3, momentum = False\n",
    "# 10 : lr = 1e-2, reg = 1e-5, momentum = True\n",
    "# 11 : lr = 1e-2, reg = 1e-5, momentum = False\n",
    "\n",
    "plt.plot(train_accss[2])\n",
    "plt.plot(val_accss[2])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Learning Rate: 1e-1, Reg: 1e-5, Momentum: SGD With Momentum\n",
      "Test Loss: 1.7745222737860966, Test Accuracy: 0.5157768750906717\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "softmax_out = best_models[2].forward(x_test)\n",
    "predictions = np.argmax(softmax_out, axis=1)\n",
    "loss = layer.loss(softmax_out, y_test)\n",
    "test_acc = np.mean(predictions == y_test)\n",
    "print(\"-----------\")\n",
    "print(\"Learning Rate: 1e-1, Reg: 1e-5, Momentum: SGD With Momentum\")\n",
    "print(\"Test Loss: {}, Test Accuracy: {}\".format(loss, test_acc))      \n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Best of All Models\n",
      "Test Loss: 1.7745222737860966, Test Accuracy: 0.5157768750906717\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "#As we can see best model is already selected from hyperparameter search.\n",
    "softmax_out = best_of_all_models.forward(x_test)\n",
    "predictions = np.argmax(softmax_out, axis=1)\n",
    "loss = layer.loss(softmax_out, y_test)\n",
    "test_acc = np.mean(predictions == y_test)\n",
    "print(\"-----------\")\n",
    "print(\"Best of All Models\")\n",
    "print(\"Test Loss: {}, Test Accuracy: {}\".format(loss, test_acc))      \n",
    "print(\"-----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
